\documentclass[12pt]{book}
\usepackage[dvips]{graphics}
\usepackage{makeidx}
\usepackage{theorem}
\makeindex
\input{genericmac}
\input{mac}
\title{Programming with Regions in the ML Kit}
\author{Mads Tofte \and Lars Birkedal \and Martin Elsman \and
\and Niels Hallenberg \and Tommy H\o jfeld Olesen \and
Peter Sestoft \and Peter Bertelsen}
\raggedbottom

{\theorembodyfont{\rmfamily} \newtheorem{example}{Example}}

\begin{document}

%\setcounter{page}{0}
%\thispagestyle{empty}
%\begin{center}{\bf
%Technical Report DIKU-TR-97/12\\
%Department of Computer Science\\ 
%University of Copenhagen\\
%Universitetsparken 1\\
%DK-2100 KBH \O\\
%DENMARK\\
%\ \\
%April 1997}\vspace{4.5cm}
%{\Large Programming with Regions in the ML Kit}\vspace{2cm}
%\begin{center}
%\large Mads Tofte\quad Lars Birkedal \quad Martin Elsman \\
%Niels Hallenberg \\ Tommy H\o jfeld Olesen \\
%Peter Sestoft \quad Peter Bertelsen
%\end{center}
%\vfill
%\end{center}
%\newpage

\maketitle
\begin{center}
\bf Values and their Representation
\end{center}
\smallskip

\hrule
\halign{\parbox[t]{15mm}{#}\hfil\ &\ \parbox[t]{13cm}{\strut#\strut}\cr
integer&32 bits, untagged. Unboxed (i.e., not region allocated).\cr
real   &64 bits, untagged. Boxed (i.e., allocated in region)\cr
string &Unbounded size. Allocated in region.\cr
bool   &one 32 bit word. Unboxed.\cr
$\alpha$ list & {\tt nil} and {\tt ::} cells unboxed (i.e., not region allocated). Auxiliary
                pairs in one region; elements 
                in zero or more regions. Size of 
                auxiliary pairs: two 32 bit words.\cr
$\alpha$ tree & A tree and its subtrees reside in one region. 
                Elements in one region (if not unboxed).\cr
{\tt exn}&Nullary exception names are unboxed. Constructed
                exception values are stored in a global region.\cr
{\tt fn $\pat$ =>~$\exp$}&An anonymous function is represented by a 
                boxed, untagged closure. Size (in 32 bit words):
                1 plus the number of free variables of the function.
                (Free region variables also count as variables.)\cr
\boxml{fun $f$ $\ldots$} & Mutually recursive region-polymorphic functions
               share the same closure, which is region-allocated, untagged
               and whose size (in words) is the number of variables
               that occur free in the recursive declaration.\cr}
\hrule
\bigskip

\begin{center}
\bf Regions and their Representation
\end{center}
\smallskip

\hrule
\halign{\parbox[t]{15mm}{#}\hfil\ &\ \parbox[t]{13cm}{\strut#\strut}\cr
Finite (\boxml{$\rho$:$n$})& Region whose size can be determined at compile time. During
         compilation, a finite region size is given as a 
         non-negative integer. After multiplicity
         inference, this integer indicates the number of times a value (of
         the appropriate type) is written into the region. Later, after
         physical size inference, the integer indicates the physical
         region size in words. At runtime, a finite region is allocated
         on the runtime stack.\cr
Infinite (\boxml{$\rho$:INF})& All other regions. At runtime, an infinite region
         consists of a stack allocated region descripter, which contains pointers
         to the beginning and the end of a linked list of fixed size region
         pages.\cr }
\hrule
\medskip


\begin{center}
\bf Storage Modes (only significant for infinite regions)
\end{center}
\smallskip

\hrule
\halign{\parbox[t]{15mm}{#}\hfil\ &\ \parbox[t]{13cm}{\strut#\strut}\cr
{\tt atbot} & Reset region, then store value.\cr
{\tt sat}   & Determine actual storage mode ({\tt attop}/{\tt atbot})
              at runtime.\cr
{\tt attop} & Store at top of region, without destroying any values
              already in the region.\cr}
\hrule
\medskip
               
\tableofcontents
\chapter*{Preface}
The ML Kit with Regions is a compiler for full\index{Standard ML}Standard ML,
including Modules and the SML Basis Library. 
It is intended for the development of stand-alone applications that
must be reliable, fast, and space efficient.

There has always been a tension between high-level features in 
programming languages and the programmer's 
legitimate need to understand
programs at the operational level. Very likely, if a resource conscious
programmer is forced to make a choice between the two, he will choose the latter.

The ML Kit with Regions is the result of a research and development
effort which has been going on at the University of Copenhagen for the
past seven years. The goal of this project has been to develop
implementation technology which combines the advantages of using a
high-level programming language, in this case Standard ML, with a model of
computation that allows programmers to reason about how much space
and time their programs will use.

In most call-by-value languages, it is not terribly hard to give a
model of time usage that is good enough for elementary reasoning. 

For space, however, the situation is much less satisfactory. Part of
the reason is that many programs must recycle memory while running.
For all such programs, the mechanisms that reclaim memory inevitably
become part of the reasoning.  This is true irrespective of whether memory
recycling is done by a \index{stack}stack mechanism or by pointer tracing garbage
collection.

In the stack discipline, every point of allocation is matched by a
point of de-allocation and these points are obvious from the
program. By contrast, garbage collection techniques usually separate
allocation, which is done by the programmer, from de-allocation, which
is done by a garbage collector.  The advantage of using reference
tracing \index{garbage collection}garbage collection techniques is that they apply to a wide
range of high-level concepts now found in programming languages, for
example recursive data types, higher-order functions, exceptions,
references, and objects. The disadvantage is that it is becoming
increasingly difficult for the programmer to reason about
lifetimes. Lifetimes may depend on subtle details in the compiler and
in the garbage collector. Thus, it is hard to model memory in a way
that is useful to programmers. Also, compilers offer little
assistance for reasoning about lifetimes.

In this report, we equip Standard ML with a different memory management
discipline,  namely a {\em region-based} memory model.
Like the stack discipline, the region discipline is, in essence, simple and
platform-independent. Unlike the traditional stack discipline,
however, the region discipline also applies to recursive data types,
references, and higher-order functions, for which one has hitherto
mostly used reference tracing garbage collection techniques.

The reader we have in mind is a person with a Computer Science
background who is interested in developing reliable and efficient
applications written in Standard ML. Also, the report may be of
interest to researchers of programming languages, since the ML Kit
with Regions is a fairly bold exercise in program analysis. We should
emphasise, however, that this report is very much intended as a user's
guide, not a scientific publication.

This report consists of three parts:
\begin{description}
\item[Part I: Overview,] in which we give an overview of the ideas that underlie programming with
regions in the Kit;
\item[Part II: Understanding Regions,] in which we systematically
go through the language constructs of the Standard ML Language,
showing for each one how it can be used when programming with regions;
\item[Part III: System Reference,] in which we explain how to interact with
the system, how to use the region profiler and how to call C functions from the ML Kit.
\end{description}

The present report describes the \index{ML Kit!Version 3}ML Kit
Version 3. This version of the ML Kit extends the ML Kit Version 2
with support for the Standard ML Modules language. The \index{ML
  Kit!Version 2}ML Kit Version 2 is a further development of the
\index{ML Kit!Version 1}ML Kit Version~1, which was developed at
Edinburgh University and Copenhagen University.  The ML Kit (after
Version 1) is also called the ML Kit with Regions.  We hope you will
enjoy using the ML Kit with Regions as much as we have enjoyed
developing it. If your experience with the Kit gives rise to comments
and suggestions, specifically with relation to the goals and visions
expressed here, please feel free to write.  Further information is
available at our \index{web site}web site:
\begin{tabbing}
\hskip2cm\boxml{http://www.diku.dk/research-groups/}\\
\hskip2cm\quad\boxml{topps/activities/mlkit.html}
\end{tabbing}

\begin{flushright}
August, 1998\\[1cm]
Mads Tofte, Lars Birkedal, Martin Elsman,\\
Niels Hallenberg, Tommy H\o jfeld Olesen,\\
Peter Sestoft, Peter Bertelsen
\end{flushright}
\part{Overview}
\chapter{Region-Based Memory Management}
\label{intro.sec}
Region-Based Memory Management is a technique for managing
memory for programs that have dynamic data structures, such as lists,
trees, pointers, and function closures.

\section{Prevailing Approaches to Dynamic Memory Management}
Many programming languages rely on a memory model consisting of a 
{\em stack} \index{stack}and a \index{heap}{\em heap}. Typically, the stack 
holds temporary values, activation records, arrays, and in general, values
whose lifetime is closely connected to procedure activations and whose size
can be determined at the latest when creation of the value begins.
The heap is what holds all the other values. In particular, the heap holds values whose size 
can grow dynamically, such as lists and trees. The heap also holds values whose lifetime
does not follow procedure activations closely (for example lists and, in functional
languages, function closures and suspensions).

The beauty of the stack discipline 
(apart from the fact that it is often very efficient in
practice) is that it couples allocation points and de-allocation points in a manner
that is intelligible to the programmer. C programmers appreciate that whatever memory
is allocated for local variables in a procedure ceases to exist (and take up memory)
when the procedure returns. \index{C}C programmers also know that counting from
one to some large number, $N$,  is not best done by making $N$ recursive
C procedure calls, because that would use stack space proportional to $N$.

By contrast, programmers have much less help when it comes to managing
the heap.  Two approaches prevail. The first approach is that the
programmer manages memory herself, using explicit allocation and
de-allocation instructions (e.g., \index{malloc@{\tt malloc}}{\tt
  malloc} and \index{free@{\tt free}}{\tt free} in C). For non-trivial
programs this can be a very significant burden, because it is, in
general, very hard to make sure that none of the values that reside in
the memory that one wishes to de-allocate are not needed for the rest
of the computation.  This puts the programmer in a very difficult
position. If one is too eager to reclaim memory in the heap, the
program might crash under some peculiar circumstances, which might be
hard to find during debugging. If one is too conservative reclaiming
memory, the program might ``leak space'', that is, it might use more
memory than expected, perhaps eventually, exhaust the memory of the
machine.

The other prevailing approach is to use automatic garbage collection
in the heap.  Some implementers of some languages even dispense with
the stack entirely, relying only on a heap with garbage collection.
Garbage collection techniques separate allocation, which is done by
the programmer, from de-allocation, which is done by the garbage
collector.  At first, this might seem like the perfect solution: no
longer does the programmer have to worry about whether memory that is
being reclaimed really is dead, for the garbage collector only
reclaims memory that cannot be reached by the rest of the
computation. However, reality is less perfect. Garbage collectors are
typically based on the idea that if data is reachable via pointers
(starting from the stack and other root data) then those data must be
kept. Consequently, programs have to be written with care to avoid
hanging on to too many pointers. Space conscious programmers (and
language implementers) can work their way around these problems, for
example by assigning {\tt nil} to pointers that are no longer used.
However, such tricks often rely on assumptions about the code that
cannot be checked by the compiler and that are likely to be
invalidated as the program evolves.


\section{Checked De-Allocation of Memory}
\label{checked.sec}
Regions offer an alternative to these two approaches. 
The runtime model is very simple, at least in principle. 
The store consists of a \index{region stack}stack
of \index{region}{\em regions}, see Figure~\ref{stacks.fig}.
\begin{figure}[t]
\hrule
\begin{center}
\begin{picture}(70,50)(0,0)
\put(0,5){\framebox(10,25){}}
\put(5,0){\makebox(0,0){$\boxml{r}_0$}}
\put(15,5){\framebox(10,5){}}
\put(20,0){\makebox(0,0){$\boxml{r}_1$}}
\put(30,5){\framebox(10,35){}}
\put(35,0){\makebox(0,0){$\boxml{r}_2$}}
\put(45,5){\framebox(10,10){}}
\put(50,0){\makebox(0,0){$\boxml{r}_3$}}
\put(60,5){\makebox(0,0){$\ldots$}}
\end{picture}
\end{center}
\caption{The store is a stack of regions; every region 
is depicted by a box in the picture.}
\vskip5mm
\hrule
\label{stacks.fig}
\end{figure}
Regions hold values, for example tuples, records, 
function closures, references,
and values of recursive types 
(such as lists and trees). 
All values, except those that fit  within 
one machine word (for example integers), are stored in regions.


The size of a region \index{region size}is not necessarily known when
the region is allocated.  Thus a region can grow gradually (and many
regions can grow at the same time) so one might think of the region
stack as a stack of heaps. However, the region stack really is a stack
in the sense that (a) if region $r_1$ is allocated before region $r_2$
then $r_2$ is de-allocated before $r_1$ and (b) when a region is
de-allocated, all the memory occupied by that region is reclaimed in
one constant time operation.

Values that reside in one region are often, but not always, of the
same type. A region can contain pointers to values that reside in the
same region or in other regions. Both forward pointers (i.e., pointers
from a region into a region closer to the stack top) and backwards
pointers (i.e., pointers to an older region) occur.

Conceivably, one can combine the region scheme with pointer tracing
\index{garbage collection}garbage collection
techniques.\footnote{Indeed we might well provide a release of the ML
Kit which has both regions and reference-tracing garbage collection.}
In the present version of the ML Kit, however, the region stack is the
only form of memory management provided. How can that be so? Is the
region model really general enough to fit a wide variety of
computations?

First notice that the pure \index{stack}stack discipline (a stack, but no heap) 
is a special case of the region stack. Here the size of a region is known
at the latest when the region is allocated. Another special case is when 
one has just one region in the region stack and that region grows dynamically.
This case can be thought of as a \index{heap}heap with no garbage collection, which again
would not be sufficient.

But when one has many regions, one obtains the possibility of distinguishing
between values according to what region they reside in. 
The ML Kit has operations for allocating, 
de-allocating, and extending regions. But it also 
has an explicit operation for \index{region!resetting}resetting an existing region, that is, reclaiming all the memory
occupied by the region without eliminating the region from the region stack.
This primitive, simple as it is, enables one to cope with most of those
situations where lifetimes simply are not nested. Figure~\ref{slideshow.fig}
shows a possible progression of the region stack.

\begin{figure}
\hrule
\begin{center}
\begin{picture}(70,45)(0,0)
\put(0,5){\framebox(10,25){}}
\put(5,0){\makebox(0,0){$\boxml{r}_0$}}
\put(15,5){\framebox(10,5){}}
\put(20,0){\makebox(0,0){$\boxml{r}_1$}}
\put(30,5){\framebox(10,35){}}
\put(35,0){\makebox(0,0){$\boxml{r}_2$}}
\put(45,5){\framebox(10,10){}}
\put(50,0){\makebox(0,0){$\boxml{r}_3$}}
\put(60,5){\framebox(10,20){}}
\put(65,0){\makebox(0,0){$\boxml{r}_4$}}
\end{picture}
\medskip

(a)
\medskip

\begin{picture}(70,50)(0,0)
\put(0,5){\framebox(10,25){}}
\put(5,0){\makebox(0,0){$\boxml{r}_0$}}
\put(15,5){\framebox(10,5){}}
\put(20,0){\makebox(0,0){$\boxml{r}_1$}}
\put(30,5){\framebox(10,45){}}
\put(35,0){\makebox(0,0){$\boxml{r}_2$}}
\put(45,5){\framebox(10,0){}}
\put(50,0){\makebox(0,0){$\boxml{r}_3$}}
\put(60,5){\framebox(10,30){}}
\put(65,0){\makebox(0,0){$\boxml{r}_4$}}
\put(75,5){\framebox(10,40){}}
\put(80,0){\makebox(0,0){$\boxml{r}_5$}}
\end{picture}
\medskip

(b)
\medskip

\begin{picture}(70,50)(0,0)
\put(0,5){\framebox(10,25){}}
\put(5,0){\makebox(0,0){$\boxml{r}_0$}}
\put(15,5){\framebox(10,45){}}
\put(20,0){\makebox(0,0){$\boxml{r}_1$}}
\put(30,5){\framebox(10,45){}}
\put(35,0){\makebox(0,0){$\boxml{r}_2$}}
\put(45,5){\framebox(10,5){}}
\put(50,0){\makebox(0,0){$\boxml{r}_3$}}
\end{picture}
\medskip

(c)
\medskip
\end{center}
\caption{Further development of the region stack: (a) after allocation of 
$\boxml{r}_4$;
(b) after growth of $\boxml{r}_2$ and $\boxml{r}_4$, resetting of $\boxml{r}_3$ and allocation of $\boxml{r}_5$;
(c) after popping of $\boxml{r}_4$ and $\boxml{r}_5$ but extension of $\boxml{r}_1$ and $\boxml{r}_3$.}
\vskip5mm
\hrule
\label{slideshow.fig}
\end{figure}

In the ML Kit the vast majority of region management is done
automatically by the compiler and the runtime system.  Indeed, with
one exception, source programs are written in Standard ML, with no
added syntax or special directives. The exception has to do with
resetting of regions. The Kit provides two built-in functions
\index{resetRegions@$\resetr$}\index{forceResetting@$\resetf$}($\resetr$ and $\resetf$), which instruct the
program to reset regions. Here $\resetr$ is a safe form of resetting
where the compiler only inserts region resetting instructions if it can prove
that they are safe; it prints thorough explanations of why it thinks
resetting might be unsafe otherwise. The function $\resetf$ is for potentially
unsafe resetting of regions, which is useful in cases where the
programmer jolly well knows that resetting is safe even if the
compiler cannot prove it. The function $\resetf$ is the only way we allow users to
make decisions that can make the program crash; many programs do not
need $\resetf$ and hence cannot crash (unless we have bugs in our
system).

All other region directives, including directives for
allocation and de-allocation of regions, are inferred automatically by
the compiler.  This happens through a series of fairly complex program
analyses and transformations (in the excess of twenty-five passes
involving three typed intermediate languages). These analyses are formally
defined and the central one, called \index{region inference}{\em region inference}, has been
proved correct for a skeletal language. Although the formal rules
that govern region inference and the other program analyses are
complex, we have on purpose restricted attention to program analyses
that we feel capture natural programming intuitions.
Moreover, the Kit implementation is such that, with one exception\footnote{The exception
has to do with exceptions. When an exception is raised, a search
down the stack for a handler takes place; this search is not
constant time and it involves popping of regions on the way. However,
the number of region operations is bounded by the number of
handlers that appear on the stack.},
every region directive takes constant time and constant space to execute. The
fact that we avoid interrupting program execution for unbounded lengths
of time gives a nice smooth experience when programs are run and should
make the scheme attractive for real-time programming.

To help programmers get used to the idea of programming with regions,
the ML Kit can print region-annotated programs, that is, source programs
it has annotated with region directives. Also, it provides a \index{region profiling}{\em
region profiler\/} for examining run-time
behaviour.  The region profiler gives a graphical representation of
region sizes as a function of time. This tool makes it possible to see
what regions use the most space and even to relate memory consumption
back to individual allocation points in the (annotated) source
program.

To sum up, the key advantages obtained by using regions compared to more 
traditional memory management schemes are
\begin{enumerate}
\item safety of de-allocation is checked by the compiler;
\item the compiler can in many cases spot potential space leaks;
\item region management is under the control of the user, provided
      one understands the principles of region inference;
\item each of the region operations that are inserted use
      constant time and constant space at runtime;
\item it is possible to relate runtime space consumption 
      to allocation points in the source program; we have found
      region profiling to be a powerful tool for eliminating
      space leaks.
\end{enumerate}
Regions are not a magic wand to solve all memory management
problems. Rather, the region scheme encourages a  particular
discipline of programming. The purpose of this report is
to lay out this discipline of programming.

\section{Example: the Game of Life}
\label{life.sec}\index{Life, game of}
To illustrate the general flavour of region-based memory management,
let us consider the problem of implementing the game of Life. The
game takes place on a board that resembles a chess board, except that
the size of the board can grow as the game evolves. Thus every position
has eight neighbouring positions (perhaps after extension of the board). 
At any point in time, every
position is either  {\em alive} or {\em dead}. A snapshot of the game consisting
of the board together with an indication of which positions are alive is called
a {\em generation}. The rules of the game specify how to progress from one
generation to the next. Consider generation $n$ from which we want
to create generation $n+1$ ($n\geq0$). Let $(i,j)$ be a position on
the board, relative to some fixed
point $(0,0)$ in the plane. Assume $(i,j)$ is alive in generation $n$. Then $(i,j)$ stays
alive in generation $n+1$ if and only if it has two or three live neighbours
in generation $n$. Assume $(i,j)$ is dead at generation $n$. Then it
is born in generation $n+1$ if and only if it has precisely three live
neighbours at generation $n$. We assume that only finitely many positions
are alive initially. An example of two generations of Life
is shown below:
\begin{verbatim}
                    0
                   0 0
                  0   00        0
       00         0   00     0000   0
       00         0   00    0000    0
                   0 0      0  0        00
                    0       0000        00
                             0000


                    0
                   0000
                  00 0 0      0 0
       00        000 0  0   0   0
       00         00 0 0    0
                   0000    0    0       00
                    0       0           00
                            0   0
                              00
\end{verbatim}

To represent the game board, we need a data structure 
which can grow dynamically
(so a two-dimensional array of fixed size is not sufficient). 
A simple solution is to represent a generation by a list of integer pairs, namely
the positions that are alive. Since we want to give all pairs belonging
to one generation the same lifetime (in the computer memory, that is!)
it is natural to store all the integer pairs belonging to one generation
in the same region. Indeed region inference forces this decision upon us,
as it happens, since it requires that all elements belonging to the same
list lie in the same region. (Different lists can lie in different regions,
however.)

Thus, after having built the initial generation, we expect the region
stack to look like this
\begin{center}
\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(45,25){\parbox{4cm}{$l_n$: list of integer pairs representing generation $n$.}}}
\put(20,0){\makebox(0,0){$\boxml{r0}$}}
\end{picture}
\end{center}
The computation of the next generation involves a considerable amount of list computation.
Chris Reade has expressed the key part of the computation as shown 
in Figure~\ref{xavier.fig}.
\begin{figure}
\hrule
\begin{verbatim}

  let val living = alive gen
      fun isalive x = member eq_int_pair_curry living x
      fun liveneighbours x = length(filter isalive (neighbours x))
      fun twoorthree n = n=2 orelse n=3
      val survivors = filter (twoorthree o liveneighbours) living
      val newnbrlist = collect 
                        (fn z => filter (fn x => not(isalive x)) 
                                        (neighbours z)
                        ) living
      val newborn = occurs3 newnbrlist
  in 
     mkgen (survivors @ newborn) 
  end
\end{verbatim}
\caption{An excerpt of a (modified version of) 
Chris Reade's Game of Life program.}
\medskip

\hrule
\label{xavier.fig}
\end{figure}
Despite the extensive use of higher-order functions here, there is a
great deal of stack structure in this computation. For example, the 
{\tt survivors} list 
can be allocated in a local region which can be de-allocated after the list
has been appended (\boxml{@}) to the {\tt newborn} list. The computation of  {\tt survivors}, 
in turn, involves the creation of a closure for \boxml{(twoorthree o liveneighbours)} and
additional creation of closures as part of the 
computation of the application of {\tt filter}. Each time {\tt liveneighbours}
is called (by {\tt filter}) additional temporary values are created.
All of this data should live shorter than {\tt survivors} itself.
The details of these lifetimes are determined automatically 
by the region inference 
algorithm, which ensures that
when the above expression terminates it will simply have created a list containing
the live positions of the new generation.

But now we have a design choice. Should we put the new generation in
the same region as the previous region or should we arrange that it is
put in a separate region? Piling all generations on top of each
other in the same region
would clearly be a waste of space: only the most recent generation is
ever needed. Similarly, giving each generation a separate region on the
region stack is no good either, because it would make the stack grow
ad infinitum (although this could be alleviated somewhat by resetting
all regions except the topmost one). The solution is simple, however:
use two regions, one for the current generation and one for the new
generation. When the new generation has been created, reset the region
of the old region and copy the contents of 
the new region into the old region. This effect is
achieved by organising the main loop of the program as follows:
\begin{verbatim}
  local 
(*1*) fun nthgen'(p as(0,g)) = p 
(*2*)   | nthgen'(p as(i,g)) = 
(*3*)       nthgen' (i-1, let val g' = nextgen  g
(*4*)                     in  show g;
(*5*)                         resetRegions g;
(*6*)                         copy g'
(*7*)                     end)
  in 
(*8*) fun iter n = #2(nthgen'(n,gun()))
  end
\end{verbatim}
Here \boxml{nthgen'} \index{nthgen@{\tt nthgen}}is the main loop of
the program. It takes a pair as argument; the first component of the
pair indicates the number of iterations desired, while the second,
\boxml{g}, is the current generation. The use of the {\tt as} pattern
in line 1 forces the argument and the result of \boxml{nthgen'} to be
in the same regions. Such a function is called a \index{region
  endomorphism}{\em region endomorphism}. In line 3, we compute a
fresh generation, which lies in fresh regions, as it happens. Having
printed the generation (line 4) we then reset the regions containing
{\tt g}. The compiler checks that this is safe. Then, in line 6 we
copy {\tt g'} and the target of this copy must be the regions of {\tt
  g}, because \boxml{nthgen'} is a region endomorphism (see
Figure~\ref{doublecopy.fig}).  All in all, we have achieved that at
most two generations are live at the same time (a fact that can be
checked by inspecting the region annotated code, if one feels
passionately about it).\footnote{The source file for the life program
  is \boxml{kitdemo/life.sml}\index{life@{\tt life}}. Running programs
  is described in Section~\ref{tryit.sec}. When run with n=10000 on
  the HP PA-RISC, the memory consumption (resident memory, measured
  using {\tt top}) quickly reaches 180Kb and
  stays there for the remaining generations.}

\begin{figure}
\hrule
\begin{center}
\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(45,25){\parbox{4cm}{$l_n$: list of integer pairs representing generation $n$.}}}
\put(20,0){\makebox(0,0){$\boxml{r0}$}}
\end{picture}
\medskip

(a)
\medskip

\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(45,25){\parbox{4cm}{$l_n$}}}
\put(20,0){\makebox(0,0){$\boxml{r0}$}}
\put(50,5){\framebox(45,25){\parbox{4cm}{$l_{n+1}$: list of integer pairs representing generation $n+1$.}}}
\put(70,0){\makebox(0,0){$\boxml{r1}$}}
\end{picture}
\medskip

(b)
\medskip

\begin{picture}(70,40)(0,0)
\put(0,5){\framebox(45,25){\parbox{4cm}{copy of $l_{n+1}$}}}
\put(20,0){\makebox(0,0){$\boxml{r0}$}}
\end{picture}
\medskip

(c)
\medskip

\end{center}
\caption{ Using double-copying in the game of Life:
(a) generation number $n$ resides in region \boxml{r0}; (b)
 generation $(n+1)$ has been built in \boxml{r1};
(c) region \boxml{r0} has been reset, the new generation
copied into \boxml{r0} and \boxml{r1} has been de-allocated.}
\vskip5mm
\hrule
\label{doublecopy.fig}
\end{figure}

The above device, which we refer to as \index{double copying}{\em
  double copying}, can be seen as a much expanded version of what is
often called ``tail recursion optimisation''.  In the case of regions,
not just the stack space, but also region space, is re-used. Indeed,
double copying is similar to invoking a copying garbage collector on
specific regions that are known not to have live pointers into them.
But by doing the copying ourselves, we have full control over when it
happens, we know that the cost of copying will be proportional to the
size of the generation under consideration and that all other memory
management is done automatically by the region mechanism. Because each
of the region management directives that the compiler inserts in the
code are constant time and space operations, we have now avoided
unpredictable interruptions due to memory management. This avoidance
of unpredictable interruptions might not be terribly important for the
purpose of the game of Life, but if we were writing control software
for the ABS brakes of a car, having control over all costs, including
memory management, would be crucial!

\begin{figure}
\begin{center}
\includegraphics{life80.ps}
\end{center}
\caption{A region profile of two hundred 
generations of the ``Game of Life'', showing
region sizes as a function of time (80 snapshots).}
\label{lifeprof80.fig}
\end{figure}


Region profiles for two hundred generations of {\tt life} starting from the configuration
shown earlier appear in Figures~\ref{lifeprof80.fig} and \ref{lifeprof200.fig}.
The highest amount of memory used for regions during the computation is
29.000 bytes. Figure~\ref{lifeprof200.fig}, which has data collected from 200 snapshots
of the computation, clearly shows that most of the 26,060 bytes are reclaimed between
every two generations of the game. It turns out that the game essentially stabilises
with a small number of live positions on the board after roughly 150 generations.
This stabilisation is clearly reflected in the region profile.

\begin{figure}
\begin{center}
\includegraphics{life200.ps}
\end{center}
\caption{Region profile of two hundred 
generations of the ``Game of Life'', showing
region sizes as a function of time (200 snapshots).}
\label{lifeprof200.fig}
\end{figure}

Figure~\ref{lifeprof200.fig} is from the same computation, but it only includes
data from 80 snapshots. This figure makes it easier to see that the largest
regions are \boxml{r94625} and \boxml{r94243}. To find out what these regions contain,
however, one needs to know about the methods described in Part~\ref{understanding.sec}.

\subsection{Try it!}
This section tells you how to repeat the profiling experiment shown above. 

Compile the SML program \boxml{kitdemo/life.sml} as follows. (Start from
 the \boxml{kit} directory.)
\begin{verbatim}
       cd kitdemo
       ../bin/kit
\end{verbatim}
Select \boxml{Profiling} from the Kit menu (type 5, then carriage return).
Toggle \boxml{region profiling} (type 0, then carriage return). Go up one
level (type \boxml{u}, then carriage return). Select \boxml{Compile an sml file}.
Type \boxml{"life.sml"} (including the quotes, then return). After the Kit has compiled
\boxml{life.sml}, type \boxml{quit}. The executable life program
is \boxml{kitdemo/run}.

Next, you run \boxml{run}, as follows:
\begin{verbatim}
       run -microsec 10000
\end{verbatim}
This will make a profiling snapshot every 10,000 microsecods (i.e., every 
ten milliseconds). If you are satisfied with less fine-grained information,
choose a larger number; it will speed up execution. If you just type
\begin{verbatim}
       run 
\end{verbatim}
there will be one snapshop per second.

Finally, you create a Postscript file and view it as follows:
\begin{verbatim}
       ../bin/rp2ps -region -name life -sampleMax 80 
       ghostview -seascape region.ps
\end{verbatim}
The option \boxml{-sampleMax $n$} instructs \boxml{rp2ps} that
to show at most $n$ snapshots (evenly distributed
over the duration of the computation).

\section{Including a Profile in a LaTex Document}
Figure~\ref{lifeprof80.fig} was produced by first\index{LaTeX document!including figure in}
executing the command
\index{-eps@{\tt -eps}}
\index{-sampleMax@{\tt -sampleMax}}
\index{-region@{\tt -region}}
\begin{verbatim}
 ../bin/rp2ps -region -name life -sampleMax 80 -eps 150 mm
\end{verbatim}
The option \boxml{-eps 150 mm} has the effect that \boxml{region.ps}
becomes an encapsulated PostScript file.\index{region.ps@{\tt region.ps}}
The resulting \boxml{region.ps} was renamed \boxml{life80.ps}
and included in this document as follows:
\begin{verbatim}
\begin{figure}
\begin{center}
\includegraphics{life80.ps}
\end{center}
\caption{A region profile of two hundred 
generations of the ``Game of Life'', showing
region sizes as a function of time (80 snapshots).}
\label{lifeprof80.fig}
\end{figure}
\end{verbatim}

\chapter{Making Regions Concrete}
In this chapter, we give a brief overview of how the abstract
memory model presented in the last chapter is mapped down to conventional
memory. In doing so, we shall introduce notation and concepts that will be
used extensively in what follows.

\section{Finite and Infinite Regions}
\label{fininf.sec}
Not every region has the property that its size is known at compile-time, 
or even when the region is first allocated at runtime. 
As we have seen, one typical use of a region is to hold
a list, and in general there is no way of knowing how long a given list
is going to be. 


For efficiency reason, however, the Kit distinguishes 
between two kinds of regions: those regions whose
size it can determine at compile-time and those it cannot. 
\index{region size}These regions are referred to as \index{region size!finite}{\em finite} and 
\index{region size!infinite}{\em infinite} regions, 
respectively.\footnote{``finite'' and ``unbounded'' would have been better
terms, but it is too late to change that.}
Finite regions are always 
allocated on the \index{runtime stack}runtime stack.
An infinite region is represented as a linked list of fixed-size \index{region page}pages.
The runtime system maintains a free list of such pages. An infinite region
is represented by a \index{region descriptor}{\em region descriptor}, which is a record kept on
the runtime stack. The region descriptor contains two pointers: one to
the first and one to the last region page in the linked list that
represents the region. Allocating an infinite region involves getting a
page from the \index{free list}free list and pushing a region descriptor 
onto the runtime
stack. Popping a region is done by appending the region pages of the
region and the free list (this is done in constant time) and then popping
the region descriptor off the runtime stack.

At runtime, every region is represented by a 32-bit entity, called
a \index{region name}{\em region name}. If the region is finite, the
region name is a pointer into the stack, namely to the beginning of the
region. If the region is infinite, the region name is a pointer to
the region descriptor of the region. 

The \index{multiplicity}{\em multiplicity} of a region is a statically determined upper
bound on the number of times a value is put into the region. The Kit
operates with three multiplicities: 0, 1 and $\infty$, ordered
by $0<1<\infty$. Multiplicities annotate
binding occurrences of region variables. An expression of the form
$$\boxml{letregion $\rho:m$ in $e$ end}$$
where $m$ is a multiplicity,
gives rise to an allocation of a region, which is finite if $m<\infty$, and
infinite otherwise.

\section{Runtime Types of Regions}
\label{runtimetypes.sec}
Every region has a \index{runtime type}runtime type. The following
runtime types exist: {\tt real}, {\tt string} and {\tt top}. Not
surprisingly, regions of runtime type {\tt real} and {\tt string}
contain values of ML type {\tt real} and {\tt string}, respectively.
Regions with runtime type {\tt top} can contain all other forms of
allocated values, that is, constructed values, tuples, records, and
function closures.

It is often, but not always, the case that all values that reside in the
same region have the same type (considered as representations of ML values).
 
\section{Allocation and De-Allocation of Regions}
\label{aldeal.sec}
The analysis that decides when regions should be allocated and de-allocated
is called {\em region inference}. Region inference inserts 
several forms of memory management directives
as directives into the program.
The target language of region inference is called \index{RegExp@$\RegExp$}$\RegExp$.

In $\RegExp$, 
region allocation and de-allocation are explicit, they are always paired,
and they follow
the syntactical structure of the source program. 
If $e$ is an expression in $\RegExp$, then so is\index{letregion@{\tt letregion}}
$$\boxml{letregion $\rho$ in $e$ end}$$
Here $\rho$ is a \index{region variable}{\em region variable}. At runtime, first a region
is allocated and bound to $\rho$. Then $e$ is evaluated, presumably using
the region bound to $\rho$ for storing values. Upon reaching {\tt end}, the program pops the
region.

Region inference also decides, for each value-producing expression, 
into which region (identified by a region variable) the value will be put.

We emphasise that region variables and {\tt letregion}-expressions are
not present in source programs. The source language is unadulterated
Standard ML, so programs  that run on the Kit should be easy to port to any 
other Standard ML implementation.

%Conceptually, there is also a normal runtime stack, which holds temporary values,
%return addresses and so on, but in practice the two stacks are merged into one, which
%we refer to as the runtime stack.

\section{The Kit Abstract Machine}
\index{Kit Abstract Machine}The Kit contains a virtual machine, called
the {\em Kit Abstract Machine} (KAM, for short), which details the
above ideas. The KAM is a register machine with one linear address
space, which is partitioned into a stack and a heap. The heap holds
region pages, all of the same size.  The KAM has simple RISC-like
instructions, for example for moving word-size data between two
registers or between a register and a memory location.  More complex
operations, such as function application, are expressed by sequences
of KAM instructions.

For the purpose of this report,
we assume that the KAM has infinitely many registers.
In reality, there is a fixed number of 32 bit registers \index{word size}and
register allocation assigns machine registers to KAM registers, using the runtime
stack for spilling. However, register allocation will not be described in this report.
%As a rule, we shall conservatively assume that 
%every access to a value requires one memory 
%access. 
Also, we do not discuss the interaction between hardware cache strategies and
the code generated by the Kit. While both can be important in practice, we do not want
to go to that level of detail. Our primary concern is with establishing a model that
the user can safely use as a worst-case model of what happens at runtime.

\section{Intermediate Languages}
The Kit compiles Standard ML programs via a sequence of typed intermediate 
languages into  KAM instructions, which in turn are compiled into ANSI C or into HP 
PA-RISC assembly language.
The intermediate languages that
we shall refer to in the following are (in the order in which they are used in the
compilation process):
\begin{description}
\item[\Lam] \index{Lambda@$\Lam$}A lambda-calculus like intermediate language. The main difference between
  the Standard ML Core Language and {\it Lambda} is that the latter only has trivial patterns.
\item[\RegExp] \index{RegExp@$\RegExp$}Same as \Lam, 
but with explicit region annotations (such as the {\tt letregion}-bindings
mentioned in Section~\ref{aldeal.sec}). Region variables have their runtime type (Section~\ref{runtimetypes.sec})
as an attribute, although, for brevity, the pretty printer omits runtime types when printing expressions, 
unless instructed otherwise.
\item[\MulExp] \index{MulExp@$\MulExp$}Same as $\RegExp$, but now every binding region variable occurrence
is also annotated with a multiplicity (Section~\ref{fininf.sec}) in addition to a runtime type.
Again, the default is that the runtime type is not printed. The terms of $\MulExp$ are polymorphic 
in the information that annotate the nodes of the terms. That way, $\MulExp$ can be used
as a common intermediate language for a number of the internal analyses of the compiler, which
add more and more information on the syntax tree.
The analysis that computes multiplicities is called the \index{multiplicity analysis}{\em multiplicity analysis}.
\end{description}
%The Kit compiles SML records into $\Lam$-tuples and compiles 
%SML-matches and other constructs containing patterns
%into simpler $\Lam$-constructs. 

The Kit contains a \index{Lambda optimiser}$\Lam$ optimiser,
which will happily rewrite $\Lam$ terms when it is clear that this rewrite results in faster programs
(as long as the rewrite cannot lead to increased space usage).

Region inference takes $\Lam$ to be the source language. Region inference happens after
the $\Lam$ optimiser has had a go at the $\Lam$ term. 
Therefore, it was not really true when we said that region inference simply annotates source
programs;  we ignored the translation from SML to $\Lam$ and
the $\Lam$ optimiser. Thus, one has to get used to (mostly minor) differences between
the source language and the intermediate languages of the compiler if one wants to read
programs in their intermediate forms.

When we want to show the result of the analyses, we usually show a $\MulExp$ expression.

\section{Runtime System}
The \index{runtime system}runtime system is written in C. It is small (less than 50Kb 
of code when compiled).
It contains operations for allocating and de-allocating regions, extending regions,
obtaining more space from the operating system, recording region profiling information, and performing
low-level operations for use by the SML Basis Library.

It is possible to call \index{C!calling}C functions from ML Kit code.
The Kit takes care of the memory allocation, by allocating regions for
the result of the call before the call and de-allocating the regions
at some point after the call. The C functions can build ML data
structures such as lists through abstract operations provided by the
Kit runtime system. See Chapter~\ref{ccall.sec} for further details.

\part{Understanding Regions}
\label{understanding.sec}
\chapter{Records and Tuples}
In this chapter, we describe construction of \index{record}records and selection of record
components. We also use records to introduce  \index{type!region-annotated}{\em region-annotated
types} and \index{effect}{\em effects}, which are crucial for understanding when regions are allocated
and de-allocated.
\section{Syntax}
As part of the SML to \index{Lambda@$\Lam$}$\Lam$ translation, all SML records and SML tuples are compiled into
$\Lam$ tuples. The components of $\Lam$ tuples are numbered from left to right, starting from 0.
%$\Lam$ has an operation 
%\index{select@{\tt SELECT}}$\boxml{SELECT}(i,e)$ 
%for selecting component number $i$
%from the $\Lam$-tuple denoted by the $\Lam$-expression $e$.
Selection is a primitive operation, both in $\Lam$ and in the other
intermediate languages. This primitive is printed using SML notation 
\boxml{\#$i$}. Components are numbered from 0: the $i$th components of
a tuple of type $\tau_1\ast\ldots\ast\tau_n$ is accessed by
\boxml{\#$i$}, for $0\leq i\leq n-1$. 

The tuple constructor in $\Lam$ is written as in SML:
$$\boxml{(}e_1\boxml{,}\ldots\boxml{,}e_n\boxml{)}$$
However, the corresponding expression in $\RegExp$ and $\MulExp$ takes the form
$$\boxml{(}e_1\boxml{,}\ldots\boxml{,}e_n\boxml{) at}\rho$$
\index{at@{\tt at}}where $\rho$ is a \index{region variable}region variable indicating where the tuple should be put.
In the case $n=0$,  the $\at\rho$ is not printed, because the empty tuple is not
allocated: it is just a constant that fits in a \index{register}KAM register.

Records are evaluated left to right.

\section{Example: Basic Record Operations}
\label{proj.ex}
Consider the source program
\begin{verbatim}
       val xy = ((),()) 
       val x = #1 xy;
\end{verbatim}
Here is the resulting $\MulExp$ program:\footnote{Program
  \boxml{kitdemo/projection.sml}. Running programs is described in
  Section~\ref{tryit.sec}.}
\begin{verbatim}
   let val xy = ((), ()) at r1; val x = #0 xy
   in  {|xy: (_,r1), x: _|}
   end 
\end{verbatim}
There are several things to notice from this example. 
\begin{enumerate}
\item The $\MulExp$ program contain a free region variable
      {\tt r1}. Notice that the construction of the
      pair {\tt xy} has been annotated by ``{\tt at r1}'', indicating
      where the pair should be put;
%      Values of type unit are not
 %     stored in regions and hence the {\tt at}-annotations on the
 %     two occurrences of {\tt ()} are not printed.
\item The expression \verb+{|xy: (_,r1), x: _|}+ is
      an example of a \index{frame}{\em frame expression}. A frame enumerates
      the components that are exported from a compilation unit.
%      It is similar to a record, except that its components
%      are variables which are annotated with a type scheme and
%      a region variable. (In records, the components can only
%      have types, not general type schemes.) In the example,
%      the printing of the type schemes of {\tt v67} and {\tt v68}
 %     has been suppressed, so one only sees the region variables.
\end{enumerate}
\section{Region-Annotated Types}
\label{reganntypes.sec}
ML type inference infers a type for every expression in the program.
Region inference extends this idea by inferring for each expression a
\index{type!region-annotated}{\em region-annotated type}. The
region-annotated type of an expression is the ML type of the
expression decorated with extra region information.  In a
region-annotated type, every type constructor that represents boxed
values (e.g., pairs and strings) is paired with a region variable,
indicating where the value is to be put at runtime. Type constructors
that represents unboxed values (e.g., integers and booleans) are not
paired with a region variable.

The following are examples of region-annotated types
\begin{description}
\item[\fbox{$\boxml{unit}$}] The type of 0-tuples.   Integers, booleans, and 0-tuples are represented \index{boxing}unboxed
  at runtime (rather than being stored in regions).\footnote{To {\em
      box} a value means to store the value in memory and represent it
    by its address.  Values that are kept in registers are said to be
    {\em unboxed}.}
\item[\fbox{$(\boxml{string}, \rho)$}] The type of strings in region
  $\rho$.
\item[\fbox{$\bigl(\boxml{int} \ast (\boxml{string}, \rho_1), \rho_2\bigr)$}] Denotes
  pairs in $\rho_2$ whose first component is an integer and whose second
  component is a string in region $\rho_1$. 
\end{description}

%A pair of a region-annotated type and a region variable is called a
%``(region-annotated) type and place''.  We use $\mu$ to range over
%types and places\index{type and place}
%$$\mu::=(\tau,\rho)$$

One can get the Kit to print the region-annotated types it infers
for binding occurrences of variables. 
The above example then becomes
\begin{verbatim}
   let val xy:(unit*unit,r1) = ((), ()) at r1; val x:unit = #0 xy
   in  {|x: unit, xy: (unit*unit,r1)|}
   end 
\end{verbatim}

\section{Effects and {\tt letregion}}
\label{effects.sec}
Here is an example of an SML program that first creates a pair and
then selects a component of the pair, after which the pair is garbage:\footnote{Program \boxml{kitdemo/elimpair.sml}.}
\begin{verbatim}
     val n = let 
                val pair = if true then (3+4, 4+5) 
                           else (4, 5)
             in 
                #1 pair
             end;
\end{verbatim}
The Kit compiles the declaration into the 
$\MulExp$ program shown in Figure~\ref{elimpair.fig}.\footnote{
In general, the $\Lam$ optimiser performs various optimisations;
elimination of case analyses whose outcome are known statically
is not one of them.}
The compiler compiles the program as it is, without reducing the conditional
to its {\tt then} branch.
\begin{figure}
\hrule
\begin{verbatim}

   let val n = 
           letregion r7:1 
           in let val pair = 
                      (case true 
                         of true => (3 + 4, 4 + 5) at r7 
                       | false => (4, 5) at r7
                      ) (*case*) 
              in  #0 pair
              end  
           end
   in  {|n: _|}
   end 
\end{verbatim}
\caption{Region inference decides that the 
pair is to be allocated in a local, finite region; the region will be de-allocated
as soon as the pair becomes garbage.}
\medskip

\hrule
\label{elimpair.fig}
\end{figure}
During evaluation, a region (denoted by {\tt r7}) 
is introduced before the pair is allocated;
it remains on the region stack till the projection of the pair
has been computed, after which the region is de-allocated. 

The ``{\tt :1}'' on the binding occurrences of {\tt r7}
is a multiplicity indicating that there is only one store
operation into the region. (The \index{multiplicity analysis}multiplicity analysis
has discovered that there is at most one store from the {\tt then}
branch and at most one store from the {\tt else} branch and that
at most one of the branches will be chosen.) Thus, the pair will be
allocated in a little region on the runtime stack.

But how does the Kit know that it is safe to de-allocate {\tt r7}
where the \index{letregion@{\tt letregion}}{\tt letregion} ends?\index{region!de-allocation}

The answer lies in the fact that the Kit infers for every expression
not just a region-annotated type, but also a so-called \index{effect}{\em effect}. 
An effect is a finite set of \index{effect!atomic}
atomic effects. Two forms of atomic
effect are \index{put@{$\Put$}}$\Put(\rho)$ and \index{get@{$\Get$}}$\Get(\rho)$, where $\rho$ as usual ranges
over region variables. $\Put(\rho)$ indicates that a value is being stored in
region $\rho$ and $\Get(\rho)$ indicates that a value is being read from region $\rho$.
In our example, the region inference algorithm considers the sub-expression $e_0 = $
\begin{verbatim}
              let val pair = 
                      (case true 
                         of true => (3 + 4, 4 + 5) at r7 
                       | false => (4, 5) at r7
                      ) (*case*) 
              in  #0 pair
              end  \end{verbatim}
and finds that it has region-annotated type $\boxml{int}$ and effect
$\{\Put(\boxml{r7}), \Get(\boxml{r7})\}$.

Whenever a region variable occurs free in the effect of an expression but occurs
free neither in the region-annotated type of the expression nor in the type of any
program variable that occurs free in the expression then that region variable denotes
a region that is used only locally within the expression.  
That this is true is of course far from trivial, but it
has been proved for a skeletal version of $\RegExp$.  Consequently, 
when this condition is met, the region inference
algorithm wraps a \index{letregion@{\tt letregion}}{\tt letregion} binding of the region variable
around that expression.

In our example, there are no free variables in $e_0$; moreover, $\boxml{r7}$
occurs in the effect of $e_0$ but not in the region-annotated type of $e_0$. Thus,
the region inference algorithm inserts a {\tt letregion} binding of $\boxml{r7}$
around $e_0$.

\section{Runtime Representation}
A \index{record!runtime representation of}record with 0 components (the value of type \index{unit@{\tt unit}}{\tt unit}) 
is stored in a \index{register}KAM register, not in a region.
A record with $n$ components ($n\geq 2$) takes up precisely $n$ 32-bit words in a region;
the tuple is represented by the (32-bit) address of the first component of the tuple.
Notice that the Kit \index{boxing}boxes tuples.
However, records are not tagged. Avoiding tags is possible, because
(1) there is no pointer tracing garbage collection; and (2) 
\index{equality!polymorphic}polymorphic equality is 
compiled into \index{equality!monomorphic}monomorphic 
equality functions that do not have
to examine the type of objects at runtime. 
%Thanks to \index{K-normalisation}K-normalisation,

$\Lam$, $\RegExp$, and $\MulExp$ allow one to express unboxed tuples, 
also in the case of function calls and returns, but the Kit does not 
(yet) have a boxing analysis that exploits it, nor does the 
code generator generate code for unboxed tuples, multiple function arguments,
or multiple function return values.\index{record!unboxed}

A tuple is not allocated until its components have been evaluated.

\section{A First Session with the Kit}
\label{tryit.sec}
The Kit is a \index{batch compilation}batch compiler. Thus, executing a
program consists of first compiling the program and then running the
generated target program. Because the Kit stores files in the
directories where your source files are located you should make a
personal copy of these directories. Therefore, before you proceed, you
should make a personal copy of the {\tt kitdemo} directory, which is
part of the distribution.

The Kit provides two mechanisms for compiling programs. The first
mechanism allows you to compile a single SML source file whereas the
second mechanism allows you to compile and maintain projects, which
are collections of SML source files. To compile a single SML source
file or a project, you need an executable version of the Kit; let us
assume it is available on your system as a UNIX program called {\tt
  kit}.\footnote{The {\tt readme} file in the distribution tells you
  how to install the Kit.}  We shall postpone the discussion of howto
compile projects to Chapter~\ref{modules_and_projects.chap}.

\subsection{Compiling an SML Source File}
To compile the SML source file {\tt projection.sml} of
Example~\ref{proj.ex}, place yourself in the {\tt kitdemo} directory
(your personal copy of it, that is) and start the Kit with the shell
command {\tt kit}.

After the Kit has uttered various greetings, you will find yourself in
a rudimentary menu-driven dialogue, see Figure~\ref{dialogue.fig}.
\begin{figure}
\hrule
\begin{verbatim}

        0       Project.......................  >>>
        1       Printing of intermediate forms  >>>
        2       Layout........................  >>>
        3       Control.......................  >>>
        4       File..........................  >>>
        5       Profiling.....................  >>>
        6       Test environment..............  >>>
        7       Debug Kit.....................  >>>
        8       Compile an sml file...........  >>>
        9       Compile it again.............. ("dummy") >>>

Toggle line (t <number>), Activate line (a <number>), Up (u), or Quit(quit): 

>
\end{verbatim}
\caption{The top-most Kit menu}
\hrule
\label{dialogue.fig}
\end{figure}
First, you are going to ask the Kit to print one of the intermediate
forms that arise under compilation (this is how the annotated programs
shown in this section were obtained). 
Choose \texttt{Printing of intermediate forms} (i.e., type \texttt{1}
followed by carriage return), and then \texttt{print drop regions
expression} to toggle on the printing of the $\MulExp$ program.
Go up one level in the menu tree by typing \texttt{u} followed by return,
and you are back in the main menu.

Now, choose \texttt{Compile an sml file}; then type
\boxml{"projection.sml"} (including the quotes) followed by return.
The Kit outputs (among other things) the $\MulExp$ program shown in
Section~\ref{proj.ex}.

Go up one on the menu tree.  Printing of the region-annotated types
can now be enabled by selecting \boxml{Layout} from the main menu, and
then \texttt{print types}.  Thereafter, go back to the top-most menu
and choose \texttt{Compile it again} to compile the source file {\tt
  projection.sml} again. This time, the Kit outputs the $\MulExp$
program shown in Section~\ref{reganntypes.sec}.

Next, you can try the example in Section~\ref{effects.sec}; select
\texttt{Compile an sml file} from the top-most menu and enter
\boxml{"elimpair.sml"}.


\subsection{Running a Target Program}
If no errors were found during compilation, the Kit produces a
\index{target program}{\em target program} in the form of an
executable file, called {\tt run}. The Kit places {\tt run} in the
working directory.

Running the target program is done from the UNIX shell by typing \index{run@{\tt run}}
\begin{verbatim}
       run
\end{verbatim}
The file will probably be around 100Kb large, even for the trivial
examples considered in this chapter.  This is because it contains the
Kit runtime system and compiled code for the parts of the SML Basis
Library that are needed for linking.

Running the programs presented in this chapter is not particularly
exciting, because none of them produce output! However, as an
exercise, try executing the \index{hello world@{\tt hello world}}{\tt
  helloworld.sml} program, which, like all other example files in this
document, is located in the \index{kitdemo directory@{\tt kitdemo}
  directory}{\tt kitdemo} directory.


\chapter{Basic Values}
In this chapter, we describe how basic values such as integers, reals,
strings, and booleans are represented in the Kit. The Kit complies to
the Definition of Standard ML (Revised)\index{Standard ML!{1997
    revision}} and to large parts of the Standard ML Basis
Library;\footnote{See the Kit web site for a link to the Standard ML
  Basis Library.}\index{Standard ML!{Basis Library}} that is, as a
programmer, you can refer to components of the Standard ML Basis
Library through the {\em initial basis}\index{initial basis}, in which all programs are
compiled.  Throughout this chapter, we introduce some of the
top-level bindings that are provided by the initial basis.

\section{Integers}
\label{integers.sec}
Values of type \index{integer}{\tt int} are represented as 32 bit signed integers.
The following operations on integers are 
pre-defined at top-level:\index{{\tt =}}\index{{\tt <>}}\index{{\tt <}}\index{{\tt >}}\index{{\tt <=}}\index{{\tt >=}}\index{{\tt +}}\index{{\tt -}}\index{div@{\tt div}}\index{mod@{\tt mod}}\index{{\tt *}}\index{\verb+~+}\index{abs@{\tt abs}}
\begin{verbatim}
infix  4 = <> < > <= >= 
infix  6 + - 
infix  7 div mod  * 
val ~ :  int -> int
val abs: int -> int
\end{verbatim}
Many other useful operations on integers are available in the {\tt
  Int} structure.\footnote{To see what operations are available in the
  {\tt Int} structure, consult the file {\tt
    kit/basislib/INTEGER.sml}.}

At runtime, integers are represented without any form of boxing or tagging, so
all 32 bits are available. 

\section{Reals}
The initial basis\index{initial basis} provides the following operations on reals:
\index{{\tt =}}\index{{\tt <>}}\index{{\tt <}}\index{{\tt >}}\index{{\tt <=}}\index{{\tt >=}}\index{{\tt +}}\index{{\tt -}}\index{{\tt *}}\index{{\tt /}}\index{\verb+~+}\index{abs@{\tt abs}}\index{real@{\tt real}}\index{trunc@{\tt trunc}}\index{floor@{\tt floor}}\index{ceil@{\tt ceil}}\index{round@{\tt round}}
\begin{verbatim}
infix  4 = <> < > <= >= 
infix  6 + - 
infix  7  * /
val ~ : real -> real
val abs: real -> real
val real: int -> real
val trunc : real -> int
val floor : real -> int
val ceil : real -> int
val round : real -> int
\end{verbatim}
Values of type {\tt real} are implemented as 64 bit floating point
numbers.  They are always boxed, that is, represented as a pointer to
two consecutive 32 bit \index{alignment}words.  These two words reside
in a region and start on a double-aligned address. For this reason,
regions with \index{runtime type}runtime type {\tt real} (see
Section~\ref{runtimetypes.sec}) are never unified with regions of any
other runtime type.

A real constant $c$ in the source program is translated into an
expression of the form \index{at@{\tt at}}$c\at\rho$, where $\rho$ is
a region variable, indicating the region into which the real will be
stored.

The structures {\tt Real} and {\tt Math} provide other useful
operations on reals.

\section{Characters and Strings}
The initial basis\index{initial basis} provides the following top-level operations on characters and strings:\index{{\tt =}}\index{\verb+^+}\index{ord@{\tt ord}}\index{chr@{\tt chr}}\index{str@{\tt str}}\index{size@{\tt size}}\index{explode@{\tt explode}}\index{implode@{\tt implode}}\index{concat@{\tt concat}}\index{substring@{\tt substring}}
\begin{verbatim}
infix  4 = 
infix  6 ^
val ord: char -> int
val chr: int -> char
val str: char -> string
val size: string -> int
val explode: string -> char list
val implode: char list -> string
val ^ : string * string -> string
val concat: string list -> string
val substring: string * int * int -> string
\end{verbatim}
Characters are represented as 32 bit words, although only 8 bits are
used to store the character. Just like integers, characters are
unboxed and untagged.

A string is represented by a 32 bit pointer into an infinite region.
The string is stored in consecutive bytes in the region, except if the
size of the string exceeds the length of one region page, in which
case the string is split into smaller strings which are linked
together. The internal string representation is completely transparent
to the programmer, who does not have to worry about the actual size of
region pages. Characters of a string takes up only 8 bits of
memory each.

Calls of {\tt ord}, {\tt chr}, {\tt str}, and {\tt size} take constant
time and space.  Calls of {\tt explode}, {\tt implode}, {tt concat},
{\tt substring}, and \verb+^+ take time and space proportional to the
sum of the size of their input and their output.

The string and character operations can raise exceptions, as detailed in the
Standard ML Basis Library documentation.

The structures {\tt Char} and {\tt String} provide other useful
operations on characters and strings.

\section{Booleans}
The boolean values {\tt true} and {\tt false} are represented as 32
bit words, although only one bit is used to denote the value. Booleans
are unboxed. The initial basis\index{initial basis} provides the following top-level
operations on booleans:\index{{\tt =}}\index{not@{\tt not}}
\begin{verbatim}
infix 4 =
val not: bool -> bool
\end{verbatim}
The structure {\tt Bool} provides other useful operations on booleans.

%
\chapter{Lists}
\label{lists.sec}\index{list}
%
Section~\ref{lsyn.sec} gives
a summary of the list concept in Standard ML, introduces
the notion of the {\em auxilary pairs} of a list and presents the
syntax of constructors and destructors in the intermediate languages.
Section~\ref{listtypes.sec} introduces region-annotated list types and
show how they correspond to the layout of lists in memory. 
Section~\ref{listexamples.sec} gives a small example.
\section{Syntax}
\label{lsyn.sec}
In Standard ML, all lists are constructed 
from the two constructors \index{::@{\tt ::}}\boxml{::} (read: cons)
and \index{nil@{\tt nil}}{\tt nil}.   
As a shorthand, one can write $\boxml{[}\exp_1\boxml{,}\cdots
\boxml{,}\exp_n\boxml{]}$ for
$$ \exp_1\boxml{::}\; \cdots\; \boxml{::} \exp_n\boxml{::}\boxml{nil}$$
which in turn is short for
$$ \boxml{op ::($\exp_1$, $\cdots$, op ::($\exp_n$,nil)$\cdots$)}$$
where $\exp$ ranges over expressions. 
The type schemes of {\tt nil} and {\tt cons} are
$$\boxml{nil}\mapsto\forall\alpha.\alpha\boxml{list}\qquad
  \boxml{::} \mapsto\forall\alpha.\alpha\ast\alpha\boxml{list}\to\alpha\boxml{list}
$$
In particular, notice that {\tt ::} is always applied to a pair. The construction
of the pair and the application of {\tt ::} should not be confused: the pair and the
constructed value are separate values.
For example, the declaration
\begin{verbatim}
       val p = (2, nil)
       val mylist = (op ::) p
       val n = #1 p
\end{verbatim}
is legal in Standard ML. We refer to the pairs to which {\tt ::} is applied
as \index{pair!auxiliary}{\em auxiliary pairs (of the list data type)}.

Decomposition of list values in Standard ML is done by \index{pattern matching}pattern matching.
A pattern can extract the pair to which {\tt ::} is applied. Pattern matching
on pairs can then give access to the components of the pair. 
\begin{verbatim}
  val abc = ["a", "b", "c"]
  val op :: p = abc (* binds p to the pair ("a", ["b","c"]) *)
  val (x::y::_) = abc  (* binds x to "a" and y to "b" *)
\end{verbatim}
In the last declaration, the pattern \boxml{(x::y::\_)} is short for the pattern
$$\boxml{(op ::(x, op ::(y, \_)))}$$ which combines decomposition of constructed
values with decomposition of pairs.

The intermediate languages 
$\Lam$, $\RegExp$, and $\MulExp$ have SML-like constructs for applying constructors, but
they decompose constructed values  
by applying a \index{decon@{\tt decon}}deconstructor primitive,
not by pattern matching.\index{at@{\tt at}}
\begin{center}
\begin{tabular}{|c|c|}\hline
$\Lam$, $\RegExp$, or $\MulExp$ & \\ \hline
\boxml{nil}   &  create {\tt nil} value \\
$\boxml{::}\,(e)$ & create {\tt ::} (cons) value \\
$\boxml{decon\_::}\,(e)$ & cons decomposition \\
\hline
\end{tabular}
\end{center}
In $\Lam$, which has essentially the same type system as SML,
 $\boxml{decon\_::}$, the decomposition function for {\tt ::}, has 
type $\forall\alpha.\alpha\boxml{list}\to\alpha\ast\alpha\boxml{list}$.
In addition, $\Lam$, $\RegExp$, and $\MulExp$ have a simple case construct:
$$\boxml{(case $e$ of :: => $e_1$ | \_ => $e_2$)}$$
where $e$ must have list type. 

Only the auxiliary pairs of a list (and perhaps the elements) are
allocated in regions at runtime; the list constructors {\tt nil} and
{\tt ::} are represented unboxed as 32 bit words, using the least
significant bit to distinguish {\tt nil} from {\tt ::} (a pointer to
an auxiliary pair of the list).

\section{Region-Annotated List Types}
\label{listtypes.sec}
In Standard ML, all elements of a given list must have the same type.
We extend this constraint to region inference by saying that all
element values in the same list must reside in the same region(s) and that all
auxiliary pairs of the same list must reside in the same region.
\begin{figure}
\hrule

\begin{center}
\begin{picture}(75,35)(0,0)
\put(0,0){\framebox(30,10){\boxml{"a"}}}
\put(0,10){\framebox(30,10){\boxml{"b"}}}
\put(0,20){\framebox(30,10){\boxml{"c"}}}
%
\put(40,0){\framebox(30,10){$(\qquad,\boxml{nil})$}}
\put(40,10){\framebox(30,10){$(\qquad,\boxml{::})$}}
\put(40,20){\framebox(30,10){$(\qquad,\boxml{::})$}}
%
\put(50,5){\vector(-1,1){20}}
\put(50,15){\vector(-1,0){20}}
\put(50,25){\vector(-1,-1){20}}
%
\put(60,15){\line(3,0){15}}
\put(60,25){\line(3,0){15}}
%
\put(75,15){\line(0,-1){7}}
\put(75,25){\line(0,-1){7}}
%
\put(75,18){\vector(-1,0){5}}
\put(75,8){\vector(-1,0){5}}
%
\put(15,-5){\hbox{$\rho_1$}}
\put(55,-5){\hbox{$\rho_2$}}
\end{picture}
\end{center}
\caption{Layout of the list 
$\boxml{["a","b","c"]}:((\boxml{string},\rho_1),[\rho_2])\boxml{list}$
in memory. The auxiliary pairs of the list reside in $\rho_2$.
Each auxiliary pair takes up two words; the constructors {\tt ::} (cons) and {\tt nil} are represented unboxed.}
\medskip

\hrule
\label{listregions.fig}
\end{figure}


Thus, region inference does not distinguish between a list and its
tail.  Indeed, a typical use of an infinite region is to hold all the
auxiliary pairs of a list.\index{type!region-annotated} For an
example, Figure~\ref{listregions.fig} shows how the list
\boxml{["a","b","c"]} is laid out in memory.

In general, the region-annotated type of a list takes the form
$$(\tau,[\rho])\boxml{list}$$
where $\tau$ is the region-annotated
type of the members of the list and where $\rho$ is the region where
the auxiliary pairs of the list are stored.  For example, the region-annotated type
$$((\boxml{string},\rho_1),[\rho_2])\boxml{list}$$
classifies lists
that have their auxiliary pairs in a region $\rho_2$ and strings in a region
$\rho_1$.

Not all lists need to live in the same regions!
Formally, {\tt nil} and {\tt ::} have the following region-annotated types:
\begin{eqnarray*}
\boxml{nil} & \mapsto & \forall\alpha\rho.(\alpha,[\rho])\boxml{list}\\
\boxml{::}  & \mapsto & \forall\alpha\rho\epsilon.(\alpha\ast(\alpha,[\rho])\boxml{list},\rho)
\ar{\epsilon.\emptyset} (\alpha,[\rho])\boxml{list}
\end{eqnarray*}
Despite its verbosity, 
the type scheme for {\tt ::} deserves careful study. It is polymorphic not just in types
(signified by the bound type variable $\alpha$) but also in regions (signified by the 
bound region variable $\rho$). The $\epsilon$ is a so-called \index{effect variable}{\em effect variable}. 
The $\epsilon.\emptyset$ appearing on the function arrow is called an \index{arrow effect}{\em arrow effect}.
Occurring in a function type, an arrow effect describes the effect of applying the function.
In this case, the effect is empty, as only unboxed values are manipulated by {\tt ::}. The effect variable $\epsilon$ 
is used for expressing dependencies between effects (examples follow in Chapter~\ref{hof.sec}). Due to the fact that 
the variables are universally quantified, every occurrence of a list can, potentially, be in its own regions. But notice 
that the type of {\tt ::} forces the element, which is consed onto the list, to be in the same regions 
as the already existing elements of the list. Similarly, the type forces the auxiliary pairs to be in
one region ($\rho$).

\section{Example: Basic List Operations}
\label{listexamples.sec}
The Kit compiles the program\footnote{Program \texttt{kitdemo/onetwothree.sml}.}  
\begin{verbatim}
       let val l = [1, 2, 3];
           val (x::_) = l
       in x end;
\end{verbatim}       
into the $\RegExp$ program shown in Figure~\ref{listprint.fig}.
\begin{figure}
\hrule
\begin{verbatim}

   let val it = 
           letregion r7:INF 
           in let val l = 
                      let val v40150 = 
                              (1, 
                               let val v40151 = 
                                       (2, 
                                        let val v40152 = 
                                                (3, nil) at r7 
                                        in :: v40152 
                                        end 
                                       ) at r7
                               in  :: v40151
                               end 
                              ) at r7
                      in  :: v40150
                      end 
              in  (case l 
                     of :: => #0 decon_:: l 
                      | _ => raise Bind
                  ) (*case*) 
              end  
           end (*r7:INF*)
   in  {|it: _|}
   end 
\end{verbatim}
\caption{Example showing construction and deconstruction of a small list.
Layout of the list {\tt l} is analogous to Figure~\ref{listregions.fig}.
The infinite region {\tt r7} holds the auxiliary pairs of the list.
}
\label{listprint.fig}
\medskip

\hrule
\end{figure}

\chapter{First-Order Functions}
In this chapter we shall treat \index{function}\index{function!first-order}functions which are declared with
\index{fun@{\tt fun}}{\tt fun} and which are first-order (i.e., they neither take functions
as arguments nor produce functions as results). Higher-order functions
are treated in Chapter~\ref{hof.sec}.
Region polymorphism works uniformly over all types; 
we use lists as an example of the general scheme. 
\section{Region-Polymorphic Functions}
\index{region polymorphism|(}It would be a serious limitation if 
all lists produced by a function were stored
in the same region, for then all those lists would have to be kept
alive till the last time one of them were used. The solution which the Kit
offers to this problem is {\em region-polymorphic functions}, i.e., functions
which are passed regions at runtime. 

When one declares a function which, when called, produces
a fresh list, the region inference algorithm will automatically insert extra
\index{region parameter!formal}formal region parameters in the function declaration.
At every place one refers to the function, for example because one calls the function,
the region inference algorithm inserts
a list of \index{region parameter!actual}actual region parameters thus telling the function where to put its
result. This is all done automatically: the user does not have to introduce
region parameters or pass them as arguments. But it is useful to understand
the general principle so that one can exploit the feature fully.

The syntax of a (single) function declaration in $\MulExp$ is:
\begin{tabbing}
\ \ \ \ \ \=\tt fun $f$ at $\rho_0$ [$\rho_1$, $\cdots$, $\rho_k$] $x$ = $e$
\end{tabbing}
Here $\rho_0$ denotes the region in which the closure for $f$ is stored,
$\rho_1, \ldots,\rho_k$ are 
the \index{region parameter!formal}{\em formal region parameters}, $x$ is the
value parameter (a single variable) and $e$ is the body of the function.
A call to $f$ takes the form
\begin{tabbing}
\ \ \ \ \ \=\tt $f$  [$\rho_1'$, $\cdots$, $\rho_k'$] at $\rho_0'$ $e'$
\end{tabbing}
where \boxml{[$\rho_1'$, $\cdots$, $\rho_k'$]} is a record of \index{region parameter!actual}{\em actual region parameters},
$\rho_0'$ is the region where this record is stored, and $e'$ is an expression
denoting the argument to the call. Note that region parameters are enclosed in angle brackets
(\boxml{[ ]}); this should not cause confusion with ML lists, since $\RegExp$ and $\MulExp$
do not use the angle brackets for lists.

Different calls of $f$ can use different actual regions,
and this is essential for obtaining good separation of lifetimes.

For an example, consider\footnote{Project: \boxml{kitdemo/fromto.pm},
file \boxml{kitdemo/fromto.sml}.}
\begin{verbatim}
       fun fromto(a, b) = if a>b then []
                          else a :: fromto(a+1, b)
       val l = #1(fromto(1,10), fromto(100,110));
\end{verbatim}
The corresponding $\MulExp$-program is shown in Figure~\ref{fromto.fig}.
\begin{figure}
\hrule
\begin{verbatim}

   let fun fromto at r1 [r7:INF, r8:INF] (var263)= 
               let val a = #0 var263; val b = #1 var263
               in  (case a > b 
                      of true => nil at r7
                      |  false => 
                         let val v2725 = 
                                 (a, 
                                  letregion r13:1, 
                                            r15:1 
                                  in fromto[r7,r8] at r13 
                                     (a + 1, 
                                      b
                                     ) at r15 
                                  end
                                 ) at r8
                         in  :: at r7 v2725
                         end 
                   ) (*case*) 
               end ; 
       val l = 
           let val v2737 = 
                   letregion r17:1, r19:1 
                   in fromto[r1,r1] at r17 
                      (1, 10) at r19 
                   end
               val _not_used = 
                   letregion r20:INF, r21:INF 
                   in let val v2738 = 
                              letregion r22:1, r24:1 
                              in fromto[r20,r21] at r22 
                                 (100, 110) at r24 
                              end
                      in  ()
                      end  
                   end
           in  v2737
           end 
   in  {|fromto: (_,r1), pair: (_,r1)|}
   end 
\end{verbatim}
\caption{The region-annotated version of {\tt fromto} shows that {\tt fromto}
is region-polymorphic.}
\medskip

\hrule
\label{fromto.fig}
\end{figure}
Note that \boxml{r7} and \boxml{r8} are formal regions of {\tt fromto}.\index{fromto@{\tt fromto}}
In the last call of {\tt fromto}, a record consisting
of region descriptors for \boxml{r20} and \boxml{r21} are passed to {\tt fromto};
the region record is stored in {\tt r22}. Note that the regions that hold
the two lists generated by this program are disjoint. The reason that \boxml{r1} is
passed twice to \boxml{fromto} in the call \boxml{fromto[at r1,at r1] at r17 (1, 10) at r19}
is that, for reasons to do with separate compilation, the Kit only has one region
for global values that 
are not of runtime type {\tt string}, 
{\tt real} or {\tt word}. Thus \boxml{r1} holds
both the pairs and the spine of the first list. In the second list, which does not escape to
top level, the pairs and the spine are kept separate, in \boxml{r21} and \boxml{r20}, 
respectively.
\section{Region Type Schemes}
\label{regtych.sec}
A \index{type scheme!region polymorphic}{\em region-polymorphic 
type scheme} takes the form
$$\sigma::=\lsigma$$
where $\alpha_1,\ldots,\alpha_n$ are type variables,
$\rho_1,\ldots,\rho_k$ are region variables,
$\epsilon_1,\ldots,\epsilon_m$ are effect variables
and $\tau$ is a region-annotated type.

The types of \boxml{nil} and \boxml{::} in Section~\ref{listtypes.sec} are examples of 
region-polymorphic type schemes. \index{region polymorphism}

There is a close connection between, on the one hand, the formal and
actual \index{region parameter}region parameters found in $\RegExp$
(and $\MulExp$) programs, and, on the other hand, the \index{region
type scheme}region type schemes which the region inference algorithm
assigns to recursively declared functions. The formal region
parameters of a function stem from the bound region variables of the
region type scheme of that function.  The actual region parameters which
annotate a call of the function are the region variables to which the bound
region variables are instantiated at that particular application.

For example, the region type scheme of {\tt fromto} from Figure~\ref{fromto.fig} is
\begin{eqnarray*}
&&\forall\rho_7\rho_8\rho_6\epsilon.((\boxml{int},\rho_2)\ast(\boxml{int},\rho_2),\rho_6)\ar{\epsilon.\{
\Get(\rho_2),\Put(\rho_2),\Get(\rho_6),\Put(\rho_7),\Put(\rho_8)\}}\\
&&\qquad (((\boxml{int},\rho_2)[\rho_8])\boxml{list},\rho_7)
\end{eqnarray*}
At the last call of {\tt fromto} in Figure~\ref{fromto.fig},
the type scheme is instantiated to the type and place
\begin{eqnarray*}
&&((\boxml{int},\rho_2)\ast(\boxml{int},\rho_2),\rho_{24})\ar{\epsilon'.\{
\Get(\rho_2),\Put(\rho_2),\Get(\rho_{24}),\Put(\rho_{20}),\Put(\rho_{21})\}}\\
&&\qquad (((\boxml{int},\rho_2)[\rho_{21}])\boxml{list},\rho_{20})
\end{eqnarray*}
The instantiation of bound variables of the type scheme which achieves this is
$$\{\rho_7\mapsto\rho_{20}, \rho_8\mapsto\rho_{21}, \rho_6\mapsto\rho_{24}, \epsilon\mapsto\epsilon'\}$$
In general, the actual region parameters annotating a call of a region-polymorphic function are obtained from
the range of the substitution by which the type scheme of the function is  instantiated at that
application.

To avoid passing regions that are never used, the Kit only introduces 
formal region variables for those bound region variables in the type scheme
for which there appears at least one \index{put@{$\Put$}}$\Put$ effect in the type of the function.
Reading a value is done simply by following a pointer to the value, irrespective
of which region the value resides in, whereas storing a value in a region uses the
name (Section~\ref{fininf.sec}) of the region.
This explains why  $\rho_6$ does not become a formal region parameter and why
$\rho_{24}$ is not passed to {\tt fromto} at the call site. This optimisation,
which is called \index{region!dropping of}{\em dropping of regions}, is
the key reason why the Kit takes the trouble to distinguish
between $\Put$ and \index{get@{$\Get$}}$\Get$ effects\label{bother-to-distinguish-get-n-put}.

\index{region type and place}\index{region type scheme and place} 
Region-polymorphic functions also have to be allocated somewhere.
Therefore, the region information associated with a region-polymorphic
function is a {\em region type scheme and place}, i.e., a pair
$(\sigma,\rho)$.  Indeed every binding occurrence of a variable
(whether the binding is done by {\tt fun}, {\tt let} or {\tt fn})
associates a region type scheme and place with the binding occurrence.
(In the case of {\tt let}, the type scheme will have no quantified
region and effect variables, however, and in the case of {\tt fn}, the
type scheme will have no quantified variables at all.) In the
following, when we refer to ``the region type (scheme) and place'' of
some variable, we mean the region type (scheme) and place which is
associated with the binding occurrence of the variable. The region
type scheme should be clearly distinguished from instances of the type
scheme which decorate non-binding occurrences of the variable.

\section{Endomorphisms and Exomorphisms}
The {\tt fromto} function from Section~\ref{regtych.sec} has the property that
it can put its result in regions that are separate from the regions where its
argument lies. This is not surprising, if one looks at the declaration of the
function: it creates a brand new list which does not share with the argument
$(a,b)$, except for the integers $a$ and $b$ which may end up in the list.
The freshness of the generated list is also evident from the region type scheme
of the function: different region variables are used for the argument and the result.

Not all region-polymorphic functions create brand new values. Very often, a
region-polymorphic function simply adds values to regions which are determined
by the argument to the function. A good example is the list append function
from the prelude:
\begin{verbatim}
       infixr 5 @
       fun [] @ ys = ys
         | (x::xs) @ ys = x :: (xs @ ys)
\end{verbatim}
Append successively conses the elements of the first list onto the second list.
Thus \boxml{ys} and \boxml{xs @ ys} must be in the same regions. However,
 \boxml{xs} and \boxml{ys} need not be in the same regions, although
the elements of \boxml{xs} and \boxml{ys} clearly must be in the same regions,
since they end up in the same list. These properties of append are summarised
in the inferred region type scheme:
\begin{eqnarray*}
&&\forall\alpha\rho_1\rho_2\rho_3\rho_1'\rho_2'\rho_4\epsilon.
   ( (((\alpha,\rho_3),[\rho_2])\boxml{list},\rho_1)\ast
      (((\alpha,\rho_3),[\rho_2'])\boxml{list},\rho_1'), \rho_4) \\
&&       \ar{\epsilon.\{\Get(\rho_4),\Get(\rho_1),\Get(\rho_2),\Put(\rho_1'),\Put(\rho_2')\}}\\
&&\quad(((\alpha,\rho_3),[\rho_2'])\boxml{list},\rho_1')
\end{eqnarray*}
One of the key things one needs to be conscious of when programming
with regions is whether one want functions to create fresh values or
whether one wants to add to existing regions. Adding to existing
regions can of course make these regions too large and long-lived,
since the entire region will be alive for as long as one of the values
in the region may be needed in the future. Here are two more examples
to highlight the difference between functions that can put values in
fresh regions and functions that add values to existing regions:
\begin{verbatim}
       fun cp1 [] = []   
         | cp1 (x::xs) = x :: cp1 xs
       fun cp2 (l as []) = l
         | cp2 (x::xs) = x :: cp2 xs
\end{verbatim}
Here \boxml{cp1} can copy a list into fresh regions, whereas \boxml{cp2} always
copies a list into the same region:
\begin{eqnarray*}
\boxml{cp1}&\mapsto&\forall\alpha\rho_1\rho_2\rho_3\rho_2'\rho_3'\epsilon.
     ((\alpha,\rho_3),[\rho_2])\boxml{list},\rho_1)\ar{\epsilon.\{\Get(\rho_1),\Get(\rho_2),
           \Put(\rho_1'),\Put(\rho_2')\}}\\
&&\quad((\alpha,\rho_3),[\rho_2'])\boxml{list},\rho_1')\\
\boxml{cp2}&\mapsto&\forall\alpha\rho_1\rho_2\epsilon.
     ((\alpha,\rho_3),[\rho_2])\boxml{list},\rho_1)\ar{\epsilon.\{\Get(\rho_1),\Get(\rho_2),
           \Put(\rho_1),\Put(\rho_2)\}}\\
&&\quad((\alpha,\rho_3),[\rho_2])\boxml{list},\rho_1)
\end{eqnarray*}
As we saw in Section~\ref{life.sec}, there are cases where it is useful to copy a list from one region into another region,
in order to make it possible to de-allocate the old region. This copying can be used
as a kind of programmer-controlled garbage collection in cases where garbage has accumulated
in the original region. 

Since it is often useful to distinguish between functions that can
put their result into fresh regions and functions that simply add to
regions determined by their value argument, we shall refer informally
to the former functions as \index{region exomorphism}{\em region
  exomorphisms} and the latter as \index{region endomorphism}{\em
  region endomorphisms}. Note that this is not a clear-cut 
distinction, however. Often, functions have both an endomorphic and an
exomorphic side to them. Also note that even a region exomorphic
function can be forced to act as an endomorphism by the calling
context. Example:
$$\boxml{if true then cp1 l else l}$$
Since the two branches of the conditional are required to have the same region-annotated
type, \boxml{l} and \boxml{cp1 l} are forced to be in the same regions.
%
\section{Polymorphic Recursion}
%
\label{polyrec.sec}
A recursive region-polymorphic function\index{recursion!polymorphic}
\begin{tabbing}
\ \ \ \ \ \=\tt fun $f$ at $\rho_0$ [$\rho_1$, $\cdots$, $\rho_k$] $x$ = $e$
\end{tabbing}
may call itself inside its own body ($e$) with regions that are different
from its own formal region parameter ({\tt [$\rho_1$, $\cdots$, $\rho_k$]}).
This feature is called {\it polymorphic recursion in regions}, named after
polymorphic recursion, the analogous concept for types.
Polymorphic recursion in regions is vital for achieving good recursion.
It is also a major source of  complication of the region inference algorithm
we use in the Kit, but we shall not tire the reader with the details here.

We now show a typical use of polymorphic recursion in regions, namely
merge sorting of lists. The basic idea of merge sort is simple: first
split the input list into two lists $l$ and $r$ of roughly equal length.
Then sort $l$ and $r$ recursively and merge the results into a single sorted
list.  When programming with regions, we need to plan which of these lists
we want to reside in the same regions. We do not want to waste space. In particular,
if $n$ is the length of the list, it would be quite irresponsible
to use $O(n\hbox{log}\,n)$ space, say.  
Let us aim at arranging that the sorting function is a 
region exomorphism which does not produce any values in its result regions
except the sorted list. To sort $n$ elements we shall need $n$ list cells 
(to hold the input list) plus roughly $2\times(n/2)$ list cells
to hold $l$ and $r$, the two lists that arise from splitting the input list. To sort $l$ recursively, we need space for the two
lists obtained by splitting $l$ etc. This grows to a maximum of $3n$ list cells
(including the $n$ cells to hold the input), before any merging is done.
By the time all of $l$ is sorted, i.e., just before $r$ is sorted recursively,
we have the following lists: the input 
($n$ cells), $l$ ($n/2$ cells), $l$ sorted ($n/2$ cells),
$r$ ($n/2$ cells). Continuing this way, one sees that the maximal memory
usage occurs at the rightmost merge to two lists of length at most one, at
which point approximately $4n$ list cells are live. Here is code which
uses these ideas:\index{cp@{\tt cp}}\index{msort@{\tt msort}}\index{merge sort}
\pagebreak

\begin{verbatim}
       fun cp [] =[]
         | cp (x::xs)= x :: cp xs

       (* exomorphic merge *)
       fun merge(xs, []):int list = cp xs
         | merge([], ys) = cp ys
         | merge(l1 as x::xs, l2 as y::ys) = 
               if x<y then x :: merge(xs, l2) 
               else y :: merge(l1, ys)

       (* splitting a list *)
       fun split(x::y::zs, l, r) = split(zs, x::l, y::r)
         | split([x], l, r) = (x::l, r)
         | split([], l, r) = (l, r)

       (* exomorphic merge sort *)
       fun msort []  = []
         | msort [x] = [x]
         | msort xs = let val (l, r) = split(xs, [], [])
                      in merge(msort l, msort r)
                      end;
\end{verbatim}
The exomorphic merge function is a bit inefficient in that it copies
one argument when the other is empty, but the exomorphism ensures that
$\boxml{msort l}$ and $\boxml{msort r}$ are not forced into the same
regions. The polymorphic recursion in regions makes it possible for
\boxml{xs}, \boxml{l}, \boxml{r}, \boxml{msort l} and \boxml{msort r}
all to be in distinct regions. For example, in the call \boxml{msort
  l}, the polymorphic recursion makes it possible for \boxml{l} to be
in regions different from \boxml{xs} and it also makes it possible for
the result of the call to be in a region different from the result of
\boxml{msort xs}.

Based on the above analysis we conclude that the space required by
\boxml{msort xs} is approximately $4nc_1+c_2{\rm log}_2n$, where $n$ is 
the length of \boxml{xs}, $c_1$ is the size of a list cell (4 words in this
case) and $c_2$ is the space on the runtime stack used by one recursive call
of {\tt msort} (probably less than 10 words). 

To check the above analysis, we sorted 50,000 integers with the region profiler
enabled. According to our
analysis, the maximal space usage should be roughly $4\times 50,000 \times 4$
words, i.e., 3,200,000 bytes, i.e,  $3.125MB$. 
As one sees in  Figure~\ref{msort.fig}, the analysis was accurate to within a
kilobyte. 

\begin{figure}[t]
\vbox{
\hskip-1cm{{\includegraphics{msort.ps}}}
}
\caption{Region profiling of {\tt msort} sorting 50,000
integers. The high-level mark of 3,201,016 bytes is exact (i.e., not sampled).}
\label{msort.fig}
\end{figure}

In Chapter~\ref{storagemodes.sec} we shall see how one can use resetting of
regions to reduce the space usage to roughly $2nc_1$.

The project {\tt kitdemo/msort.pm} contains the above declarations. 
After compiling the project, the region-annotated code may be found
in the file\linebreak {\tt kitdemo/msort.log}.
\index{region polymorphism|)}
%
\chapter{Value Declarations}
%
\label{valdecl.sec}
Although region inference is based on types and effects, it is also
to some extent syntax dependent: two programs can easily be equivalent
in their input-output behaviour and yet result in very different memory
behaviour. In this chapter we discuss how to write 
\index{declaration!of value}declarations in order
to obtain good results with region inference. The region inference rules
that underlie the ML Kit with Regions are related to the scope rules of
ML, so we start by a (very informal) summary of the scope rules of ML declarations.
\section{Syntax}
A Standard ML  {\em value declaration} binds a value 
to a value \index{scope rules|(}variable. For example, the result of evaluating the value declaration
\begin{verbatim}
       val x = 3+4
\end{verbatim}
is the \index{environment}environment $\{\boxml{x}\mapsto 7\}$. More generally,
evaluation of a value binding \boxml{val $\id$ = $\exp$} proceeds
as follows. Assume the result of evaluating $\exp$ is a value, $v$.
Then the result of evaluating \boxml{val $\id$ = $\exp$} is the
environment $\{\id\mapsto v\}$.

The value declaration is just one form of Core Language declaration 
(the others being type and exception declarations). We use $\dec$ to
range over declarations. Declarations can be
combined in several ways. For example, \index{declaration!sequential}
$$\dec_1\boxml{;}\dec_2$$
is a {\em sequential declaration}. The identifiers declared by this
declaration are the identifiers that are declared by $\dec_1$ or $\dec_2$;
moreover, identifiers declared in $\dec_1$ may be referenced in $\dec_2$.
The \index{;@{\tt ;}}semicolon is associative. Thus in a sequence 
$\dec_1\boxml{;}\ldots\boxml{;}\dec_n$
of declarations, identifiers declared in 
$\dec_i$ may be referenced in $\dec_{i+1},\ldots
,\dec_n$ ($1\leq i\leq n$). 

The Core Language has two forms of \index{declaration!local}\index{let@{\tt let}}local declarations. The
expression 
$$\boxml{let $\dec$ in $\exp$ end}$$
declares identifiers whose scope does not extend beyond $\exp$. Similarly,
the declaration\index{local@{\tt local}}
$$\boxml{local $\dec_1$ in $\dec_2$ end}$$
first declares identifiers (in $\dec_1$) whose scope does not extend beyond
$\dec_2$ and it then uses these declarations to perform the declaration in
$\dec_2$. An identifier is declared by the entire local construct if and only
if it is declared by $\dec_2$.

\section{On the Relationship between Scope and Lifetime}
\label{scope.sec}
Scope  \index{lifetime|(}is  a syntactic concept: a declaration
of an identifier contains a binding occurrence of the identifier; the scope of
the declaration is the part of the ensuing program text whose free occurrences
of that identifier are bound by that binding occurrence. By contrast, lifetime,
as we use the word, is a dynamic concept. A value is ``live'' if and only if the remainder of the
computation uses it (or part of it). The traditional \index{stack}stack discipline
couples these two concepts very closely. For example, in the pure stack
discipline, the evaluation of 
$$\boxml{let $\dec$ in $\exp$ end}$$
in an environment $E$
proceeds as follows. First evaluate $\dec$, yielding an environment,
$E_1$. Then evaluate $\exp$ in the environment $E$ extended with $E_1$, yielding
value $v$. Then $v$ is the result of evaluating the {\tt let}-expression in
$E$. In implementation terms: first push an environment $E_1$ onto the stack,
use it to evaluate the expression in the scope of the declaration and then
pop the stack. That this idea works in \index{block structure}block-structured languages hinges
on a number of carefully made language design decisions. In functional and
object-oriented languages, memory cannot be managed that simply. The problem
is that while environments can be managed in a stack-like manner, the
values in the range of the environment cannot (unless one uses regions, that is). 
For example consider the ML expression:

\vbox{
\begin{verbatim}
       local
          val private = [2,3,5,7,11,13]
       in
          fun smallPrime(n:int): bool = 
                 List.member n private
       end
\end{verbatim}
}

Although the scope of the declaration is only the declaration of \index{smallPrime@{\tt smallPrime}}{\tt smallPrime},
{\tt private} is accessed (at runtime) whenever {\tt smallPrime} is called.
Thus the lifetime of the list of small primes is at least as long as the
lifetime of the {\tt smallPrime} function itself.

The region discipline still has a coupling between scope and lifetimes,
but, since we want to be able to handle recursive data types and higher-order
functions, the coupling is less tight. 
The ground rule of region inference\index{region inference!ground rule}\index{letregion@{\tt letregion}}
is that as long as a value variable $\id$ is in scope, the value bound to it
at runtime will remain allocated. More precisely:
\begin{quote}
       Ground Rule: The region rules forbid transforming an expression
       $\exp$ into \boxml{letregion $\rho$ in $\exp$ end} if $\exp$ is
       in the scope of an identifier which has $\rho$ free in its region type
       scheme or place.
\end{quote}
For an example, consider
\begin{verbatim}
       let 
          val list = [1,2,3]
          val n = length list
          val r = sin(real n)
       in
          cos(r)
       end
\end{verbatim} 
At runtime, the list bound to {\tt list} is not used (i.e., it is not live) 
after its length has been computed;
similarly, the value of {\tt n} is not live after it has been converted to a floating point
number, and so on. In short, at runtime we have a sequence of short, non-overlapping
lifetimes. 

With region inference, however, the list bound to {\tt list} will stay allocated
throughout the evaluation of the remainder of the {\tt let}-expression.\footnote{One can
force de-allocation of the list by  inserting 
$\boxml{val \_ = \resetr(list)}$ after the declaration of {\tt n}; but, as we shall see,
there are less draconian ways of achieving the same result.} 

It is crucial to bear the ground rule in mind when programming with regions.
For a more interesting example, consider the following declarations, taken from a program which
computes prime numbers using the \index{Sieve of Eratosthenes}Sieve of Eratosthenes:
\begin{verbatim}
    fun cp [] = []
      | cp (x::xs) = x :: cp xs 

    fun sift (n, []) = []
      | sift (n, (x::xs)) = if x mod n = 0 then sift(n,xs)
                            else x::sift(n,xs)
    fun sieve(a as ([], p)) = a
      | sieve(x::xs, p) = let val rest = sift(x,xs)
                          in sieve(cp rest,x::p)
                          end
\end{verbatim}
Here {\tt sift(n, l)} produces a list of the numbers from {\tt l} that
are not divisible by \boxml{n}; {\tt sieve(xs, p)} repeatedly calls
{\tt sift}, adding primes to the front of {\tt p}, until the list of numbers
remaining in the sieve becomes empty. The programmer has employed the copying
technique suggested in Section~\ref{life.sec} to avoid that the 
lists that are bound to {\tt rest} during the repeated filtering
all are  put in the same region. The programmer's intention is that the
{\tt cp rest} should overwrite {\tt x::xs} by a copy of {\tt rest}, so
that space consumption would be bounded by a constant times the size of
the input.  But it does not work as intended: since {\tt rest}
is in scope at the recursive application of {\tt sieve}, the list which
is bound to {\tt rest} will stay
allocated for the duration of that call, which is in fact the remainder of
the entire computation! 

In many cases, the solution is simply to shorten the scope of the declaration. 
In the above example, a good solution is to move the application of {\tt
sieve} outside the {\tt let}:\pagebreak

\begin{verbatim}
    fun sieve(a as ([], p)) = a
      | sieve(x::xs, p) = 
            sieve let val rest = sift(x,xs)
                  in (cp rest,x::p)
                  end
\end{verbatim}
Although we cannot explain why the copying really overwrites the input
list until we have dealt with resetting of regions (Chapter~\ref{storagemodes.sec})
we can explain why this transformation ensures that the list bound to
{\tt rest} will not live to see the recursive call of {\tt sieve}.
Unless forced by context to do otherwise, {\tt sift} 
will create a list using fresh regions. Since {\tt cp} is also \index{region exomorphism}exomorphic,
there will be no sharing between {\tt rest} and the other lists. Precisely,
the two region variables that denote the two regions which hold the 
spine and the auxiliary pairs of {\tt rest} appear in the effect of the
(revised) {\tt let}-expression but neither of them occur free in the
region type scheme and place of any variable in scope at that point, not
even in the region type scheme and place of {\tt sieve}, whose only {\em free}
region variables are the global integer region {\tt r2} and the region which
contains {\tt sieve} itself. Consequently, region inference will wrap
the {\tt let}-expression by a {\tt letregion}-binding of the two region
variables in question, e.g., 
\begin{verbatim}
    fun sieve(a as ([], p)) = a
      | sieve(x::xs, p) = 
            sieve letregion r10, r11
                  in let val rest = sift[r10,r11](x,xs)
                     in (cp rest,x::p)
                     end
                  end
\end{verbatim}
\section{Summary}
Informally, region inference forces lifetime to be at least ``as long'' as
scope. However, region inference will introduce a {\tt letregion $\rho$}-binding
around an expression containing a free occurrence of $\rho$ 
as soon as $\rho$ occurs free neither in the type of
the expression nor in the region type scheme and place of any variable
in scope at the expression.

Useful \index{program transformation}program transformations to shorten \index{lifetime|)}lifetimes include:
\begin{enumerate}
\item Inwards let floating: \index{let floating}transform
$$\boxml{let val $\id_1$ = $\exp_1$ val $\id_2$ = $\exp_2$ in $\exp$ end}$$
into
$$\boxml{let val $\id_2$ = let val $\id_1$ = $\exp_1$ in $\exp_2$ end in $\exp$ end}$$
provided $\id_1$ does not occur free in $\exp$.
\item Application extrusion: \index{application extrusion}transform
$$\boxml{let $\dec$ in $f$($\exp$) end}$$
into
$$\boxml{$f$ let $\dec$ in $\exp$ end}$$
provided $f$ is an identifier which is not declared by $\dec$.
\end{enumerate} 
These meaning-preserving 
transformations are useful in situations where early de-allocation is important. 
Application extrusion is a useful programming habbit, 
especially in connection with \index{tail recursion}tail recursion;
the reader will see it employed several times in what follows.
\index{scope rules|)}
%
\chapter{Static detection of space leaks}
%
\label{spaceleak.sec}
``Space leak'' is the informal term used when a program uses much
more memory than one would expect, typically because of memory not
being re-cycled as early as it should (or not at all).

If a region-polymorphic function with region type scheme $\sigma$
has a $\Put$-effect on a region variable 
which is not amongst the bound region variables of $\sigma$ then
one quite possibly has a space leak: every application of the
function may write values into a region which is the same for
all calls of the function. For example, consider the 
source program\footnote{Project: \boxml{kitdemo/escape.pm}, file
\boxml{kitdemo/escape.sml}.}
\begin{verbatim}
       fun g() = 
         let val x = [5,7]
             fun f(y) = (if y>3 then x@x else x; 
                         5)
         in 
             f 1; f 4
         end;
\end{verbatim} 
Here \boxml{f} has type $\boxml{int}\to\boxml{int}$; yet, when \boxml{y>3} evaluates
to \boxml{true}, an append operation producing a list in the same region
as {\tt x} is performed. The first call of $\boxml{f}$ will not cause the
append operation to be called, but the second one will. One can say that
\boxml{f} has a space leak in that it can write values into a more
global region, namely a region which is allocated at the beginning of
the body of {\tt g}. Hence the sequence of calls to {\tt f} would
accumulate copies of {\tt x@x} in that region, although none of these
lists are accessible anywhere.
In this particular case, the values are not even part of 
the result type of {\tt f}, 
so the writing is a ``side-effect'' at the implementation level,
even though there are no references in the program.

The region type scheme inferred for \boxml{f} is:

$$\forall\epsilon.(\boxml{int},\boxml{r2})\ar{\epsilon.\{\Put(\mathtt{r4}),\Put(\mathtt{r5}), \Get(\mathtt{r2}),\Put(\mathtt{r2})\}}
  (\boxml{int},\boxml{r2})$$
where the region-annotated type of \boxml{x} is
$$(((\boxml{int},\boxml{r2}),[\boxml{r5}])\boxml{list},\boxml{r4})$$
Here we see that $\boxml{r4}$ and $\boxml{r5}$ are free in the type scheme but appear with $\Put$ effects.

\section{Warnings About Space Leaks}
The Kit issues a warning each time it meets a {\tt fun}-declared
function which has a free put effect occurring somewhere in its type
scheme. In practice, we have found this to be an extremely valuable
device for predicting space leaks. In our example, the following
warning is printed on the log file:
\begin{verbatim}
 fun g at r1 [] (var314)= 
    letregion r8:INF, r9:INF 
    in let val x = 
               let val v3294 = 
                       (5, 
                        let val v3295 = (7, nil at r8) at r9
                        in  :: at r8 v3295
                        end 
                       ) at r9
               in  :: at r8 v3294
               end 
       in  letregion r12:1 
           in let fun f at r12 [] (y)= 
                    let val _not_used = 
                            let val v3291 = 
                                    (case y > 3 
                                       of true => 
                                          letregion 
                                          ... 
                                          in @[r8,r9] at r15 
                                             (x, x) at r17 
                                          end
                                       |  false => x
                                    ) (*case*) 
                            in  ()
                            end 
                    in  5
                    end ; 
                  val _not_used = 
                      let val v3293 = 
                              letregion r18:1 
                              in f[] 1 
                              end
                      in  ()
                      end 
              in  letregion r20:1 
                  in f[] 4 
                  end
              end  
           end
       end  
    end

 *** Warnings ***
f        has a type scheme with escaping put effects on region(s): 
r8, which is also free in the type (schemes) of :  x
r9, which is also free in the type (schemes) of :  x
\end{verbatim}
We are told that the program might space
leak in regions \boxml{r8} and \boxml{r9}. Looking at the 
function \boxml{f}, we see that these two regions are actual
region parameters to \boxml{@}. This reveals that the problem is the
call to \boxml{@}.
\section{Fixing Space Leaks}
Often one can fix a space leak by delaying the creation of the
global value which causes the space leak. In the above example,
we can move the construction of the list into \boxml{f}:\footnote{Project:
\boxml{kitdemo/escape.pm}, file \boxml{kitdemo/escape1.sml}.}
\begin{verbatim}
fun g() = 
  let fun mk_x() = [5,7]
      fun f(y) = let val x = mk_x()
                 in if y>3 then x@x else x; 5 
                 end
  in 
      f 1; f 4
  end;
\end{verbatim}
Of course, this means that the list will be re-constructed upon each application
of \boxml{f}. Another solution is to move the creation of the list as close to 
the calls as possible and then pass the list as an extra argument:\footnote{Project:
\boxml{kitdemo/escape.pm}, file \boxml{kitdemo/escape2.sml}.}
\begin{verbatim}
       fun g() = 
         let 
             fun f(x,y) = (if y>3 then x@x else x; 5)
         in 
             let val x = [5,7]
             in  f(x, 1); f(x, 4)
             end
         end;
\end{verbatim}
Both solutions stop warnings from being printed, 
but the second solution is better than the first: \boxml{f} still has a
put effect on the regions containing \boxml{x}, but the difference
is that these are now represented by bound region variables in the type scheme of
\boxml{f}. This has two advantages: (a) allocation of space for the list is
delayed till the list is actually used; and (b), the list can be de-allocated
after the calls have been made (whereas in the original version, \boxml{x} occurs
free in the declaration of \boxml{f} and will be kept alive as long a \boxml{f} can be called).

At other times, there is no clean way of avoiding escaping put regions.
One example is found in the prelude:\index{Io@{\tt Io}}\index{open_in@{\tt open\_in}}\index{open_out@{\tt open\_out}}
\begin{verbatim}
  exception Io of string
  exception CANNOT_OPEN
  fun open_in(f: string): instream =         
         INS(prim(31, ("openInStream", "openInStream", f, 
                       CANNOT_OPEN)))
         handle CANNOT_OPEN => raise Io("Cannot open " ^ f)
  fun open_out(f: string): outstream =       
         OUTS(prim(31, ("openOutStream", "openOutStream", f, 
                        CANNOT_OPEN)))
         handle CANNOT_OPEN => raise Io("Cannot open " ^ f)
\end{verbatim}
As explained in Chapter~\ref{exceptions.sec}, 
our region inference algorithm is very simple-minded about 
unary exception\index{exception} constructors:
when a unary exception constructor is applied to a value, both the
argument value and the resulting constructed value are forced into
a global region. Thus the application \verb+Io("Cannot open " ^ f)+
has a potential space leak in it: every time we concatenate the two
strings, the resulting string will be put into a global region. This particular
space leak is perhaps not something that would keep one awake at night, since most 
programs do not make a large number of failed attempts to open files, but it
is useful to be warned about this potential problem.

\chapter{References}
\label{refs.sec}
Section~\ref{refbasics.sec} gives a brief summary of references in
Standard ML; it may be skipped by readers who know the language.
Thereafter we discuss runtime representation of references, region-annotated
reference types and show examples.
\section{References in Standard ML}
\label{refbasics.sec}
A reference is a memory address (pointer).
Standard ML has three built-in operations on \index{reference}references 
\index{ref@{\tt ref}}\index{"!@{\tt "!}}\index{:=@{\tt :=}}
\medskip

\halign{\indent\tt#\ \hfil&\quad$#$\hfil\ &\quad#\hfil\cr
ref & \forall\alpha.\alpha\to\alpha\REF & create reference\cr
!   & \forall\alpha.\alpha\REF\to\alpha & dereferencing\cr
:=  & \forall\alpha.\alpha\REF\ast\alpha\to\UNIT & assignment\cr}
\medskip

\noindent
If the type
of a reference $r$ 
is $\tau\,\REF$ then one can store values of type $\tau$ (only)
at address $r$. 
A reference is a value and can therefore be bound to a value identifier
by a value declaration ({\tt val}$\cdots$). While the
value stored at a reference may change, the binding between variable
and reference does not change. We show an example,
since this point can be confusing to programmers who are familiar with
updatable variables in languages like C and Pascal.
\begin{verbatim}
    val it = let
                 val x: int ref = ref 3
                 val y: bool ref = ref true
                 val z: int ref  = if !y then x else ref 5
             in 
                z:= 6;
                !x
             end
\end{verbatim}
Since \boxml{!y} evaluates to true, {\tt z} becomes bound
to the same reference, $r$,  as {\tt x}. 
So the subsequent assignment to {\tt z} 
changes the contents of the store at address $r$
to contain 6. Since {\tt x} and {\tt z} are aliases, the
result of the {\tt let}-expression is the contents of the store
at address $r$, i.e., 6.

\section{Runtime Representation of References}
The Kit translates an 
SML expression of the form $\boxml{ref $\exp$}$ into
an expression of the form
$$\boxml{ref at $\rho\quad e$}$$
which is evaluated as follows. First $e$ is evaluated. Assume
this yields a value, $v$. Here $v$ may be a \index{boxing}boxed 
or an unboxed value.
Next, a 32-bit word is allocated in the region denoted by $\rho$;
let $r$ be the address of this word. Then $v$ is stored at
address $r$ and $r$ is the result of the evaluation.

Note that a reference really is a pointer in the implementation. 
In particular,
a reference is not tagged and may  be stored
in a KAM register. The contents
of the reference is also one word, either an unboxed value (e.g., 
an integer or a boolean) or a pointer (if the contents is boxed). 
So the contents of a reference is not tagged either.

Dereferencing a reference $r$ 
is done by reading the contents of the memory location $r$.
Note that this does not require knowledge of what region the word
with address $r$ resides in.

Assigning a value $v$ to a reference $r$ simply stores $v$ in the
memory at address $r$. When $v$ is an unboxed value, this can be
regarded as copying $v$ into the memory cell $r$; othewise $v$ is
a pointer which the assignment stores in the memory cell $r$. Either
way, assignment is a constant-time operation.

\section{Region-annotated Reference Types}
The general \index{type!region-annotated}form 
of a region-annotated reference type and place is:
$$(\mu\,\REF,\rho)$$
Informally, a reference $r$ has this type
if it is the address of a word in the region denoted by $\rho$ and,
moreover, $\mu$ is the type and place of the contents of that word. 
For example, assume
$\rho$ is bound to some region name, say \boxml{r35}; then the evaluation
of ~\boxml{val x = ref at $\rho$ 3}~ results in the environment
$\{\boxml{x}\mapsto r\}$, where $r$ is the address of a word with
contents 3 residing in region \boxml{r35}, see Figure~\ref{refs.fig}.

\begin{figure}
\hrule
\begin{center}
\begin{picture}(50,40)
\put(8,5){\hbox{$\ldots$}}
\put(20,5){\framebox(20,10){\boxml{3}}}
\put(15,8){\hbox{$r:$}}
\put(25,0){\boxml{r35}}
\put(8,0){\boxml{r34}}
\put(45,0){\boxml{r36}}
\put(45,5){\hbox{$\ldots$}}
\end{picture}
\end{center}
\caption{Creating a reference allocates one word in a region on the 
region stack. Above, the region is drawn as a finite region,
but it could equally well be infinite.}
\label{refs.fig}
\hrule
\end{figure}


References are treated like all other values by region inference.
The region-annotated types given to the three built-in operations
are:
\medskip

\halign{\indent\tt#\ \hfil&\quad$#$\hfil\ &#\hfil\cr
ref & \forall\alpha\rho_1\rho_2\epsilon.(\alpha,\rho_1)\ar{\epsilon.\{\Put(\rho_2)\}}((\alpha,\rho_1)\REF,\rho_2)\cr
!   &  \forall\alpha\rho_1\rho_2\epsilon.((\alpha,\rho_1)\REF,\rho_2)\ar{\epsilon.\{\Get(\rho_2)\}}(\alpha,\rho_1)\cr
:=  & \forall\alpha\rho_1\rho_2\rho_3\rho_4\epsilon.(((\alpha,\rho_1)\REF,\rho_2)\ast(\alpha,\rho_1),\rho_3)
           \ar{\epsilon.\{\Get(\rho_3),\Put(\rho_2),\Put(\rho_4)\}}\cr
& (\UNIT,\rho_4)\cr}
\medskip

\noindent
Note that within each of these type schemes, $\alpha$ is
paired with the same region variable. The reason is that assigning a value $v$
to a reference $r$ does not make a copy of $v$ (unless $v$ is unboxed). 
The advantage of the chosen scheme for handling references is that
reference creation, dereferencing and assignment all are constant-time
operations. The disadvantage is that if two values may be
assigned to the same reference, they are forced to be in the same regions (cf. the
region type schemes given above). 

If we compile the example from Section~\ref{refbasics.sec} we get the 
program shown in Figure~\ref{otherrefs.fig}.\footnote{Project:
\boxml{kitdemo/refs.pm}, file \boxml{kitdemo/refs3.sml}.}
\begin{figure}
\hrule
\begin{verbatim}
   let val it = 
       letregion r7:INF 
       in let val x = ref at r7 3
          in  letregion r8:1 
              in let val y = 
                         let val v3845 = true 
                         in ref at r8 v3845 end ; 
                     val z = 
                         (case letregion r9:1 in ![] y end 
                         of true => x | false => ref at r7 5)
                     val v3842 = 
                         letregion r11:1, r13:1 
                         in :=[r7] at r11 (z, 6) at r13 
                         end
                 in  letregion r14:1 in ![] x end
                 end  
              end
          end  
       end
   in  {|it: (_,r2)|}
   end 
\end{verbatim}
\caption{Region-annotated reference creation.}
\label{otherrefs.fig}
\medskip

\hrule
\end{figure}
The region denoted by {\tt r7} contains the memory 
word whose address is bound to {\tt x} and {\tt z},
and whose contents is first 3, then 6.  The region denoted
by {\tt r8} contains a single boolean.
Also note that the word containing 5 is
designated {\tt r7}, 
since the {\tt then} and {\tt else} branches must give the same
type and place. Finally note that all 
references will be reclaimed automatically,
at the end of {\tt letregion} constructs 
which bind \boxml{r7} and \boxml{r8}.

\section{Local References}
References to words\index{reference!local} which are created locally within a function and do
not escape the function naturally reside in regions which are local to
the function body.
For example, the declaration:\footnote{Project: \boxml{kitdemo/refs.pm}, file
\boxml{kitdemo/refs1.sml}.}
\begin{verbatim}
       fun id(x) = let val r = ref x in ! r end;
\end{verbatim}
is compiled into
\begin{verbatim}
   let fun id at r1 [] (x)= 
           letregion r9:1 
           in let val r = ref at r9 x
              in  letregion r10:1 in ![] r end
              end  
           end
   in  {|id: (_,r1)|}
   end 
\end{verbatim}
Here {\tt r9} will be implemented as one word on the runtime stack. The
evaluation of ~~\boxml{ref at r9 x}~~ moves the contents of the standard
argument register (\boxml{standardArg}) to that word on the stack. At the
end of the {\tt letregion r9 $\ldots$ end}, the word is popped off the stack.

Now let us turn to an example of a memory cell whose lifetime
extends the scope of its declaration, because it is
accessible via a function (in Algol terminology,
the reference is an {\em own variable} \index{variable!own}of the function.)\footnote{Project:
\boxml{kitdemo/refs.pm}, file \boxml{kitdemo/refs2.sml}.}
\begin{verbatim}
       local
         val r = ref ([]:string list)
       in
         fun memo_id x = (r:= x:: !r; x)
       end
       val y = memo_id "abc"
       val z = memo_id "efg";
\end{verbatim}
This compiles into
\begin{verbatim}
   let val r = 
           let val v3756 = nil at r1 in ref at r1 v3756 end ; 
       fun memo_id at r1[] (x) = 
           let val v3752 = 
                   letregion r8:1, r10:1 
                   in :=[r1] at r8 
                      (r, 
                       let val v3753 = 
                               (x, 
                                letregion r12:1 
                                in ![] r 
                                end
                               ) at r1
                       in  :: at r1 v3753
                       end 
                      ) at r10 
                   end
           in  x
           end ; 
       val y = letregion r14:1 in memo_id[] "abc"at r4 end 
       val z = letregion r16:1 in memo_id[] "efg"at r4 end 
   in  {|
       r: (_,r1), 
       memo_id: (_,r1), 
       y: (_,r4), 
       z: (_,r4)
       |}
   end 
\end{verbatim}
and the Kit warns us that there is a possible space leak (Chapter~\ref{spaceleak.sec}):
{\small
\begin{verbatim}
 *** Warnings ***
memo_id  has a type scheme with escaping put effects on region(s): 
r1, which is also free in the type (schemes) of :  ! := r Match Bind
\end{verbatim}
}
%
\section{Hints on Programming  with References}
There is no need to shy away from using references when programming
with regions. However, one needs to be aware of the restriction that
values that may be assigned to the same references are forced to live
in the same region, and this region with all its values will be alive
for as long as the reference is live. This poses no problem if the
contents type is unboxed (e.g., {\tt int}), for in that case no region
for the contents is allocated at all. But one should avoid creating
long-lived references which are assigned many different large values.
\chapter{Recursive Data Types}
\label{datatypes.sec}
Standard ML \index{tree!binary}permits the programmer to declare (possibly recursive) data types 
using the {\tt datatype} declaration. For example, one can declare a polymorphic, recursive
data type for binary trees as follows:\index{tree@{\tt tree}}\index{Lf@{\tt Lf}}\index{Br@{\tt Br}}\index{datatype@{\tt datatype}}
\begin{verbatim}
       datatype 'a tree = Lf | Br of 'a * 'a tree * 'a tree;
\end{verbatim}
\section{Spreading Data Types}
The Kit performs an analysis, called \index{spreading}``spreading of data types'',
of the {\tt datatype} declarations contained in the program. Spreading
determines  (a) a so-called \index{arity}arity of every type name
which the data type declaration introduces and (b) a region type scheme for
every value constructor introduced by the data type declaration. In Standard ML,
every type name has an attribute, called its arity. For example, {\tt int} has
arity 0 while the type name introduced by the above declaration would have
arity 1. However, the notion of arity has to be extended internally in the Kit to account for regions
and effects. For lists, for example, we need not just a region for holding the constructors
{\tt nil} and {\tt ::}, but also a region for holding the pairs to which {\tt ::} is
applied. For the data type
\begin{verbatim}
       datatype 'a foo = A | B of ('a * 'a) * ('a * 'a)
\end{verbatim}
the type of {\tt B} introduces the possibility of three region variables
(one for each star), even if we decide to pair all occurrences of \verb+'a+
by the same region variable. Region variables which are induced by the types
of constructors and which do not hold the constructed values themselves are called
\index{region variable!auxiliary}{\em auxiliary region variables}. For example,
the {\tt list} data type:
\begin{verbatim}
       datatype 'a list = nil | op :: of 'a * 'a list
\end{verbatim}
has one auxiliary region variable, namely the region variable which
describes where the pairs of type {\tt 'a * 'a list}, i.e., the auxiliary
\index{pair!auxiliary}pairs, reside.

One also needs auxiliary arrow effects, for cases such as 
\begin{verbatim}
       datatype V = N of int | F of V -> V
\end{verbatim}
where we need an arrow effect for the function type \boxml{V -> V}. We refer
to such an arrow effect as an \index{arrow effect!auxiliary}{\em auxiliary arrow effect} of the data type in question.

We define the {\em (internal) arity} of a type name $t$ to be a 
triple $(n,k,m)$ of non-negative integers, 
where $n$ is the usual Standard ML arity of the type name,
$k$ is the \index{region arity}{\em region arity} of $t$ and $m$ is the \index{effect arity}{\em effect arity} of 
$t$. The region and effect arity indicate the number of auxiliary regions
and arrow effects of the data type, respectively.

For efficiency purposes, we have found it prudent to restrict the maximal number
of auxiliary regions a data type can have to 3 
(one for each kind of runtime type of regions) and
to restrict the maximal number of auxiliary effects to 1.               
Otherwise, the number of auxiliary regions can grow exponentially in the
size of the program:
\begin{verbatim}
       datatype t0 = C
       datatype t1 = C1 of t0 * t0
       datatype t2 = C2 of t1 * t1
       ...
\end{verbatim}
Here the number of auxiliary region variables would double for each new data type
declaration. 

Furthermore, all type names introduced by a {\tt datatype} declaration are
given the same arity (a {\tt datatype} declaration can declare several
types simultaneously). Within one constructor binding ({\it conbind\/}), all
occurrences of the same type variable are paired with the same region variable. 
Different type variables are paired with different region variables.
Since we allow at most one auxiliary region variable for each {\tt datatype}
declaration, the analysis of data type declarations sometimes has to unify
two auxiliary region variables that would otherwise be distinct, but it only unifies auxiliary region
variables that have the same runtime type. 

The practical consequence of these restrictions is that sometimes
applying a constructor to a value $v$ forces identification of regions
of $v$ that hold otherwise unrelated parts of $v$.


The automatic memory management we have discussed for lists extends to
other recursive data types without problems. For example, binary trees
are put into regions and are subsequently de-allocated (in a constant time operation) when
the region is popped. The next section is an example 
to illustrate the point.

For simplicity, constructed values are always boxed. 
\section{Example: Balanced Trees}
Consider the following program in
Figure~\ref{balpre.fig}.\footnote{Project: \boxml{kitdemo/trees.pm}, file
  \boxml{kitdemo/trees.sml}.}\begin{figure} \hrule
\begin{verbatim}

   datatype 'a tree = Lf | Br of 'a * 'a tree * 'a tree

   (* preorder traversal of tree *)

   fun preord (Lf, xs) = xs
     | preord (Br(x,t1,t2),xs) = 
         x::preord(t1,preord(t2,xs))


   (* building a balanced binary tree
      from a list: *)

   fun balpre [] = Lf
     | balpre(x::xs) = 
        let val k = length xs div 2
        in Br(x, balpre(take(xs, k)),
                 balpre(drop(xs, k)))
        end

   (* preord o balpre is the identity: *)

   val it = say(implode(preord(balpre(explode 
       "Greetings from the Kit\n"),[])));
\end{verbatim}
\caption{Example showing recycling of memory used for an intermediate 
data structure.}
%         {\tt balpre} builds a balanced binary tree from a list and {\tt preord}
%         then flattens the tree to a list (after which the tree is garbage).}
\medskip

\hrule
\label{balpre.fig}
\end{figure}
Note that we would hope that the balanced tree
produced by {\tt balpre} is removed after it
has been collapsed into a list by {\tt preord}.
And indeed it is. Here is the proof:
\bigskip

%\vbox{
\hrule
\begin{verbatim}
       val it = 
           letregion r72:1, r74:1 
           in say[] 
              letregion r75:1, r77:INF, r78:INF, r79:INF 
              in implode[r74] at r75 
                 letregion r80:1, r82:1, r83:INF, r84:INF 
                 in preord[r77,r78] at r80 
                    (letregion r85:1, r87:INF, r88:INF 
                     in balpre[r83,r84] at r85 
                        letregion r89:1, r91:1 
                        in explode[r87,r88,r79] at r89 
                           "Greetings from the Kit\n"at r91 
                        end 
                     end 
                     nil at r77
                    ) at r82 
                 end 
              end 
           end 
\end{verbatim}
%\hrule
\bigskip
%}


This is the kind of certainty about lifetimes we are aiming at.
Imagine, for example, that the trees under consideration 
were terms representing
different intermediate forms in a compiler. Then one would
like to know that (possibly large) syntax trees are not
kept in memory longer than needed.
%
\chapter{Exceptions}
%
\label{exceptions.sec}\index{exception}
\section{Exception Constructors and Exception Names}
Standard ML \index{exception}\index{exception constructor}exception constructors are introduced by \index{exception declaration}\index{exception@{\tt exception}} 
{\em exception declarations}. The two most basic forms are
$$\boxml{exception {\it excon}}$$
and 
$$\boxml{exception {\it excon} of {\it ty}}$$
for introducing nullary and unary exception constructors,
respectively. Unary exception constructors are typically
used when one wants to raise an exception which contains a
``reason'' (represented by a value of type {\it ty}).

Unlike in some languages (for example Java), exception
declarations need not occur at top level. For example,
a function body may contain exception declarations.
Each evaluation of an exception declaration creates a
fresh {\em exception name} \index{exception!generative}\index{exception name}and binds it to the exception
constructor. This is sometimes referred to as the {\em generative}
nature of ML exceptions.

In the ML Kit, an exception name is implemented
as a pointer to a pair consisting of an integer 
and a string pointer; the string pointer points
to the name of the exception, which is a global
constant in the target program. The string is used
for printing the name of the exception if it ever propagates
to the top level. The cost of creating
the pair is, as always with pairs, two words.

\section{Exception Values}
Standard ML has a type \index{exn@{\tt exn}}
{\tt exn} of \index{exception value}{\em exception values}.
An exception value is  either an  
\index{exception name}exception name 
or a \index{exception value!constructed}
{\em constructed exception value}. A constructed
exception value can be thought of as a pair $(\ename,v)$  of
an exception name $\ename$ and a value $v$; we refer to  $v$ as the
{\em argument} of $\ename$.

An exception value which is just a nullary exception name is
represented as the name itself, i.e., by a pointer to a pair
of an integer and a string. Thus referring to a nullary exception
constructor allocates no memory. By contrast, applying a unary 
exception constructor to an argument constructs a constructed
exception value. Cost: two words.

The distinction between nullary and unary exception constructors
is important in the Kit because our region inference analysis
takes a simple-minded approach to exceptions: {\em all exception
names and all constructed exception values are put in global regions and thus
never reclaimed automatically.}\index{region!global}

We therefore make the following recommendations:
\begin{enumerate}
\item Put exception declarations at top-level, if possible.
      That way, the memory required by exception names will
       be bounded by the program size.
\item Avoid applying unary exception constructors frequently; there is
      no harm in raising and handling constructed exception values frequently,
      it is the creation of many different constructed exception values
      that can lead to space leaks. Nullary
      constructors may be used freely without incurring memory costs.
\end{enumerate}
\section{Raising Exceptions}
An expression of the form \index{exception!raising}
$$\boxml{raise {\it exp}}$$
is evaluated as follows. First {\it exp}, an expression of 
type {\tt exn}, is evaluated to an exception value. Then the runtime
\index{stack}stack is scanned from top towards bottom in search of a handler
which can handle the exception. The KAM has a register which points
to the top-most exception handler; the exception handlers are linked
together as a linked list interspersed with the other contents of
the runtime stack. If a matching handler is found, the runtime stack
is popped down to the handler. This popping includes popping of regions
that lie between that stack top and the handler. Put differently,
consider an expression of the form \index{letregion@{\tt letregion}}
{\tt letregion $\rho$ in $e$ end}; if $e$ evaluates to an exception packet,
then the region bound to $\rho$ is de-allocated and the packet is also
the result of evaluating the \texttt{letregion} expression.

We have not attempted to design an analysis which would estimate how
far down the stack a given exception value might propagate. Of course,
it would not be a very good idea to allocate a constructed exception
value in a region which is popped before the exception is handled!
This is why we put all exception names and all constructed exception
values in global regions.\index{region!global}

\section{Handling Exceptions}
The ML expression form\index{exception!handling}
$$\boxml{${\it exp}_1$ handle {\it match}}$$
is compiled into a $\MulExp$ expression of the form
\begin{tabbing}
\ \ \ \ \ \ \=\tt letregion $\rho$ in \\
\>\ \ \=\boxml{let $f$ = fn {\it match} at $\rho$ in $e_1$ handle $f$ end}\\
\>\tt end
\end{tabbing}
where $f$ is a fresh variable.
So first a handler (expressed as a function) is evaluated and stored
in some region $\rho$. This region will always have
multiplicity one and therefore be a finite region which is put on the stack.
Then $e_1$, the result of compiling ${\it exp}_1$, is evaluated.
If $e_1$ terminates with a value, the {\tt letregion} construct
will take care of de-allocating the handler.
If $e_1$ terminates with an exception, however, $f$ is applied.

Thus the combined cost of raising an exception and searching for 
the appropriate handler takes time proportional to the depth
of the runtime stack in the worst case. 

This is the only operation which takes time which
cannot be determined statically, 
provided one admits 
arithmetic operations as constant-time operations. 

\section{Example: Prudent Use of Exceptions}
Here is an example of prudent use of exceptions in the ML Kit:\index{hd@{\tt hd}}\index{tl@{\tt tl}}
\bigskip

\vbox{
\hrule
\begin{verbatim}
exception Hd               (* recommendation 1 *)

fun hd [] = raise Hd
  | hd (x::_) = x

exception Tl

fun tl [] = raise Tl
  | tl (_ ::xs) = xs

exception Error of string 

local 
  val error_f = Error "f"  (* recommendation 2 *)
in
  fun f(l) = 
      hd(tl(tl l)) handle _ => raise error_f
end
     
val r = f[1,2,3,4];
\end{verbatim}
\hrule
}\bigskip

Note that the application
\boxml{Error "f"} has been lifted out from the 
body of \boxml{f}. No matter how many times {\tt f} is applied,
it will not create additional exception values.\footnote{Project:
\boxml{kitdemo/exceptions.pm}, file: \boxml{kitdemo/exceptions.sml}.}
\chapter{Resetting Regions}
\label{storagemodes.sec}
In Section~\ref{checked.sec} we explained that resetting \index{region!resetting}
regions is an important ingredient in programming with regions.
%(The point was illustrated with the Game of Life in Section~\ref{life.sec}.)
This chapter gives an informal explanation of the rules that
govern resetting, rules which play a key r\^ole in Kit programming
irrespective of whether one leaves resetting of regions to the
Kit or prefers to control resetting explicitly in the program.


Resetting only makes sense for infinite regions. It is a 
constant-time operation.

The Kit contains an analysis, the {\em storage mode analysis}, which has
two purposes:
\begin{enumerate}
\item inserting automatic resetting of infinite regions, when possible;
\item checking applications of $\resetr$ (and \index{forceResetting$\resetf$}$\resetf$) in order to 
report on the safety of the resetting requested by the programmer.
\end{enumerate}

As a matter of design, one might wonder whether it would not be sufficient
to rely on the user indicating where resetting should be done. However,
checking whether resetting is safe at a particular point chosen
by the user is of course no easier than checking whether resetting is safe
at an arbitrary point in the program, so one might as well let the compiler
insert region resetting whenever it can prove that it is safe. 

In this chapter we describe the principles that underlie the storage
mode analysis. Even if one is willing to insert $\resetr$ and
$\resetf$ instructions in the program, one still needs to understand
these principles, in order to be able to act upon the messages that are
generated by the system in response to explicit $\resetr$ and
$\resetf$ instructions.
%
\section{Storage Modes}
%
As we have seen in previous chapters, region inference decorates every 
allocation point with an annotation of the \index{allocation point}\index{at@{\tt at}}
form ``\boxml{at} $\rho$'',
indicating into which region the value should be stored. 

Now the basic idea is that storing a value into a region can be done
in one of two ways, at runtime. One either stores the value at the 
\index{top of region}{\em top}
of the region, thereby increasing the size of the region; or one stores
the value into the \index{bottom of region}{\em bottom} of the region, by first resetting the region
(so that it contains no values) and then storing the value into the region.
%Pure resetting of a region can be accomplished by storing a value of size zero
%at the bottom of the region. 

The storage mode analysis transforms an allocation point ``\boxml{at
$\rho$}'' into \index{attop@{\tt attop}}``\boxml{attop} $\rho$'' when it  estimates that
$\rho$ contains live values at the allocation point, whereas it
transform it into \index{atbot@{\tt atbot}}``\boxml{atbot $\rho$}'', if it can prove that the
region will not contain live values at that allocation point. The
tokens {\tt attop} and {\tt atbot} are called \index{storage mode}{\em storage modes}.

Region polymorphism \index{region polymorphism}introduces several interesting problems. Let $f$ be
a region-polymorphic function with formal region parameter $\rho$ and
consider an allocation point {\tt at $\rho$} in the body of $f$.
Whether it is safe for $f$ to store the value $\atbot$ in the region
depends not only on the body of $f$ but also on the context in which
$f$ is called.

For example, consider the compilation unit
\begin{verbatim}
  fun f [] = []
    | f (x::xs) = x+1 :: f xs

  val ll = [1,2,3]
  val l2 = if true then f l1 else l1
  val x::_ = l1;
\end{verbatim}
When {\tt f} stores the empty list, it can potentially reset the
region it writes into (as well as the \index{region!auxiliary}auxiliary region intended for
the \index{pair!auxiliary}auxiliary pairs of the list). In the above program, however,
the conditional forces \boxml{f l1} and \boxml{l2} 
to be in the same regions as {\tt l1}.
Since \boxml{l1} is live after the application of {\tt f}, this application
must not use {\tt atbot} as storage mode. Indeed, even if we removed the
last line of the program, the application could still not use {\tt atbot}, 
for \boxml{l1} is exported from the compilation unit and thus potentially 
used by subsequent compilation units.

By contrast, consider\footnote{Project: \boxml{kitdemo/sma.pm}, file: \boxml{kitdemo/sma1.sml}.}
\begin{verbatim}
    fun f [] = []
      | f (x::xs) = x+1 :: f xs

    val n = length(let val l1 = [1,2,3]
                   in if true then f l1 else l1
                   end)
\end{verbatim}
When {\tt f} stores {\tt nil}, it is welcome to reset the regions that
hold \boxml{l1}, for by that time, \boxml{l1} is
no longer needed! ({\tt f} traverses {\tt l1}, but when it reaches the
end of the list, {\tt l1} is no longer needed.)  Indeed the Kit will
{\em replace} the list \boxml{[1,2,3]} by \boxml{[2,3,4]}. The ability
to replace data in regions is crucial in many situations (as we
illustrated with the game of Life in Section~\ref{life.sec}).

Since the Kit allows  separate compilation, it
cannot know all the call sites of a region-polymorphic function,
when it is declared.
Therefore, when considering an allocation point ``\boxml{at $\rho$}''
inside the body of some region-polymorphic function, $f$, which
has $\rho$ as a formal region parameter,
one cannot know at compile time whether to use {\tt attop} or {\tt
atbot}.  Instead, the storage mode analysis operates with a third kind of
storage mode: {\tt sat}, read: ``somewhere at''. Consider an
application of $f$ in which $\rho$ is
instantiated to some region variable, $\rho'$, say. At runtime, $\rho'$
is bound to some region name (Section~\ref{fininf.sec}), $r'$.
Then $r'$ is combined with a definite storage mode 
(i.e., {\tt attop} or {\tt atbot}), to yield $r$, say, which
is then bound to $\rho$.
When $r'$ was originally created (by a {\tt letregion}-expression),
$r'$ was also made to contain an indication
of whether it is an infinite region or a finite 
region.\footnote{On machines\label{atbit.lab} that have at least four bytes per
word, the two least significant bits of a pointer to a word
will always be 00. These two bits hold extra information in
the \index{region name}region name.
One bit, called the ``atbot bit'', holds the current storage mode of
the region. Another bit, called the ``infinity bit'', indicates whether
the region is finite or infinite.} 
At runtime, an allocation \boxml{sat $\rho$} in the body
of $f$ will test $r$ to see whether the region is infinite and 
whether the value should be stored at the top or at the bottom.\footnote{When
$\rho$ has multiplicity infinity, $r'$ must be the name of an infinite region,
so the runtime check on whether $r$ has its infinity bit set is omitted.}

The relevant parts of the result of compiling the last example above
are shown in Figure~\ref{sma1.fig}.  To see the storage modes, switch
on the flag ~~\boxml{print atbot expression}\index{print atbot
  expression@{\tt print atbot expression}}~~in the
menu~~\texttt{Printing of intermediate forms}.  The intermediate form
obtained by enabling this flag is from before the optimisation that
drops $\Get$-regions (page \pageref{bother-to-distinguish-get-n-put})
and may therefore have more region variables.


\bigskip

\begin{figure}
\vbox{
\hrule
\begin{verbatim}
    fun f attop r1 [r7:INF, r8:INF, r9:0, r10:0] (var180)= 
        (case var180 
           of nil => nil sat r7
           |  :: => let val v2007 = decon_:: var180;             
                        val x = #0 v2007;                        
                        val xs = #1 v2007;                       
                        val v2010 =                              
                            (x + 1attop r2,                      
                             letregion r15:1                     
                             in f[sat r7,sat r8,sat r9,sat r10]  
                                   atbot r15 xs                  
                             end) attop r8             
                    in  :: attop r7 v2010                        
                    end) (*case*) ;
    val n = 
        letregion r17:1, r19:INF, r20:INF 
        in length[atbot r19,atbot r20,attop r2] atbot r17 
           let val l1 = 
                let val v2014 = 
                     (1attop r2, 
                      let val v2015 = 
                           (2attop r2, 
                            let val v2016 = 
                                 (3attop r2, nil atbot r19) attop r20
                            in :: attop r19 v2016 
                            end 
                           ) attop r20
                      in  :: attop r19 v2015
                      end) attop r20
                in  :: attop r19 v2014
                end 
           in  (case true attop r2 
                  of true => 
                     letregion r24:1 
      (*1*)          in f[atbot r19,atbot r20,atbot r19,atbot r20] 
                          atbot r24 l1 
                     end 
                  |  false => l1) (*case*) 
           end  
        end (*r17:1, r19:INF, r20:INF*)
\end{verbatim}
%   let fun f attop r1 [r7:INF, r8:INF](var487) = 
%         (case var487 
%            of nil => nil sat r7
%            |  :: => 
%               let val v5173 = decon_:: var487; 
%                   val x = #0 v5173; 
%                   val xs = #1 v5173; 
%                   val v5176 = 
%                       (x + 1, 
%                        letregion r15:2 
%                        in  f[sat r7,sat r8] atbot r15 xs 
%                        end (*r15:2*)
%                       ) attop r8
%               in  :: attop r7 v5176
%               end 
%         ) (*case*) ; 
%       val n = 
%           letregion r17:0, r19:inf, r20:inf 
%           in length
%              let val l1 = 
%                  let val v5180 = 
%                      (1, let val v5181 = 
%                              (2, let val v5182 = (3, 
%                                       nil atbot r19) attop r20
%                                  in  :: attop r19 v5182
%                                  end) attop r20
%                          in  :: attop r19 v5181
%                          end ) attop r20
%                  in  :: attop r19 v5180
%                  end 
%              in  (case true 
%                  of true => 
%                     letregion r24:2 
%         (*1*)       in f[atbot r19,atbot r20] atbot r24 l1 
%                     end (*r24:2*)
%                  |  false => l1
%                  ) (*case*) 
%              end  
%          end (*r17:0, r19:inf, r20:inf*)
%   in  {|f: (_,r1), n: (_,r2)|}
%   end 
}
\caption{Storage modes inferred by the storage mode analysis.}
\bigskip
\label{sma1.fig}
\hrule
\end{figure}

\section{Storage Mode Analysis}
\label{sma.sec}
For the purpose of the storage mode analysis, actual region
parameters to region-polymorphic functions are considered allocation
points. Passing a region as an actual argument to a region-polymorphic
function involves neither resetting the region nor storing any value
in it, but a storage mode has to be determined at that point
nonetheless, since it has to be passed into the function together with
the region. The storage mode expresses whether, at the call site,
there may be any live values in the region {\em after} the call. For
example, in Figure~\ref{sma1.fig} the call to {\tt f}
at {\tt (*1*)} passes both {\tt r19} and {\tt r20} with storage
mode {\tt atbot} since the only value that exists before the call
of {\tt f} and is needed after the call of {\tt f} is {\tt length},
which is declared in a different compilation unit and therefore
obviously  resides neither in {\tt r19} nor in {\tt r20}.

Within every lambda abstraction, the Kit performs a backwards flow
analysis which determines, for every allocation point, a set of
\index{variable!locally live}{\em locally live variables}, i.e., a set
of variables used by the remainder of the computation in the function
up to the syntactic end of the function. (This includes variables
which appear in function application expressions.) Prior to the
computation of locally live variables, a program transformation, called
\index{K-normalisation}\label{K-normal-form}{\em K-normalisation},
has made sure that every intermediate result which arises during
computation becomes bound to a variable. (This happens by introducing
extra {\tt let} bindings, when necessary.)\footnote{K-normalisation is
  transparent to users: although the storage mode analysis and all
  subsequent phases up to code generation operate on K-normal forms,
  programs are always simplified to eliminate the extra let-bindings
  before they are presented to the user.}

The Kit also computes a set of locally live variables
for each allocation point which does not occur inside
any function.

We now give an informal explanation of the rules that assign
storage modes to allocation points.
Let an allocation point
\begin{equation}
\label{allocpoint}\at\,\rho
\end{equation}
be given. 
\bigskip

\noindent{\bf CASE A:} $\rho$ is a global region. Then $\attop$ is used. 
There is a 
deficiency  we have to admit here. The Kit only puts {\tt letregion}
around expressions, not around declarations. Thus, if one writes

\vbox{
\begin{verbatim}
    local 
      fun f [] = []
        | f (x::xs) = x+1 :: f xs
      val l1 = [1,2,3]
    in
      val n = length(if true then f l1 else l1)
    end
\end{verbatim}}

\noindent at top level, then \boxml{l1} is put into a global region, although
this is really unnecessary. As a consequence, {\tt f} would be
called with storage mode {\tt attop} and thus {\tt l1} would not be
overwritten.
\bigskip

\noindent{\bf CASE B:}
The region variable $\rho$ is not a global region and 
the allocation point (\ref{allocpoint}) occurs inside a lambda
abstraction, 
i.e, inside an expression of the form \boxml{fn {\it pat} => $e$}.
Here we regard every expression of the form
$$\boxml{let fun f(x) = $e$ in $e'$ end}$$ as an abbreviation for
$$\boxml{let val rec f  = fn(x) => $e$ in $e'$ end}$$
Then it makes sense to talk about 
{\em the smallest enclosing lambda abstraction
(of the allocation point)}.

Now there are the following cases:
\begin{description}
\item[B1] {\it $\rho$ is bound outside the smallest enclosing lambda abstraction
      (and this lambda abstraction is not the right-hand side of a 
      declaration of a region-polymorphic function which has $\rho$ as
      formal parameter):}
      use {\tt attop} (see Figure~\ref{b1.fig})\index{attop@{\tt attop}};
\item[B2]{\it $\rho$ is bound by a {\tt letregion}-expression inside the
      smallest enclosing function:} use {\tt atbot} if no locally live
      variable at the allocation point has $\rho$ free in its region 
      type scheme and place (Section~\ref{regtych.sec}), and use {\tt attop} otherwise 
      (see Figure~\ref{b2.fig})\index{letregion@{\tt letregion}};
\item[B3 (first attempt)]{\it $\rho$ is a formal parameter of a region-polymorphic function
      whose right-hand side is the smallest enclosing lambda abstraction:}
            use \index{sat@{\tt sat}}{\tt sat}, if no locally live
      variable at the allocation point has $\rho$ free in its region type scheme and
      place, and use {\tt attop} otherwise (see Figure~\ref{b3.fig}).
\end{description}
\begin{figure}
\hrule
\begin{center}
\begin{tabbing}
\\
\hskip3cm\=\tt letregion $\rho$\\
       \>\tt in $\ldots$ (fn {\it pat} => $\ldots\at\,\rho\ldots$)\\
       \>\tt end\\
\\
       \>\tt fun f at $\rho_1$[$\rho$] =\\
       \>\tt\ \ \ (fn x => (fn y => $\ldots$ at $\rho$ $\ldots$)at $\rho_2$)at $\rho_1$\\
\end{tabbing}
\end{center}
\caption{Two typical situations where $\at\,\rho$ is turned into $\attop\,\rho$
by rule~B1.\index{function!Curried}}
\medskip

\hrule
\label{b1.fig}
\end{figure}
\begin{figure}
\hrule
\begin{center}
\begin{tabbing}
\\
\hskip3cm\=\tt (fn ${\it pat}$ => $\ldots$\\
       \>\ \ \=\tt letregion $\rho$ \\
       \>    \>\tt in  $\ldots\at\,\rho\ldots l \ldots$\\
       \>    \>\tt end $\ldots$\\
       \>\tt )
\end{tabbing}
\end{center}
\caption{The situation which is considered in B2. If no locally live variable
$l$ has $\rho$ occurring in its type scheme and place, 
replace $\at\,\rho$ by $\atbot\,\rho$, otherwise
by $\attop\,\rho$.}
\medskip

\hrule
\label{b2.fig}
\end{figure}
\begin{figure}
\hrule
\begin{center}
\begin{tabbing}
\\
\hskip3cm\=\tt fun f at $\rho_0$ [$\rho$, $\ldots$] = \\
         \>\tt \ \ \=\tt (fn ${\it pat}$ => $\ldots\at\rho\ldots l\ldots$)
\end{tabbing}
\end{center}
\caption{The situation which is considered in B3. If no locally live variable
$l$ has in its type scheme and place a region variable which may be
aliased with $\rho$,  replace $\at\,\rho$ by $\sat\,\rho$, otherwise
by $\attop\,\rho$.}
\medskip

\hrule
\label{b3.fig}
\end{figure}
The motivation for (B1) is that if $\rho$ is declared non-locally,
then we do not attempt to find out whether $\rho$ contains live data (this would
require a more sophisticated analysis.) 
The intuition behind (B2) is as follows. Region inference
makes sure that the region-annotated type and place of a variable always contains
free in it region variables for all the regions which the value bound to that
variable needs when used. The lifetime of the region bound to 
$\rho$ is given by the {\tt letregion} expression which is in the same function
as the allocation point. Thus,  
if no locally live variable at the allocation point
has $\rho$ free in its type scheme 
or place, then $\rho$ really does not contain any
live value at that allocation point.

The intuition behind (B3) is the same as behind (B2), but
in this case there is a complication: 
$\rho$ is only a formal parameter so it may
be instantiated to different regions; 
in particular it may be instantiated to 
a region variable which {\em does} occur free in the type scheme and place of a
locally live variable at the allocation point. If that happens, 
rule (B3), as stated, is not sound!

We refer to the phenomenon that two different region variables in the
program may denote the same region at runtime as \index{region
  aliasing} {\em region aliasing}. In order to determine whether to
use {\tt sat} or {\tt attop} in case (B3), the Kit builds a
\index{region flow graph}\label{region flow graph}{\em region flow
  graph} for the entire compilation unit. (This happens in a phase
prior to the storage mode analysis proper.)  The nodes of the region
flow graph are region variables and arrow effects that appear in the
region-annotated compilation unit.  Whenever $\rho_1$ is a formal
region parameter of some function declared in the unit and $\rho_2$ is
a corresponding actual region parameter in the same unit, a directed
edge from $\rho_1$ to $\rho_2$ is created. Similarly for arrow
effects: if $\epsilon_1.\rea_1$ is a bound arrow effect of a
region-polymorphic function declared in the compilation unit and
$\epsilon_2.\rea_2$ is a corresponding actual arrow effect then an
edge from $\epsilon_1$ to $\epsilon_2$ is inserted into the graph.
Also, edges from $\epsilon_2$ to every region and effect variable
occurring in $\rea_2$ are inserted. Finally, for every
region-polymorphic function $f$ declared in the program and every
formal region parameter $\rho$ of $f$, if $f$ is exported from the
compilation unit, then an edge from $\rho$ to the global region of the
same runtime type as $\rho$ is inserted into the graph. (This is
necessary, in order to cater for applications of $f$ in subsequent
compilation modules.)  Let $G$ be the graph thus constructed. For
every node $\rho$ in the graph, we write $\langle\rho\rangle$ to
denote the set of region variables which can be reached from $\rho$,
including $\rho$ itself. The rule that replaces (B3)
is:\index{region parameter!formal}
\begin{description}
\item[B3]{\it $\rho$ is a formal parameter of a region-polymorphic function
      whose right-hand side is the smallest enclosing lambda abstraction:}
      use {\tt sat}, if, for every variable $l$ which is locally live 
      at the allocation point and for every region variable $\rho'$
      which occurs free in the region type scheme and place of $l$, it
      is the case that $\langle\rho\rangle\cap\langle\rho'\rangle =\emptyset$;
      use {\tt attop} otherwise.
\end{description}
\medskip

\noindent{\bf CASE C:} $\rho$ is bound by a {\tt letregion}-expression
and the allocation point (\ref{allocpoint})
does not occur inside any function abstraction.
As in (B2), use {\tt atbot} if no locally live
variable at the allocation point has $\rho$ free in its region 
type scheme and place, and use {\tt attop} otherwise.


\section{Example: Computing the Length of a List}
\label{length.sec}
We shall now illustrate the storage mode rules of 
Section~\ref{sma.sec}
with some small examples which also allow us to discuss
benefits and drawbacks associated with region resetting.

Consider the functions declared in Figure~\ref{length.fig}\footnote{Project:
\boxml{kitdemo/nlength10000.pm}, file: \boxml{kitdemo/length.sml}.}; they
implement five different ways of finding the length of a list!
The first, {\tt nlength}, is the most straightforward one.
It is not tail recursive. Textbooks in functional programming often
recommend that functions are written iteratively (i.e., using tail 
calls) whenever possible. This we have done with {\tt tlength}.
Next, {\tt klength} is a version which contains a local \index{region endomorphism}region 
endomorphism {\tt loop} to perform the iteration; {\tt llength} 
is similar to {\tt klength}, except that the region endomorphism
is declared outside {\tt llength}, using \index{local@{\tt local}}{\tt local}.
\begin{figure}
\vbox{
\hrule
\begin{verbatim}

fun upto n = 
  let fun loop(p as (0,acc)) = p
        | loop(n, acc) = 
            loop(n-1, n::acc)
  in
      #2(loop(n,[]))
  end

fun nlength [] = 0
  | nlength (_::xs) = 1 + nlength xs

fun tlength'([], acc) = acc
  | tlength'(_::xs, acc) = tlength'(xs,acc+1)

fun tlength(l) = tlength'(l,0)

fun klength l =
  let fun loop(p as ([], acc)) = p
        | loop(_::xs, acc) = loop(xs,acc+1)
  in
      #2(loop(l,0))
  end

local 
  fun llength'(p as ([], acc)) = p
    | llength'(_::xs, acc) = llength'(xs,acc+1)
in
  fun llength(l) = #2(llength'(l, 0))
end

fun global(p as ([], acc)) = p
  | global(_::xs, acc) = global(xs, acc+1)

fun glength(l) = #2(global(l, 0))

val run =   nlength(upto 10000) + tlength(upto 10000) +
            klength(upto 10000) + llength(upto 10000) +
            glength(upto 10000);
\end{verbatim}
}
\caption{Five different ways of computing the length of lists.}
\bigskip
\label{length.fig}
\hrule
\end{figure}
Region and stack profiles resulting from running the program
are shown in Figure~\ref{length.region.fig}.
% and \ref{length.stack.fig},
%respectively. 
The diagram shows how much space is used in
regions, both finite regions on the stack and infinite regions. 
The \index{region descriptor}{\tt rDesc} band shows how much space is used on the stack for
holding region descriptors. The 
\index{stack@{\tt stack} profile}{\tt stack} band shows how much space is used on the stack, 
including neither finite regions nor region descriptors; the {\tt stack}
band mainly consists of registers and return addresses 
that have been pushed onto the stack. 
%Figure~\ref{length.stack.fig}
%shows the two bands {\tt stack} and {\tt rDesc} again, but without
%an region bands.
\begin{figure}
\begin{center}
\vbox{
{\includegraphics{length.region.ps}}
}
\end{center}
\caption{Region profiling of five different
ways of computing the length of a list, namely, from left to right:
{\tt nlength}, {\tt tlength}, {\tt klength}, {\tt llength}
and {\tt glength}.}
\label{length.region.fig}
\end{figure}
%
%
%

%\begin{figure}
%\begin{center}
%\vbox{
%{\includegraphics{length.stack.ps}}
%}
%\end{center}
%\caption{Stack profiling of five different
%ways of computing the length of a list, namely, from left to right:
%{\tt nlength}, {\tt tlength}, {\tt klength}, {\tt llength}
%and {\tt glength}. The first spike is for {\tt nlength}, the second
%for {\tt tlength}.}
%\label{length.stack.fig}
%\end{figure}

In Figure~\ref{length.region.fig} we clearly see the five phases.
In each phase, first a list is built ---
seen as an almost linear growth in
two regions; 
then follows a shorter computation of the length of the list.
The space behaviour of the five ways of computing the length
vary considerably. We shall have more to say about the time behaviour
below.

As one would expect, 
{\tt nlength} leads to a peak in stack size and it
does not use regions. (The peak in stack size is caused by the
stacking of a return address.)

Next we see that {\tt tlength} is not an improvement over
{\tt nlength}! Note that {\tt tlength'} is region-polymorphic and that the
polymorphic recursion in regions allows the pair \boxml{(xs, acc+1)}
to be stored in a region different from  the argument pair to {\tt tlength'}.
Thus what appears to be a tail call is in fact not a tail call, for
it is automatically enclosed in a {\tt letregion} construct which introduces
a fresh region for each argument pair \boxml{(xs, acc+1)}. This region is finite, so it is
allocated on the stack. That is why we see a sharp increase in
stack size for {\tt tlength'}.

The next function, {\tt klength}, deserves careful study, since
it is a prototype of a particular schema
which can be used again and again when programming with
regions. Iteration is done by a \index{region endomorphism}region endomorphism,
{\tt loop}, which is
declared as a local function to the main function. The use of
the same variable {\tt p} on both the left-hand side and the right-hand
side of the declaration of {\tt loop} forces {\tt loop} to be a region
endomorphism. Since the result of 
\boxml{loop(xs,acc+1)} is also the result of {\tt loop}, the
result of \boxml{loop(xs,acc+1)} therefore has to be in the same region as {\tt p};
but since {\tt loop} is an endomorphism, this forces 
\boxml{(xs, acc+1)} to be in the same region as {\tt p}.
Thus what appears to be a tail call ({\tt loop(xs,acc+1)})
really will be a tail call; in particular there will be no fresh region
for the argument and no growth
of the stack. 

Better still, we have carefully arranged that
memory consumption will be constant throughout the computation of
the length of the list. First, the argument to the 
initial call of {\tt loop} is a pair \boxml{(l, 0)} constructed
at that point. Since {\tt loop} is a region endomorphism, the
result of \boxml{loop(l, 0)} will be in the same region as \boxml{(l, 0)}.
Moreover, since we then immediately take the second projection of
that pair, that region is clearly local to the body of {\tt klength}.
Call the region  $\rho$. Since there can be an unbounded number of stores into
this region, $\rho$ is classified as infinite by multiplicity inference.

The storage mode passed along with $\rho$
in the initial call \boxml{loop(l,0)} is {\tt atbot}, by 
rule (B2) of Section~\ref{sma.sec}. Inside {\tt loop}, the storage
mode given to the allocation of \boxml{(xs, acc+1)} is {\tt sat},
by rule (B3) in Section~\ref{sma.sec}: the only locally live
variable at the point where the allocation takes place is {\tt loop}
--- which we must not destroy before calling! --- and the region which
{\tt loop} lies in is clearly different from $\rho$.

Therefore, every iteration of {\tt loop} resets the ``infinite'' region
$\rho$ so that it will in fact only contain at most one pair.
This is seen very clearly in the third hump of 
Figure~\ref{length.region.fig}.

Next consider {\tt llength}. The difference from {\tt klength} is
that {\tt llength'} is now declared outside {\tt llength}.
Note that although the use of {\tt local} makes it clear that {\tt llength'}
is not exported from the compilation unit, {\tt llength'} must in fact reside
in a global region, since {\tt llength}, which is exported, calls
{\tt llength'}.  Nonetheless, the storage mode analysis still achieves
constant memory usage. As before, we have arranged that iteration is
done by a region endomorphism which is initially applied to a freshly
constructed pair. This pair can reside in a region which is local to the
body of {\tt llength} (once again, the projection \verb+#2(llength'(l, 0))+
makes sure that the pair does not escape the body of {\tt llength}).
The crucial bit is now which storage mode {\tt llength'} uses 
when it stores \boxml{(xs, acc+1)}.
The only locally live
variable at that point is {\tt llength'} itself and, as we noted above,
{\tt length'} lives in a global region which is clearly different
from the region inside {\tt llength} which contains all the pairs.
Thus storage mode {\tt sat} will be used, as desired.

Finally, consider {\tt glength}, which is similar to {\tt llength}, but
with the crucial difference that {\tt global} is exported from 
the compilation unit. Since {\tt global} may be called from a different
compilation unit, then, for all we know,
{\tt global} may  be applied to a pair which resides in the same
(global) region as {\tt global} itself. Using {\tt sat} when storing
{\tt (xs, acc+1)} would then be a big mistake: it would destroy
the very function we are trying to call! Therefore, the storage mode
analysis assigns {\tt attop} to that storage operation.\footnote{To be
precise, {\tt attop} comes about by using rule (B3) of
Section~\ref{sma.sec}. This example illustrates
why we put edges from formal region parameters to global regions for
exported functions when constructing the region 
flow graph.}
Consequently
we get a memory leak, as shown in the final hump of Figure~\ref{length.region.fig}. 

To sum up, here is how one writes a loop without using space proportional
to the number of iterations:\index{length of list}
\begin{enumerate}
\item The iteration should be done by an auxiliary, uncurried function 
      which is declared as local to the function that uses it; we
      refer (informally) 
      to this auxiliary function as the {\em iterator}.\index{iterator}
\item The iterator should be a region endomorphism and it should 
      be tail recursive;\index{region endomorphism}
\item Iteration should start from a suitably fresh initial argument;
      the result of the iteration should be kept clearly separate
      from the region where the iterator function lies.
\end{enumerate}
Mutual recursion poses no additional complications. All functions
in a block of mutually recursive functions are put in the same region.

Finally, the reader may be concerned that the two recommended
solutions, {\tt klength} and {\tt llength}, seem to be much slower
than the other versions. This is mostly an artifact of the profiling
software, however.\footnote{When profiling is turned on, 
every resetting of a region involves a scan of an entire
region page (typically 1 Kb) and this cost far dominates
the cost of allocating a pair into the region.} To get
a better picture of the actual cost of the different versions, we
compiled the five programs separately (using lists of length 100,000
instead of 10,000) using the HP backend and then 
ran the programs on an HP-9000s700. The results are shown 
in Figure~\ref{length.timing.fig}. Since {\tt upto} alone
takes 0.10 seconds to build the list, the differences 
in times are clear:
the two
programs that reset regions ({\tt klength} and {\tt llength}) are
slower than those that leak space. Writing {\tt attop} into
an infinite region {\tt glength} is only slightly slower than
storing values on the stack ({\tt nlength}). Thus most of the extra
cost of {\tt klength} and {\tt llength} stems from the operation
which resets regions. This extra cost could probably be reduced
significantly by an analysis which discovered that the regions
that have been marked as infinite only ever contain one value
at the time and could therefore be treated as finite regions.

\begin{figure}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}\hline
program      & {\tt upto} & {\tt nlength} & {\tt tlength} & {\tt klength} & {\tt llength} & {\tt glength} \\ \hline
sec. & 0.10 & 0.14 & 0.15 & 0.18 & 0.20 & 0.14\\ \hline
\end{tabular}
\end{center}
\caption{User time in seconds for building a list of 100,000 elements and
computing its length, using five different length functions. {\tt upto} builds
the list, but does not compute a length. Times are average
over three runs.}
\label{length.timing.fig}
\end{figure}

Programming with storage modes is useful if one wants to miniaturise 
programs using the Kit. However, it is often the case that there are only
a few places in the program where resetting is really essential, for example
in some main loop which is supposed to run forever. Therefore, the Kit provides
two operations which the programmer can use to encourage (or force) 
the Kit to perform resetting at particular places in the program. 
These are described in the next
section.

\section{$\resetr$ and $\resetf$}
The programmer can reset regions using the two built-in primitives
\index{resetRegions@{\tt resetRegions}}\index{forceResetting@{\tt forceResetting}}
$$\resetr\; {\it id}$$
and 
$$\resetf\; {\it id}$$
Note that, in both cases, the argument has to be an identifier (more specifically, 
a value variable). To port programs that contain {\tt resetRegions}
and {\tt forceResetting} to other ML systems, simply declare
\begin{verbatim}
       fun resetRegions _ = ()
       fun forceResetting _ = ()
\end{verbatim}
before compiling the program developed using the Kit.

Let $\rho$ be a region variable which occurs free in the type and
place of {\it id}.  Let $m$ be the storage mode determined for $\rho$
at a program point according to the rules of the previous section.
Whether resetting of {\it id} at that program point actually takes
place at runtime, depends on $m$ and on whether resetting is forced,
see Figure~\ref{smamodes.fig}.  
\medskip

\begin{figure}
\begin{center}
Does resetting really take place at runtime?
\begin{tabular}{|l|p{1.0in}|p{1.0in}|}\hline
           & \resetr     & \resetf \\ \hline
$m=\atbot$ & yes      &  yes \\
$m=\sat$   & only if runtime storage mode is {\tt atbot}        &  yes$\ast$ \\
$m=\attop$ & no$\ast$  &  yes$\ast$ \\ \hline
\end{tabular}
\smallskip

($\ast$): A compile-time warning is printed in this case.
\end{center}
\caption{The storage modes that will be used when resetting a region
depending on $m$, the storage mode inferred by the storage mode analysis
and depending on whether the resetting is safe ($\resetr$) or potentially
unsafe ($\resetf$).}
\label{smamodes.fig}
\end{figure}

\section{Example: Improved Mergesort}
\label{improvedmerge.sec}
We can now improve on the mergesort algorithm (Section~\ref{polyrec.sec}) by
taking storage modes into account. \index{merge sort}\index{msort@{\tt msort}}Splitting a list can be done by
an iterative region endomorphism which is made local to the sorting function.
Also, when the input list has been split, it is no longer needed, so the region
it resides in can be reset. Similarly, when the two smaller lists have been sorted
(into new regions) the regions of the smaller lists can be reset. These three simple
observations lead to the following variant of {\tt msort:}\footnote{Project: \boxml{kitdemo/msortreset1.pm}, file \boxml{kitdemo/msortreset1.sml}.}
\medskip

\hrule
\begin{verbatim}

       local
         (* splitting a list *)
         fun split(x::y::zs, l, r) = split(zs, x::l, y::r)
           | split(x::xs, l, r) = (xs, x::l, r)
           | split(p as ([], l, r)) = p

  
         infix footnote
         fun x footnote y = x

         (* exomorphic merge sort *)
         fun msort []  = []
           | msort [x] = [x]
           | msort xs = let val (_, l, r) = split(xs, [], [])
                        in resetRegions xs;
                           merge(msort l footnote resetRegions l, 
                                 msort r footnote resetRegions r)
                        end

       in
         val runmsort = msort(upto(50000))
 
         val result = output(std_out, "Really done\n");
       end
\end{verbatim}
\hrule
\medskip

Unfortunately, the storage mode analysis complains:
\begin{verbatim}
resetRegions(v7038): 
   You have suggested resetting the regions that appear free 
   in the type scheme and place of 'v7038', i.e., in
   (([(int,r2)],[r63],) list,r62)
   (1)                                                    
        'r63': there is a conflict with the locally
        live variable
        l :(([(int,r2)],[r72],) list,r71)
        from which the following region variables can be reached 
        in the region flow graph:
             {r71,r2,r72}
        Amongst these, 'r72' can also be reached from 'r63'.
        Thus I have given 'r63' storage mode "attop".
   (2)                                                    
        'r62': there is a conflict with the locally
        live variable
        l :(([(int,r2)],[r72],) list,r71)
        from which the following region variables can be reached 
        in the region flow graph:
             {r71,r2,r72}
        Amongst these, 'r71' can also be reached from 'r62'.
        Thus I have given 'r62' storage mode "attop".
\end{verbatim}
Here {\tt v7038} turns out to be {\tt xs} (by inspection of the
region-annotated term), so there are two complaints
concerning the first $\resetr$, but none concerning the two remaining
ones.  Consider \boxml{(1)}. By inspecting the region-annotated term
one sees that \boxml{r62} and \boxml{r63} are formal parameters of
{\tt msort}.  Due to the recursive call {\tt msort r}, the region
graph contains an edge from \boxml{r63} to \boxml{r72} and, as pointed
out in \boxml{(2)}, an edge from \boxml{r62} to \boxml{r71}. Thus the
analysis decides on {\tt attop}, using rule (B3) This shows a weakness
in the analysis, for using {\tt sat} would really be sound. (The
problem is that, unlike polymorphic recursion, the region flow graph
does not distinguish between different calls of the same function.)
Seeing that this is the problem, we decide to put $\resetf$ to work,
see Figure~\ref{force.fig}.
\begin{figure}
\hrule
\begin{verbatim}

       local
         (* splitting a list *)
         fun split(x::y::zs, l, r) = split(zs, x::l, y::r)
           | split(x::xs, l, r) = (xs, x::l, r)
           | split(p as ([], l, r)) = p

  
         infix footnote
         fun x footnote y = x

         (* exomorphic merge sort *)
         fun msort []  = []
           | msort [x] = [x]
           | msort xs = let val (_, l, r) = split(xs, [], [])
                        in forceResetting xs;
                           merge(msort l footnote resetRegions l, 
                                 msort r footnote resetRegions r)
                        end

       in
         val runmsort = msort(upto(50000))
 
         val result = output(std_out, "Really done\n");
       end
\end{verbatim}
\caption{Using {\tt forceResetting} to reset regions.}
\medskip
\hrule
\label{force.fig}
\end{figure}
The region profile of the improved merge sort appears in 
Figure~\ref{msortreset.fig}. Note that, as expected, we have
now brought space consumption down from four times to two times the size of the
input. 
Figure~\ref{msortreset.fig}
may be compared to Figure~\ref{msort.fig}, page~\pageref{msort.fig}.

\begin{figure}
\begin{center}
\includegraphics{msortreset2.ps}
\end{center}
\caption{Region profiling of the improved mergesort. 
The two upper trianges contain unsorted elements, while the
two lower triangles contain sorted elements.
Project: \boxml{kitdemo/msortreset2.pm},
file \boxml{kitdemo/msortreset2.sml}; program compiled with
profiling enabled and then run with the command
\boxml{run -microsec 100000}. The picture \index{region.ps@{\tt region.ps}}(\boxml{region.ps}) 
was generated by the \index{sampleMax@{\tt sampleMax}}\index{eps file}\index{rp2ps@{\tt rp2ps}}command: \boxml{rp2ps -region -sampleMax 1000 -eps 120 mm}
and then pre-viewed using the command \boxml{ghostview region.ps}~.}
\label{msortreset.fig}
\end{figure}

\section{Example: Scanning Text Files}
In this section we present a program which can 
\index{scan@{\tt scan}}scan a sequence of Standard ML source
files in order to compute what percentage of the source files is made
up by comments. Recall that an ML comment begins with the two
characters {\tt (*}, ends with {\tt *)} and that comments may be
nested but must be balanced (within each file, we require).

The obvious solution to this problem is to implement an
automaton with counters to keep track of the level
of nesting of parentheses, number of characters read and
number of characters within comments. This provides an interesting test
for region inference: although designed with the lambda calculus
in mind, does the scheme cope with good old-fashioned state
computations? 

Let us be ambitious and write a program which only ever holds on to one character at a
time when it scans a file. In other words, the aim is to use constant space (i.e., space
consumption should be independent of the length of the input file).

To this end, let us arrange to use a region with infinite multiplicity to
hold the current input character and then reset that region before we proceed
to the next character. The iteration is done by tail recursion, using region
endomorphisms to ensure constant space usage.

The bulk of the program appears below. The scanning of a single
file is done by {\tt scan}, which contains three mutually recursive
region endomorphisms ({\tt count}, {\tt after\_lparen} and
{\tt after\_star}) written in accordance with the guidelines
in Section~\ref{length.sec}. The built-in {\tt input} function understands
storage modes: if called with storage mode {\tt atbot} it will reset the region
where the string should be put before reading the string from the input.
Consequently, at every call of {\tt next}, the ``input buffer region'' will be reset.

The other important loop in the program is {\tt driver}, a function which
repeatedly reads a function name from a given input stream, opens the file
with that name and calls {\tt scan} to process the file. Once again, we
want to keep at most one file name in memory at a time, so we would like
the region containing the file name to be reset upon each iteration.
As it turns out, our {\tt readWord} will always store the string it
creates at the top of the region in question. The reason is that
it calls {\tt implode}, which is declared in and exported from 
the prelude. It is {\tt implode} which always stores {\tt attop}, by
rule B3 and the fact that formal region parameters of exported functions
are connected to global regions in the region flow graph. 
Thus the two occurrences of resetRegions are necessary. In general,
when splitting a program unit into two, one may have 
to insert explicit $\resetr$ into the second unit, when operations from the
first unit are called. 

\bigskip
\hrule
\begin{verbatim}
local
  exception NotBalanced
  fun scan(is: instream) : int*int =
    let
      fun next() = input(is, 1)
      fun up(level,inside) = if level>0 then inside+1 
                             else inside

      (* n: characters read in 'is'
         inside: characters belonging to comments
         level : current number of unmatched (* 
         s     : next input character or empty *)
         count is endo *)
      fun count(p as (n,inside,level,s:string))=
        case s of
          "" => (* end of stream: *) p  
        | "(" => after_lparen(n+1,inside,level,next())
        | "*" => after_star(n+1,up(level,inside),level,next())
        | ch  => count(n+1,up(level,inside), level,next())
      and after_lparen(p as (n,inside,level,s))=
        case s of
          "" => p
        | "*" => count(n+1,inside+2, level+1,next())
        | "(" => after_lparen(n+1, up(level,inside), level,next())
        | ch => count(n+1,up(level,up(level,inside)),level,next())
      and after_star(p as (n,inside,level,s)) =
        case s of
          "" => p
        | ")" => if level>0 then
                    count(n+1,inside+1,level-1,next())
                 else raise NotBalanced
        | "*" => after_star(n+1,up(level,inside), level,next())
        | "(" => after_lparen(n+1,inside,level,next())
        | ch  => count(n+1,up(level,inside),level,next())
    
      val (n, inside,level,_) = count(0,0,0,next())
    in
     if level=0 then (n,inside) else raise NotBalanced
    end
  
  fun report_file(filename, n, inside) = 
      writeln(implode[filename , ": size = " , toString n , 
               " comments: ", toString inside, " (",
               toString(percent(inside, n)) handle Quot => "", 
               "%)"]);

  (* scan_file(filename) scans through the file named
     filename returning either Some(size_in_bytes, size_of_comments)
     or, in case of an error, None. In either case a line of
     information is printed. *)

  fun scan_file (filename: string) : (int*int)Option=
   let val is  = open_in filename 
   in let val (n,inside)  = scan is
      in close_in is; 
         report_file(filename, n, inside);
         Some(n,inside)
      end handle NotBalanced => 
          (writeln(filename ^ ": not balanced");
           close_in is;
           None)
   end handle Io msg  => (writeln msg; None)
  
  fun report_totals(n,inside) = 
       writeln(implode["\n\nTotal sizes: ", toString n, 
            " comments: ", toString inside,
            " (", toString(percent(inside,n)) handle Quot => "",
            ")%"])

  (* main(is) reads a sequence of filenames from is,
     one file name pr line (leading spaces are skipped;
     no spaces allowed in file names). Each file is 
     scanned using scan_file after which a summary
     report is printed *)

  fun main(is: instream):unit =
  let 
    fun driver(p as(None,n,inside)) = 
           (report_totals(n, inside); p)
      | driver(p as (Some filename,n:int,inside:int)) =
          driver(case scan_file filename of
                   Some(n',inside') =>
                   (resetRegions p; 
                    (readWord(is), n+n',inside+inside'))
                | None => (resetRegions p;
                           (readWord(is),n,inside)))
  in
    driver(readWord(is),0,0);
    ()
  end

in 
  val result = main(std_in)
end
\end{verbatim}
\hrule
\bigskip

The program was compiled\footnote{Project: \boxml{kitdemo/scan.pm}.} both
with and without profiling turned on. The output from running the
program on 10 files listed in the \boxml{ML\_CONSULT}
file of the Kit is shown below
\begin{verbatim}
     Parsing/INFIX_STACK.sml: size = 585 comments: 417 (71%)
     Parsing/InfixStack34g.sml: size = 7641 comments: 3120 (40%)
     Parsing/Infixing34g.sml: size = 28389 comments: 4645 (16%)
     Parsing/LEX_BASICS.sml: size = 2102 comments: 1334 (63%)
     Parsing/LEX_UTILS.sml: size = 1294 comments: 399 (30%)
     Parsing/LexBasics36e.sml: size = 11674 comments: 2968 (25%)
     Parsing/LexUtils33b.sml: size = 7566 comments: 1834 (24%)
     Parsing/MyBase.sml: size = 33735 comments: 10896 (32%)
     Parsing/PARSE.sml: size = 1151 comments: 644 (55%)
     Parsing/Parse34g.sml: size = 6926 comments: 924 (13%)


     Total sizes: 101063 comments: 27181 (26)%
\end{verbatim}
A region profile for that run is shown in Figure~\ref{scan.fig}.  The
almost-constant space usage is evident. The occasional disturbances
are due to the non-iterative functions which read a file name from
input by first reading one line and then extracting the name.
\begin{figure}
\begin{center}
\includegraphics{scan.ps}
\end{center}
\caption{Region profiling of the scanner. Note that the unit of measure on 
the y-axis is bytes, not kilobytes. The occasional increase is due to the
functions which read a file name from an instream. Project: \boxml{kitdemo/scan.pm}.
The program was compiled with profiling enabled, then run by the
unix command \boxml{run -microsec 100000 < ../../kitdemo/scanfiles}. A postscript
picture (\boxml{region.ps}) can be generated by the unix command
\boxml{rp2ps -region -sampleMax 1000 -eps 120 mm}.
}
\label{scan.fig}
\end{figure}
%
%
\chapter{Higher-Order Functions}
\label{hof.sec}
%
\section{Lambda-Abstraction ({\tt fn})}
A {\em lambda abstraction} \index{lambda abstraction}\index{function!higher-order}in Standard ML is an expression of the
form 
$$\boxml{fn {\it pat} => {\it exp}}$$
where {\it pat} is a pattern and {\it exp} an expression.
Lambda expressions denote functions. We refer to the {\it exp} as the
{\em body} of the function; variable occurrences in {\it pat} are
binding occurrences; informally, the variables that occur
in {\it pat} are said to be {\em lambda-bound} with scope {\it exp}.\index{variable!lambda-bound} 

Lambda-abstractions are represented by closures, both in the language
definition and in the Kit. In the Kit, a closure for a lambda abstraction
consists of a code pointer plus one word for each free variable of the
lambda abstraction. Closures are not tagged. 

At this stage, it will hardly come as a surprise to the reader that closures are stored
in regions.  Sometimes they reside in finite regions on the stack, other times
they live in infinite regions, just like all other boxed values.

Every occurrence of {\tt fn} \index{fn@{\tt fn}}in the program is considered 
an allocation point; the region-annotated version of the lambda abstraction is
$$\boxml{fn at $\rho$ {\it pat} => {\it exp}}$$
Standard ML allows  functions to be declared using {\tt val} rather than {\tt fun}, e.g., 
\begin{verbatim}
       val h = g o f
\end{verbatim}
Whereas functions declared with \index{fun@{\tt fun}}{\tt fun} automatically become region polymorphic,
functions declared with \index{val@{\tt val}}{\tt val} do not in general become \index{region polymorphism}
region-polymorphic.\footnote{The reason for this
is that the expression on the right-hand side of the value declaration might have an effect (e.g, 
print something) before returning the function. It would not be correct to suspend this effect by
introducing formal region parameters.} However, in the special case where the right-hand side of
the value declaration is a \index{lambda abstraction}lambda abstraction, the Kit automatically converts the declaration
into a {\tt fun} declaration, thereby making the function region polymorphic after all.

ML allows declarations of the form\index{fun@{\tt fun}}
$$\boxml{fun $f$ $\atpat_1\,\atpat_2 \cdots \atpat_n$ = $\exp$}$$
as a shorthand for 
$$\boxml{fun $f$ $\atpat_1$ => fn $\atpat_2$ => $\cdots$ fn $\atpat_n$ => $\exp$}$$
where $\atpat$ ranges over atomic patterns.
We say that functions declared using this abbreviation are \index{function!Curried}{\em Curried}. 
\section{Region-Annotated Function Types}
\label{functiontypes.sec}
The general form of a region-annotated \index{function type!region-annotated}\index{type!region-annotated}function type is
$$\mu_1\ar{\epsilon.\rea}\mu_2$$
where $\mu_1$ is the region-annotated type and place of the argument
and $\mu_2$ is the region-annotated type and place of the result. A region-annotated
function type with place takes the form 
$$(\mu_1\ar{\epsilon.\rea}\mu_2, \rho)$$
where $\rho$ is the region containing the closure.
As mentioned in Section~\ref{listtypes.sec}, the unusual looking object
$\epsilon.\rea$ is called an \index{arrow effect}{\em arrow effect}. Its first component
is an \index{effect variable} effect variable, whose purpose will be explained shortly.
The second component is called the \index{effect!latent}{\em latent effect}, and describes
the effect of evaluating the body of the function. 

The following example illustrates why latent effects are crucial for
knowing the lifetimes of closures.\footnote{Project: \boxml{kitdemo/lambda.pm},
file \boxml{kitdemo/lambda.sml}.} Consider
\begin{verbatim}
       val n = let val f = let val xs = [1,2]
                           in fn ys => length xs + length ys
                           end
               in f [7]
               end
\end{verbatim}
Note that {\tt xs} has to be kept alive for as long as the
function {\tt fn ys => $\cdots$}~ may be called, for this function
will access {\tt xs}, when called.
The region-annotated version appears in Figure~\ref{lambda1.fig}.  (To
see the output programs discussed in this section, enable the flag
\texttt{print drop regions expression} and look under the heading
{\tt Report: AFTER DROP REGIONS}.)
\begin{figure}
\hrule
\begin{verbatim}

   let val n = 
       letregion r7:1, r9:INF, r10:1, r11:INF, r12:INF 
       in let val f = 
              let val xs = 
                  let val v9260 = 
                      (1, 
                       let val v9261 = (2, nil at r11) at r12
                       in  :: at r11 v9261
                       end 
                      ) at r12
                  in  :: at r11 v9260
                  end 
              in   fn at r7 ys => 
                   letregion r16:1 in length[] xs end + 
                   letregion r18:1 in length[] ys end
              end 
          in  f 
              let val v9257 = (7, nil at r9) at r10
              in  :: at r9 v9257
              end 
          end  
       end
   in  {|n: (_,r2)|}
   end 
\end{verbatim}
\caption{Region-annotated program illustrating that the lifetime of
a closure is at least as long as the lifetime of the values that evaluation
of the function body will require.}
\medskip
\hrule
\label{lambda1.fig}
\end{figure}
We see that {\tt xs} is put in {\tt r11} and {\tt r12}, that the
function closure for \boxml{(fn ys => $\cdots$)} is put in {\tt r7}
and indeed, {\tt r7}, {\tt r11} and {\tt r12} all have the
same lifetime. To understand how the region inference system figured that out, 
let us consider the effect and the 
region-annotated type of particular sub-expressions. Looking at the lambda
abstraction, it must have a functional type of the form 
$(\mu\ar{\epsilon.\rea}\mu', {\tt r7})$ where $\rea$ is the
effect
$$\{\Get(\boxml{r1}), \Get(\boxml{r2}), \Get(\boxml{r11}), 
    \Get(\boxml{r12}), \Get(\boxml{r9}),
    \Get(\boxml{r10}), \Put(\boxml{r2})\}$$
Note that \boxml{r11} and \boxml{r12} occur free in the type of the
lambda abstraction. But, as pointed out in Section~\ref{effects.sec},
the criterion
for putting ~~{\tt letregion $\rho$ in $\ldots$ end}~~ around an expression $e$
is that $\rho$ occurs free neither in the region-annotated type and place of $e$ nor
in the region-annotated type scheme and place of any variable in the domain of the
type environment.\index{region!de-allocation} The smallest sub-expression
of the program for which {\tt r11} and {\tt r12} does not occur free in
the type and place of the expression is the right-hand side 
of the {\tt val}-binding of {\tt n}, for that expression
simply has region-annotated type and place $\boxml{(int,r2)}$.
And at that point, the only region variables that occur free in
the type environment are global region variables.
Hence the placement of the letregion-binding of {\tt r11} and
{\tt r12}.

\section{Arrow Effects}
In a first-order language, effect variables might not be particularly important.
But in a higher-order language like ML, effect variables are useful for tracking
dependencies between functions. The following example illustrates the point:\footnote{Project: \boxml{kitdemo/lambda.pm}, files
\boxml{kitdemo/lambda1.sml} and \boxml{kitdemo/lambda2.sml}.}
\begin{verbatim}
       fun apply f x = f x
       val y = apply (fn n => n+1) 5
       val z = apply (fn m => m) 9
\end{verbatim}
Here is the region type scheme of {\tt apply}:
\begin{tabbing}
\qquad$\forall\alpha_1\alpha_2\rho_1\rho_2\rho_3\rho_4\epsilon_1\epsilon_2\epsilon_3.$\=$((\alpha_1,\rho_1)
        \ar{\epsilon_1.\emptyset}(\alpha_2,\rho_2),\rho_3)\ar{\epsilon_2.\{\Put(\rho_4)\}}$\\
            \>$((\alpha_1,\rho_1)\ar{\epsilon_3.\{\Get(\rho_3), \epsilon_1\}}(\alpha_2,\rho_2),\rho_4)$
\end{tabbing}
The latent effect associated with $\epsilon_2$ shows that when {\tt apply} is applied to a function,
it may create (in fact: will create) a function closure in $\rho_4$.  The latent effect associated with
$\epsilon_1$ is empty, since the declaration of {\tt apply} does not tell us anything about what effect
the formal parameter {\tt f} must have. Crucially,  however, $\epsilon_1$ is included as an atomic effect
in the latent effect associated with $\epsilon_3$: whenever the body of {\tt apply f} is evaluated, the
body of {\tt f} may be (in fact: will be) evaluated.

The polymorphism in effects makes it possible to distinguish between the latent effects of different
actual arguments to {\tt apply}. For example, the functions {\tt fn n => n+1} and {\tt fn m => m}
have different latent effects. Let us take {\tt fn n => n+1} as example. It has function type and place
\begin{equation}
\label{suc.lab}
((\boxml{int},\rho_2)\ar{\epsilon_5.\{\Get(\rho_2),\Put(\rho_2)\}}(\boxml{int}, \rho_2), \rho_5)
\end{equation}
Here we have assumed that integers always live in $\rho_2$, while $\epsilon_5$ and $\rho_5$ were
chosen arbitrarily. The region inference algorithm discovers that (\ref{suc.lab}) is an instance
of $((\alpha_1,\rho_1)
        \ar{\epsilon_1.\emptyset}(\alpha_2,\rho_2),\rho_3)$ from the type scheme for {\tt apply} 
under the instantiating substitution
\begin{tabbing}
$S =($\=$\{\alpha_1\mapsto\boxml{int},\alpha_2\mapsto\boxml{int}\},\{
       \rho_1\mapsto\rho_2,\rho_2\mapsto\rho_2,\rho_3\mapsto\rho_5\},$\\
\>$\{
       \epsilon_1\mapsto\epsilon_5.\{\Get(\rho_2),\Put(\rho_2)\})$
\end{tabbing}
Formally, a \index{substitution}{\em substitution} is a triple $(\St,\Sr,\Se)$,
where $\St$ is a map from type variables to types, $\Sr$ is a finite map from region variables
to region variables and $\Se$ is a map from effect variables to arrow effects.
Although we shall not define what it means to apply a  substitution to a
type in this document, 
let us explain why substitutions map effect variables to arrow effects. 
One alternative, one might consider, is to let substitutions map effect variables to effect
variables. But then substitutions would not be able to 
account for the idea that
effects can ``grow'', when instantiated. In the {\tt apply} example, for instance, the
empty effect associated with $\epsilon_1$ has to grow to $\{\Get(\rho_2),\Put(\rho_2)\}$ at the
concrete application of {\tt apply} (otherwise, as it is easy to demonstrate, 
the region inference system would become unsound). 

Another alternative would be to let substitutions
map effect variables to effects. But that would not work well together with the idea of
using substitutions to express ``growth'' of effects either. For example, applying the
map $\{\epsilon\mapsto\{\Get(\rho_0),\Put(\rho_2)\}\}$ to the effect $\{\Get(\rho_9),\epsilon\}$,
say, 
would presumably yield the effect $\{\Get(\rho_9),\Get(\rho_0),\Put(\rho_2)\}$ in which the fact
that the original effect had to be at least as large as whatever $\epsilon$ stands for, is lost.
Instead, we define substitution so that applying the effect substitution
$\{\epsilon\mapsto\epsilon.\{\Get(\rho_2),\Put(\rho)\}\}$ to 
$\{\Get(\rho_9),\epsilon\}$ yields $\{\Get(\rho_9),\epsilon,\Get(\rho_2),\Put(\rho)\}$.

We can now give a complete definition of atomic effects. 
An \index{effect!atomic, definition}{\em atomic effect} is either an effect
variable or a term of the form $\Get(\rho)$ or $\Put(\rho)$, where $\rho$ as usual ranges over region
variables. An \index{effect!definition}{\em effect} is a finite set of atomic effects.

One can get the Kit to print region-annotated \index{type!region
  annotated}\index{region type scheme!printing of}types of all binding
occurrences of value variables.  Also, one can choose to have arrow
effects included in the printout: Enable the flags~~\texttt{print
  types}~~and~~\texttt{print effects}~~in the \texttt{Layout} menu.
Although this gives very verbose output, it is instructive to look at
such a term just once, to see how arrow effects are
instantiated. We show the full output for the {\tt apply} example in
Figure~\ref{lam2.fig}. In reading the output it is useful to know that
the Kit represents effects and arrow effects as graphs, the nodes of
which are region variables, effect variables $\Put$, $\Get$ or
\boxml{U} (for ``union''; \boxml{U} by itself means the empty set). 
Region variables are leaf nodes. A $\Put$
or $\Get$ node has emanating from it precisely one edge; it leads to
the region variable in question.  An effect variable node (written
{\tt e} followed by a sequence number) is always the handle of an
arrow effect; there are edges from the effect variable to the atomic
effects of that arrow effect, either directly, or via union nodes or
other effect variable nodes.  For instance, \texttt{e14(U)} in the
figure denotes an effect variable with an edge to an empty union node.
When a term containing arrow effects is printed, shared nodes that
have already been printed are marked with a \boxml{@}; their children
are not printed again.  For instance, in the figure, the second
occurence of \texttt{r2} is printed as \boxml{@r2}.  The binding
occurrence of {\tt apply} has been printed with its region type
scheme. Each non-binding occurrence of { \tt apply} has been printed
with four square-bracketed lists: The first list is the actual region
arguments; the following three are ``instantiation lists'' that show
the range of the substitution by which the bound variables of the type
scheme was instantiated, in the same order as the bound variables
occurred.  For example, in the second use of {\tt apply}, \boxml{r8}
was instantiated to {\tt r17}.

\begin{figure}
\hrule
\begin{verbatim} 

       fun apply 
           :all 
               'a34,'a32,r7,r8,r9,r10,e11,e12,e13.
               (((('a32,r10)-e11->('a34,r9)),r8)
                -e12(put(r7))->
                ((('a32,r10)-e13(U(U,get(r8),e11))->('a34,r9)),r7)
               ) 
           at r1 
           [r7:1] 
           (f)= 
           fn e13 at r7 x:('a32,r10) => f x

       val y:(int,r2) = 
           letregion r9:1, r10:1 
           in  letregion r11:1 
               in apply
                   [r9] 
                   [int,int] 
                   [r9,r10,r2,r2] 
                   [e7(U(get(r2),get(r1),put(@r2))),
                    e12(put(r9)),
                    e8(e7(U(get(r2),get(r1),put(@r2))),get(r10))
                   ]
                  at r11 
                  (fn e7 at r10 n:(int,r2) => n + 1) 
               end
               5 
           end
       val z:(int,r2) = 
           letregion r16:1, r17:1 
           in  letregion r18:1 
               in apply
                   [r16] 
                   [int,int] 
                   [r16,r17,r2,r2] 
                   [e14(U),e19(put(r16)),e15(e14(U),get(r17))]
                  at r18 
                  (fn e14 at r17 m:(int,r2) => m) 
               end
               9 
           end
\end{verbatim}
\caption{The instantiation of arrow effects keeps different applications of
  the same function (here {\tt apply}) apart. (Project
  \boxml{kitdemo/lambda.pm}, files: \boxml{kitdemo/lambda1.sml} and
  \boxml{lambda2.sml}.)}
%       fun apply at r1: 
%         all 
%           'a290,'a288,r7,r8,r9,r10,e11,e12,e13.
%           (((('a288,r10)-e11->('a290,r9)),r8)
%                          -e12(put(r7))->
%            ((('a288,r10)-e13(U(U,get(r8),e11))->('a290,r9)),r7)
%           )
%           []
%           (f) = 
%           fn e13 at r7 x:('a288,r10) => f x
%       val y:(int,r2) = 
%           letregion r9:1, r10:1 
%           in  letregion r11:1 
%               in apply(
%                   [int,int], 
%                   [r9,r10,r2,r2], 
%                   [e7(U(get(r2),get(r1),put(@r2))),
%                    e12(put(r9)),
%                    e8(e7(U(get(r2),get(r1),put(@r2))),get(r10))
%                   ]
%                  ) at r11 
%                  (fn e7 at r10 n:(int,r2) => n + 1) 
%               end (*r11:1*) 
%               5 
%           end (*r9:1, r10:1*); 
%       val z:(int,r2) = 
%           letregion r16:1, r17:1 
%           in  letregion r18:1 
%               in apply(
%                   [int,int], 
%                   [r16,r17,r2,r2], 
%                   [e14(U),e19(put(r16)),e15(e14(U),get(r17))]
%                  ) at r18 
%                  (fn e14 at r17 m:(int,r2) => m) 
%               end (*r18:1*) 
%               9 
%           end (*r16:1, r17:1*)
\medskip
\hrule
\label{lam2.fig}
\end{figure}
\section{Region-Polymorphic Recursion and Higher-Order Functions}
Unlike identifiers bound by {\tt fun}, lambda-bound function identifiers
are never region-polymorphic. So in an expression of the form
$$\boxml{(fn f => $\cdots$ f $\cdots$ f $\cdots$)}$$
all the uses of $\boxml{f}$ use the same regions. Indeed, since \boxml{f}
occurs free in the type environment while region inference analyses the body of the lambda abstraction,
none of the regions which appear in the type of \boxml{f} will be de-allocated inside the body
of the lambda abstraction. Also, such a region
must be bound outside the lambda abstraction, so
any attempt to 
reset such a region inside the body of the abstraction
will cause the storage mode analysis to complain (by Rule (B1) of Section~\ref{sma.sec}).

Therefore, when a function $f$ is passed as argument to another function, $g$,
$$g(f)$$
first regions are allocated for the use of $f$, then $g$ is called and finally
the regions are de-allocated (provided they are not global regions). 
Whether the {\tt letregion} construct thus introduced encloses the call site
immediately
$$\boxml{letregion $\rho_1,\ldots,\rho_n$ in $g$($f$) end}$$
or further out
$$\boxml{letregion $\rho_1,\ldots,\rho_n$ in $\ldots$ $g$($f$) $\ldots$  end}$$
depends on the type and effect of the expression \boxml{$g$($f$)} in the usual way:
regions can be de-allocated when they   occur free neither in the type
of the expression nor in the type environment.

\section{Examples: {\tt map} and {\tt foldl}}
Consider\footnote{Project: \boxml{kitdemo/lambda.pm},
files \boxml{kitdemo/lambda3.sml} and \boxml{kitdemo/lambda4.sml}.}
\begin{verbatim}
     fun map f [] = []
       | map f (x::xs) = f(x) :: map f xs
    
     val x = map (fn x => x+1) [7,11]
\end{verbatim}
The above formulation of {\tt map} is not the most efficient one in the Kit, 
since it will create one closure for each element in the list, due
to currying.\footnote{When {\tt map} and
the application of {\tt map} appear in the same compilation unit, 
the Kit will automatically specialise {\tt map}
to a recursive function which does not have this defect. 
(This it the result of a general optimisation of curried, closed functions
that have a constant argument.)
The output we present in this section was obtained
by putting {\tt map} in a compilation unit of its own.} However it serves to
illustrate the point made in the previous section about allocating regions in 
connection with higher-order functions. The region-annotated version is seen
in Figure~\ref{lam3.fig}.
\begin{figure}
\hrule
\begin{verbatim}

       fun map at r1 [r7:1, r8:0, r9:0] (var932)= 
           fn at r7 var933 => 
           (case var933 
            of nil => nil at r8
            |  :: => 
               let val v10434 = decon_:: var933; 
                   val x = #0 v10434; 
                   val xs = #1 v10434; 
                   val v10439 = 
                       (var932 x, 
                        letregion r21:1 
                        in  letregion r22:1 
                            in map[r21,r8,r9] at r22 var932 
                            end
                            xs 
                        end
                       ) at r9
               in  :: at r8 v10439
               end 
           ) (*case*) 

       val x = 
           letregion r9:1, r10:INF, r11:INF, r12:1 
           in  letregion r13:1 
               in map[r9,r1,r1] at r13 (fn at r12 x => x + 1) 
               end
               let val v10465 = 
                       (7, 
                        let val v10466 = (11, nil at r10) at r11
                        in  :: at r10 v10466
                        end 
                       ) at r11
               in  :: at r10 v10465
               end  
           end
\end{verbatim}
\caption{Although this version of {\tt map} creates a closure for
  each list element, the region-polymorphic recursion (of {\tt map})
  ensures that that closure is put in a region local to {\tt map}.
  Thus these closures do not pile up in {\tt r12}, the region of the
  initial argument.} 
\medskip \hrule
\label{lam3.fig}
\end{figure}
We see that the regions that appear free in the type and place of the successor
function (i.e., \boxml{r2} and \boxml{r12}) must be allocated prior 
to the call of {\tt map} and that they stay
alive throughout the evaluation of the body of {\tt map}. Note, however, that
the closures that are created when {\tt map} is applied do not pile up in
{\tt r12}, the region of the successor function. Instead, they are put
in local regions bound to {\tt r22}, one closure in each region. 
Also, if we had given some
more complicated argument to {\tt map}, the body of that function could have
{\tt letregion} expressions. For each list element, regions would then be
allocated, used and then de-allocated before proceeding to the next list element.

So it might appear that higher-order functions are nothing to worry about when
programming with regions. That is not so, however. The limitation that lambda-bound
functions are never region-polymorphic can lead to space leaks. Here is an example:
\begin{verbatim}
       fun foldl f acc [] = acc
         | foldl f acc (x::xs)  = foldl f (f(x,acc)) xs

       val x = foldl (fn (x,acc) => 10*acc+x) 0 [7,2];
\end{verbatim}
Since {\tt f} is lambda-bound, all the pairs created by the expression \boxml{(x,acc)}
will pile up in the same region. The storage mode analysis will infer storage mode {\tt attop}
for the allocation of the pair, by rule (B1) of Section~\ref{sma.sec}: since {\tt foldl} is
curried, 
there are several lambdas between the formal region parameter of {\tt foldl} which indicates
where the pair should be put, and the allocation point of the pair.

It does not help to uncurry {\tt foldl} and turn {\tt foldl} into a region endomorphism: 
\begin{verbatim}
       fun foldl(p as (f,[],_)) = p
         | foldl(f,x::xs,acc) = foldl(f,xs,f(x,acc))

       val x = #3(foldl(fn(x,acc) => 10*acc+x,[7,2],0));
\end{verbatim}
The storage mode analysis will still give {\tt attop} for
the allocation of the pair \boxml{(x,acc)}, for
the region of the pair is free in the type of \boxml{f},
which is locally live at that point.

The solution is to require that {\tt f} be curried, to avoid the creation of the pair altogether, i.e, going to higher order
rather than lower:
\begin{verbatim}
       fun foldl f b xs = 
         let fun loop(p as ([], b))= p
               | loop(x::xs, b) = loop(xs,f x b)
         in
             #2(loop(xs,b))
         end
\end{verbatim}
The region-annotated version appears in Figure~\ref{foldl.fig}
(page~\pageref{foldl.fig}).

\chapter{The function call}
Standard ML allows function applications of the form
$$\exp_1 \exp_2$$
where $\exp_1$ is the operator and $\exp_2$ is the operand.
The syntax for  function application is overloaded, in that it is used
for  three different purposes in ML:
\begin{enumerate}
\item application of built-in operations such as \boxml{+}, \boxml{=}, \boxml{:=};
\item application of a value constructor (including {\tt ref}) or an exception constructor;
\item application of user-defined functions, i.e., functions that
are introduced by {\tt fn} or {\tt fun};
\end{enumerate}
This chapter is about the last kind of function application; in this chapter,
we use the term function application to stand for application of user-defined functions
only.

Function applications are ubiquitous in Standard ML programs; in particular, iteration
is often achieved by function calls. Not surprisingly, careful compilation of 
function calls is essential for obtaining
good performance. 

The Kit partitions function calls into four kinds, which are implemented in different ways.
At best, a function call is simply realised by a jump in the target code. 

The resource conscious programmer will want to know the special cases; for example,
when doing an iterative computation, it is important to know whether the space usage
is going to be independent of the number of iterations. 

In this section we enumerate the cases recognized by the Kit and show how one can
check whether specific function calls in the code turn out the way one intended.

The Kit performs a backwards flow analysis, called \index{call conversion}{\em call conversion},
to determine which function calls are tail calls and, more generally, which function calls fall
into the special cases listed below. We say that expressions produced
by this analysis are \index{function call!call-explicit}{\em
  call-explicit}.\label{call-explicit}

One can inspect call-explicit programs by enabling the flag\index{print call-explicit expression@{\tt print call-explicit expression}} 
$$\boxml{print call-explicit expression}$$
in the menu~~ \texttt{Printing of intermediate forms}.
Call-explicit expressions are produced after regions have been dropped
(page~\pageref{bother-to-distinguish-get-n-put}) but before generation of KAM code.

We shall first give a brief description of the parameter passing mechanism in general
and then discuss the different kinds of function calls provided, working our way from 
the most specialised (and most efficient) cases towards the default  cases.
\section{Parameter Passing}
There is one (and so far only one) \index{register}register which is used for passing arguments
to functions. It is called \index{standardArg@{\tt standardArg}}{\tt stardardArg}. In addition, region-polymorphic functions
use another fixed register, 
called \index{standardArg1@{\tt standardArg1}}{\tt standardArg1}\footnote{Admittedly, not terribly good nomenclature.},
which points to the record of region parameters which the caller has allocated prior to the call.
\section{Tail Calls}
\label{tailcall.sec}
A call which is the last action of a function is 
referred to as a {\em tail call}. After region inference, the Kit performs a 
tail call analysis (in one backwards scan through the program). It is significant that
the tail call analysis happens after region inference: 
as we saw in Section~\ref{length.sec}, a function call that
looks like a tail call in the 
source program may end up as a non-tail call in the
region-annotated program, because the function  has to return 
in order to free memory.
\section{Simple Jump ({\tt jmp})}
\label{simplejump.sec}
In this section we shall consider conditions under which one can
implement a function call as a simple \index{jump}\index{jmp@{\tt jmp}}\index{region polymorphism}jump. A call of a region-polymorphic
function takes the form \boxml{$f$ [$\rho_1$, $\ldots$, $\rho_n$] at $\rho_0$ $\exp$} where $\rho_0$ is the region which holds the region vector
containing the actual region parameters $\rho_1$, $\ldots$, $\rho_n$. 
During \index{K-normalisation}K-normalisation, the Kit tries to bring the creation of $\rho_0$ close to the point of
the call. Therefore, an important case to consider is a call of the form
\begin{equation}
\label{ntcall}
\boxml{letregion $\rho_0$ in $f$ [$\rho_1$, $\ldots$, $\rho_n$] at $\rho_0$ $\exp$ end}\quad (n\geq0)
\end{equation}
where $f$ is the name of a region-polymorphic function.

The Kit simplifies this expression to a simple jump
$$\boxml{jmp $f$ $\exp$}$$
if the following conditions are met:
\begin{enumerate}
  \item \label{cond1}
    the call is a tail call; and
  \item \label{cond2}
    one has 
      \begin{enumerate}
         \item \label{cond2a} $n=0$; or
         \item \label{cond2b} the call occurs 
               inside the body of some region-polymorphic
               function $g$ and
                 \begin{enumerate}
                   \item \label{cond2ba}
                       the actual region parameters 
                       $\rho_1$, $\ldots$, $\rho_n$ are a prefix
                       of the formal region parameters of $g$, 
                       i.e., the list of formal region parameters of $g$
                       is \boxml{[}$\rho_1$, $\ldots$, $\rho_n$, 
                       $\rho_{n+1}$, $\ldots$, $\rho_{n+k}$\boxml{]}, 
                       for some
                       $\rho_{n+1}$, \ldots, $\rho_{n+k}$; and 
                   \item \label{cond2bb}
                       the closest surrounding $\lambda$ of the call 
                       is the $\lambda$ that starts the
                       right-hand side of $g$.
                  \end{enumerate}
       \end{enumerate}
\end{enumerate}
The start address of $f$ is known during compilation (since
$f$ is region polymorphic). Thus such a function call
is as efficient as an assembly language {\tt goto} to a constant
label.

To understand the above requirements, 
note that if the region $\rho_0$ really has to be created (be
it on the stack or as an infinite region) then the call $f$ cannot
be treated as a tail call, for $f$ has to return to de-allocate
$\rho_0$. Now (\ref{cond2a}) is one way of ensuring
that there is no need to allocate $\rho_0$. A different way
is given by (\ref{cond2b}). The idea is to re-use the region vector
of the function $g$ in which the call of $f$ occurs (a common special case
is that $g$ is $f$). Condition (\ref{cond2ba}) ensures that the
actual region parameters of $f$ coincide with (a prefix of) the formal
parameters of $g$. Finally, (\ref{cond2bb}) is necessary in order to
ensure that the region vector of $g$ really is available when $f$
is called.

To understand (\ref{cond2bb}) in more detail, consider the example
\begin{verbatim}
   fun g[r](x) = 
     h[r1] (fn y => letregion r2 in f[r] at r2 y end),
\end{verbatim}
which one might think of as sugar for 
\begin{verbatim}
   val rec g[r] = fn x => 
     h[r1] (fn y => letregion r2 in f[r]at r2 y end).
\end{verbatim}
Here the call to \boxml{f} will not be implemented by a {\tt jmp}, for
there is a \boxml{fn} between the start of the body of \boxml{g} and
the call of \boxml{f}.  Indeed, we must not implement the call of {\tt
f} by a {\tt jmp}, for in the call \boxml{f[r] at r2},  
a region vector containing \boxml{r} has to be constructed, since,
at the point of the call, \boxml{r}, is available only from the closure
of \boxml{fn y => letregion r2 in f[r]at r2 y end}.


Note that (\ref{ntcall}) requires 
that the {\tt letregion} bind only one region variable (the region used for
the region record). The way to avoid that {\tt letregion} binds more than one region variable 
is to turn the calling function into a region endomorphism, when possible.

The following is an example of how one obtains simple jumps:\footnote{Project: \boxml{kitdemo/tail.pm}, file: \boxml{kitdemo/tail2.sml}.}
\begin{verbatim}
       local
         fun f'(p as (0,b)) = p
           | f'(n,b) = f'(n-1,n*b)
       in
         fun f(a,b) = #2(f'(a,b))
       end;
\end{verbatim}
The  call-explicit version of {\tt f'} appears in 
Figure~\ref{tail2.fig}. 
Another example of a {\tt jmp} tail call 
will be shown in Section~\ref{foldl.sec}.

\begin{figure}
\hrule
\begin{verbatim}

     fun f' attop r1 [r7:inf] (var1024)= 
         (case #0 var1024 
          of 0 => var1024
          |  _ => 
            let val n = #0 var1024; val b = #1 var1024
            in  jmp f' (n - 1, n * b) sat r7
            end 
         ) (*case*) ; 
\end{verbatim}
\caption{An example where a function call 
         turns into a simple jump.}
\medskip
\hrule
\label{tail2.fig}
\end{figure}

\section{Non-Tail Call of Region-Polymorphic Function \index{funcall@{\tt funcall}}({\tt funcall})}
Still referring to the form (\ref{ntcall}), let us consider the
case where (\ref{cond1}) or (\ref{cond2}) is not satisfied.
Then the Kit will allocate $\rho_0$ before the call of $f$ 
and de-allocate it afterwards.\footnote{One could avoid this
allocation in the case $n=1$ or, more generally, if one
allowed unboxed representation of region vectors, but for
simplicity, we choose to forego this opportunity for optimisation.} 
The region bound to 
$\rho_0$ will always be finite and be on the stack. 
Due to this allocation, the call cannot be a tail call. The
mnemonic used for a non-tail call of a region-polymorphic function
is {\tt funcall}. Thus (\ref{ntcall}) is simplified to 
$$\boxml{letregion $\rho_0$ in funcall $f$ [$\rho_1$, $\ldots$, $\rho_n$] at $\rho_0$ $\exp$ end}.$$


Now let us turn to calls of region-polymorphic functions which do not fit the
pattern (\ref{ntcall}). One special case is:
$$\boxml{letregion $\rho_0,\rho_1,\ldots\rho_k$ in $f$ [] at $\rho_0$ $\exp$ end}
$$
where  $k>0$. Here $\rho_0$ is not needed; the Kit therefore replaces
the expression by 
$$\boxml{letregion $\rho_1,\ldots\rho_k$ in funcall $f$  $\exp$ end}
$$
(For reasons of presentation, we have assumed that the
\texttt{letregion}-bound region variables have been rearranged, if
necessary, to bring $\rho_0$ to the front.)

Every remaining case of an application of a region-polymorphic function
       $$\boxml{$f$ [$\rho_1$, $\ldots$, $\rho_n$] at $\rho_0$ $\exp$}$$
is replaced by 
%{\tt jmp $f$ $\exp$}, 
%if the call is a tail call, and by
       $$\boxml{$($funcall $f$ [$\rho_1$, $\ldots$, $\rho_n$] at $\rho_0)$ $\exp$}$$
%otherwise.

This completes all possible cases of applications of 
region-polymorphic functions. We now turn to function applications
where the operator is not the name of a region-polymorphic function.

\section{Tail Call of Unknown Function ({\tt fnjmp})}
Consider the case:\index{fnjmp@{\tt fnjmp}}
$$\exp_1\,\exp_2$$
where (a) the call is a tail call and (b) $\exp_1$ is not the name of a region-polymorphic function.

Here $\exp_1$ will be evaluated to a closure, pointed to by a standard 
register, \index{standardClos@{\tt standardClos}}\index{register}
{\tt standardClos}. Then $\exp_2$ will be evaluated and the result put
in the standard register \index{standardArg@{\tt standardArg}}{\tt standardArg}.
The first word in the closure always contains the address of
the code of the function. This address is fetched into a register and a jump to
the address is made. Since the call is a tail call, it induces no allocation, neither
on the stack nor in regions. It is thus as efficient as an
indirect {\tt goto} in assembly language.

%To avoid that $\exp_2$ puts values
%in fresh regions (which would make the call a non-tail call) one
%can ``disable'' region polymorphism of $f$ as explained in Section~\ref{tailcall.sec}.

The mnemonic used in call-explicit expressions for this special case is
$$\boxml{fnjmp $\exp_1$ $\exp_2$}$$

\section{Non-Tail call of Unknown Function ({\tt fncall})}
Consider the case
$$\exp_1\,\exp_2$$
where (a) the call is not a tail call and (b) $\exp_1$ is not the name of a region-polymorphic function.

This is implemented as follows: first $\exp_1$ is evaluated and the result, a  pointer to a closure, 
is stored in \boxml{standardClos}.
Then $\exp_2$ is evaluated and stored in $\boxml{standardArg}$. Then live registers and a return address
are pushed onto the stack and a jump is made to the code address which is stored in the first word of the closure
pointed to by {\tt standardClos}. Upon return, registers are restored from the stack.

The mnemonic used in call-explicit expressions for this special case is
$$\boxml{fncall $\exp_1$ $\exp_2$}$$
\section{Example: Function Composition}
The prelude defines function composition as follows:
\begin{verbatim}
       fun (f o g) x = f(g x)
\end{verbatim}
The resulting call-explicit expression produced by the Kit is\footnote{Project:
\boxml{kitdemo/compose.pm}, file \boxml{kitdemo/compose.sml}.}
\begin{verbatim}
      fun o attop r1[r7:2] (var1026) = 
          fn attop r7 x => 
             let val f = #0 var1026; val g = #1 var1026
             in  fnjmp f (fncall g x)
             end 
\end{verbatim}
Note that \boxml{f o g} first creates a closure in \boxml{r7}
and then returns. When called, the created function first performs
a non-tail call of \boxml{g} and then a tail call to \boxml{f}.\index{o@{\tt o}}

\section{Example: {\tt foldl}  Revisited}
\label{foldl.sec}
Consider
\begin{verbatim}
       fun foldl f b xs = 
         case xs of 
           [] => b
         | x::xs' => foldl f (f x b) xs'
\end{verbatim}
Note that the recursive call of \index{foldl@{\tt foldl}}{\tt foldl} is a call of a known function, but not a tail
call: {\tt foldl} returns a closure, which is subsequently
applied to the value of {\tt (f x b)}. This too returns a closure
which in turn is applied to {\tt xs'}. 
The resulting call-explicit expression is\footnote{Project:
\boxml{kitdemo/fold.pm}, file \boxml{kitdemo/fold1.sml}.}

\begin{verbatim}
fun foldl attop r1 [r7:4, r8:4] (f)= 
    fn attop r7 b => 
       fn attop r8 xs => 
          (case xs 
           of nil => b
           |  :: => 
             let val v11876 = decon_:: xs; 
                 val x = #0 v11876; 
                 val xs' = #1 v11876
             in  letregion r22:4 
                 in fncall 
                    letregion r24:4 
                    in fncall 
                       letregion r25:2 
                       in funcall foldl[atbot r24,atbot r22] atbot r25 f 
                       end
                       (fncall (fncall f x) b) 
                    end
                    xs' 
                 end
             end 
          ) (*case*) 
\end{verbatim}
Note that upon each iteration, fresh regions for holding
two closures are being allocated for the duration of the
recursive call. Thus space usage is linear in the length 
of the list (4 words for each list cell, to be precise).

An efficient version of {\tt foldl} is written thus:
\begin{verbatim}
       fun foldl f b xs = 
         let fun loop(p as ([], b))= p
               | loop(x::xs, b) = loop(xs,f x b))
         in
             #2(loop(xs,b))
         end
\end{verbatim}
It is compiled into the  call-explicit expression in Figure~\ref{foldl.fig}.\footnote{Project:
\boxml{kitdemo/fold.pm}, file \boxml{kitdemo/fold2.sml}.}
\begin{figure}
\hrule
\begin{verbatim}

fun foldl attop r1 [r7:3, r8:3] (f)= 
    fn attop r7 b => 
       fn attop r8 xs => 
          letregion r20:1 
          in let fun loop atbot r20 [r21:inf] (var1074)= 
                     (case #0 var1074 
                      of nil => var1074
                      |  :: => 
                         let val v11919 = #0 var1074; 
                             val v11921 = decon_:: v11919; 
                             val b = #1 var1074; 
                             val x = #0 v11921; 
                             val xs = #1 v11921
  (* note jmp *)         in  jmp loop (xs, 
                                       fncall (fncall f x) b
                                      ) sat r21
                         end 
                     ) (*case*) 
             in  letregion r28:inf 
                 in let val v11926 = 
                          letregion r29:1 
                          in funcall loop[atbot r28] atbot r29
                                     (xs, b) atbot r28 
                          end
                    in  #1 v11926
                    end  
                 end
             end  
          end
 
\end{verbatim}
\caption{The result of compiling {\tt foldl} is an iterative function which avoids
argument pairs piling up in one region.}
\medskip
\hrule
\label{foldl.fig}
\end{figure}
There are two reasons why this is much better: the loop is implemented as a jump and,
more importantly, there
is no new allocation in each iteration, except, of course,  for
the allocation which {\tt f} might make.\footnote{We repeat
that because {\tt f} is a formal function parameter, all the
allocations made by the calls to {\tt f} (one call for each element of the list)
are put in the same regions. If the list is very long or the values produced large,
it may be a good idea to copy the final result to separate regions.}

As an exercise, consider the following variant of {\tt foldl} which assumes that
{\tt f} takes a pair as an argument:
\begin{verbatim}
       fun foldl' f b xs = 
         let fun loop(p as ([], b))= p
               | loop(x::xs, b) = loop(xs,f(x,b)))
         in
             #2(loop(xs,b))
         end
\end{verbatim}
Interestingly, this program contains a potential space leak. Can you
detect it? If not, the Kit will tell you when you compile the program.\footnote{Project:
\boxml{kitdemo/fold.pm}, file \boxml{kitdemo/fold3.sml}.}


\chapter{Modules and Projects}
\label{modules_and_projects.chap}
In Section \ref{tryit.sec} we described how software projects with
multiple source files are compiled in the Kit. In this chapter we
describe how to program in the large, with the Kit, using Standard ML
Modules and the possibility of organizing source files into project
files. The Kit fully supports Standard ML Modules, and it has a
sophisticated system for avoiding unnecessary recompilation. In the
following section we describe the notion of projects. We then turn to
show how to program with structures, signatures and functors, in the
Kit, and we explain how these module constructs are compiled.


\section{Projects \label{projects.sec}}
A project file has extension {\tt .pm}, and in it you can mention a
sequence of projects to import and a sequence of source files. Both
project files and source files may be mentioned using either absolute
or relative paths (relative paths are relative to the location of the
project file). Until now, we have seen many examples of project files
with no imports (see e.g., Section~\ref{tryit.sec} for such an
example). Later, in Section~\ref{functors.sec}, we shall see an
example of a project that imports other projects; the Kit enforces the
restriction that projects may not be cyclic. Project files may contain
Standard ML style comments.

Every source file must contain a top-level Standard ML declaration;
the scope of the declaration is all the subsequent source files
mentioned in the project file and all other projects that imports
this project file. Thus, a source file may depend on source files
mentioned earlier in the project file and on other imported projects.
The meaning of an entire project is the meaning of the top-level
declaration that would arise by first expanding all imported projects
and then concatenating all the source files listed in the project
file, in the order they are listed, except that each project is 
only executed the first time it is imported. 

The Kit has a system for managing compilation and recompilation of
projects.  The system guarantees that the result of first modifying
one or more source files of a project and then using the separate
compilation system to rebuild the project is the same as if all source
files were
recompiled.\index{recompilation}\index{project}\index{source file}
Thus, the separate compilation system is a way of avoiding recompiling
parts of a (possibly) long sequence of declarations, while ensuring
that the result is always the same as if one had recompiled the entire
program.  As an example, consider the project file for the text
scanning example:\footnote{Project: \boxml{kitdemo/scan.pm}.}
\begin{verbatim}
prelude.sml
lib.sml
scan.sml
\end{verbatim}

\noindent 
The source files for the project are {\tt prelude.sml}, {\tt lib.sml},
and {\tt scan.sml}, which are all located in the directory where the
project file {\tt scan.ps} is located. Whereas both of the source
files {\tt lib.sml} and {\tt scan.sml} depend on the source file {\tt
prelude.sml}, the source file {\tt scan.sml} also depends on {\tt
lib.sml}.

The {\tt Project} sub-menu provides the user with operations for
setting a project file name and for reading and compiling the project
file (see Section \ref{tryit.sec}). The system detects automatically
(from file modification dates) if a source file is modified.  After a
project has been successfully compiled and linked, it can be executed
by running the command\index{run@{\tt run}}
\begin{verbatim}
run
\end{verbatim}
in the working directory.  

The Kit compiles each source file of a project one at a time, in the
order mentioned in the project file. A source file is compiled under
a given set of assumptions, which provides, for instance, region type
schemes for free variables of the source file. Also, compilation of a
source file gives rise to exported information about declared
identifiers. Exported information may occur in assumptions for source
files mentioned later in the project file.

A source file is recompiled if either (1) the user has modified the
source file or (2) the assumptions under which the source file was
previously compiled have changed. To avoid unnecessary recompilation,
assumptions for a source file depend on only the free identifiers.
Moreover, if a source file has been compiled earlier, the system will
seek to {\em match\/}\index{matching} the new exported information to
the old exported information by renaming generated names to names
generated when the source file was first compiled. Matching allows the
compiler to use fresh names (stamps) for implementing generative data
types, for instance, and still achieve that a source file is not
necessarily recompiled even though source files, on which it depends,
are modified.\index{recompilation!cut-off}

Let us assume that we modify the source file {\tt lib.sml} of the
text scanning example.  Selecting {\tt Compile and link project} in
the {\tt Project} sub-menu will cause {\tt lib.sml} to be recompiled.
Then, the Kit checks whether the assumptions under which the source
file {\tt scan.sml} was compiled have changed, and if so, recompiles
{\tt scan.sml}.  Modifying only comments or string constants inside
{\tt lib.sml} or extending its set of declared identifiers does not
trigger recompilation of {\tt scan.sml}.  However, more information is
needed to compile a source file than the ML type schemes for its free
variables. Thus, it might be the case that a source file must be
recompiled even though the ML type assumptions for free variables have
not changed. For instance, the region type scheme for a free variable
might have changed, even though the underlying ML type scheme has not.

As an example, consider modifying the function {\tt readWord} in the
source file {\tt lib.sml} to put its result in a global region. This
will trigger recompilation of the source file {\tt scan.sml}, because
the assumptions under which it was previously compiled have
changed. Besides changes in region type schemes, changes in
multiplicities and in physical sizes of formal region variables of
functions may also trigger recompilation.


\section{Structures}
The support for Modules together with the possibility of dividing top-level
declarations into source files provide a mechanism for
programming in the large. In the Kit, structures only exist at compile
time, thus, the memory conscious programmer need not worry where
structures go at runtime.

Consider the project {\tt set.pm},\footnote{Project:
  \boxml{kitdemo/set.pm}.} which mentions the source files {\tt
  prelude.sml}, {\tt poly\_set.sml}, and {\tt int\_set.sml}. The source
  file {\tt poly\_set.sml} contains the following top-level
  declaration:
\begin{verbatim}
structure PolySet = 
  struct
    type 'a set = 'a list
    fun singleton x = [x]
    fun mem(x,[]) = false
      | mem(x,y::ys) = x=y orelse mem(x,ys)
    fun union(s1,[]) = s1
      | union(s1,x::s2) = if mem(x,s1) then union(s1,s2)
                          else x::union(s1,s2)  
    fun inter(s1,[]) = []
      | inter(s1,x::s2) = if mem(x,s1) then x::inter(s1,s2)
                          else inter(s1,s2)
  end
\end{verbatim}

\noindent
The code generated by the Kit for the {\tt IntSet} structure is
exactly as if the declarations were written outside of a structure.
As a consequence, when you refer to a component of a structure using
qualified identifiers (e.g., {\tt IntSet.mem}) no code is generated
for fetching the component from the structure. Moreover, when opening
a structure, using the {\tt open} declaration, no code is generated
for rebinding the identifiers that become visible.

\section{Signatures}
Signature declarations are held entirely in the compiler at compile
time and do not result in any generated code. The source file {\tt
int\_set.sml} in the project {\tt set.pm}, discussed earlier, contains
the signature declaration
\begin{verbatim}
signature INT_SET =
  sig
    type 'a set
    val singleton : int -> int set
    val mem : int * int set -> bool
    val union : int set * int set -> int set
  end
\end{verbatim}

\noindent
Signatures are used in two contexts; for specifying arguments to
functors and for providing restricted views of structures using
transparent and opaque signature constraints. We defer the discussion
of the former use of signatures to Section \ref{functors.sec}.

Transparent signature constraints may both restrict components from a
structure and make polymorphic components less polymorphic. Moreover,
opaque signature constraints may also make type components of
structures abstract. Consider the structure declarations
\begin{verbatim}
structure IntSet1 : INT_SET = PolySet
structure IntSet2 :> INT_SET = PolySet
\end{verbatim}

\noindent
located in the source file {\tt int\_set.sml}. No code is generated
for the structure declarations. Instead, the compiler memorises that
if you refer to {\tt IntSet1.mem}, for instance, then it is actually
{\tt PolySet.mem} that is applied with type instance {\tt int}.

As for the second declaration, opaque signature constraints are
eliminated at compile time (after elaboration) and transformed into
transparent signature constraints.

\section{Functors \label{functors.sec}}
Functors are functions from structures to structures. The Kit
specialises functors for each application. Thus, types that are
abstract for the programmer becomes visible to the compiler.
Moreover, region type schemes and other information about identifiers
are available when the Kit compiles the body of a functor.

However, for practical reasons, it is important that functors are not
simply in-lined. In-lining could cause intermediate representations of
programs in the Kit to be as large as all sources for the entire
program.  Further, non-restricted in-lining could lead to unnecessary
recompilation upon modification of source files. Instead, the largest
structure declarations not containing functor applications are
compiled into separate chunks of machine object code. Assumptions for
compiling these structure declarations are memorised, so that the
generated code can be reused upon modification of source files if the
assumptions do not change.

Consider the project {\tt functor\_set.pm}:\footnote{Project:
  \boxml{kitdemo/functor\_set.pm}.}
\begin{verbatim}
import utils/utils.pm
in
   functor_set.sml
   app_set.sml
end
\end{verbatim}
The project imports the sub-project {\tt utils.pm}\footnote{Project:
\boxml{kitdemo/utils/utils.pm}.}, which provides a structure {\tt
ListUtils} containing the function {\tt pr\_list} with type scheme
{\tt ('a -> string) -> 'a list -> string}. The source file {\tt
functor\_set.sml} is listed in Figure~\ref{functor_set.fig}. It
declares the functor {\tt Set}, which takes as arguments the element
type for the set and an ordering function on elements.
\begin{figure}
\hrule \medskip
\begin{verbatim}
functor Set(type elem  (* total order *)
            val lt : elem * elem -> bool
            val pr : elem -> string) =
  struct
    type set = elem list
    fun singleton (x:elem) = [x]
    fun mem(x,[]) = false
      | mem(x,y::ys) = if lt(y,x) then mem(x,ys)
                       else (not o lt)(x,y)
    fun union(s1,s2) = 
      let fun uni([], s, acc) = rev acc @ s
            | uni(s, [], acc) = rev acc @ s
            | uni(s1 as x::xs, s2 as y::ys, acc) = 
                uni(if lt(x,y) then (xs, s2, x::acc)
                    else if lt(y,x) then (s1, ys, y::acc)
                    else (xs, ys, y::acc))
      in uni(s1, s2, []) 
      end
    val pr = ListUtils.pr_list pr
  end
\end{verbatim}
\caption{\label{functor_set.fig} The source file {\tt functor\_set.sml}.}
\medskip \hrule
\end{figure}

The source file {\tt app\_set.sml} is listed in
Figure~\ref{app_set.fig}. It constructs a structure {\tt IntSet} by
applying the functor {\tt Set} to appropriate arguments including an
ordering operation on integers and an operation for giving the string
representation of an integer. The {\tt IntSet} structure is used for
constructing a set \verb+{5,6}+, which the program prints using the
builtin {\tt print} function.
\begin{figure}
\hrule \medskip
\begin{verbatim}
structure IntSet = Set(type elem = int
                       val lt = op <
                       val pr = Int.toString)
local open IntSet
in val a = singleton 5
   val b = singleton 6
   val c = union(union(a,b),b)
   val _ = print(pr c)
end
\end{verbatim}
\caption{\label{app_set.fig} The source file {\tt app\_set.sml}.}
\medskip \hrule
\end{figure}

The body of the {\tt Set} functor is instantiated to form the code for
the {\tt IntSet} structure. The result of instantiating the {\tt Set}
functor is first translated into a {\sl Lambda\/} program and then
translated into a {\sl MulExp\/} program. The {\sl MulExp\/} program
for the instantiated functor body is shown in
Figure~\ref{set_inst_mulexp.fig}.
\begin{figure}
\hrule \medskip
\begin{verbatim}
 MEMO: fill in...
\end{verbatim}
\caption{\label{set_inst_mulexp.fig} The {\sl MulExp\/} program
resulting from instantiating the {\tt Set} functor.}
\medskip \hrule
\end{figure}



\part{System Reference}
%
\chapter{Using the Profiler}
%
\label{useOfProf.sec}
We have already seen several examples of the use of the region profiler. We
shall now explain how to profile in more detail. For example, we shall see
how one can find out precisely what allocation points in the program
contribute to a particular region.

The region profiler consists of several tools which can be used to analyse
the dynamic memory behaviour of the target program. First of all, there are
the \emph{profiles}\index{profiles} which are graphs showing the dynamic
memory usage of the executed program. There are three different graphs:
\begin{itemize}
\item A \emph{region profile} is a graph\index{region profile} which gives
  a ``global'' view of the memory usage by showing the total number of
  words allocated in regions and on the stack as a function of time. In the
  graph, regions that arise from the same
\begin{center}
\texttt{letregion} $\rho$ \texttt{in} $e$ \texttt{end}
\end{center}
expression are collected into one coloured band, labelled $\rho$. The
region variables that label bands are always global or letregion-bound,
never formal region parameters.

\item An \emph{object profile} is a graph\index{object profile} which gives
  a ``local'' view into a particular region, as a function of time. The
  graph shows the objects allocated into a chosen region, with one coloured
  band for each allocation point in the region-annotated lambda
  program\footnote{Every occurrence of an ``\texttt{at}'' in the
    region-annotated lambda program is an allocation point.}.  Each
  allocation point is annotated with a \emph{program point}\index{program
    point} which is a unique number identifying the
  allocation.\footnote{Program points are unique local to a project, e.g.\ 
    with a project containing two source files, 
    the program points in the region-annotated lambda
    programs for the two files will be distinct.}
  
  If you have an object profile showing that program point 42
  (written \texttt{pp42}) contributes with a lot of allocations you
  can search for \texttt{pp42} in the region-annotated lambda
  program.
\item A \emph{stack profile} is a graph\index{stack profile} which shows
  the stack memory usage, as a function of time.
\end{itemize}

As described above the region profiler can give you a region-annotated
lambda program annotated with program points.
  
During compilation, it is also possible to generate a \emph{region flow
  graph}\index{region flow graph} which shows how
regions may be passed around at runtime when region polymorphic functions
are applied. The region flow graph is very handy when profiling larger
programs when one wants to find out why a formal region variable has been
instantiated to a certain \texttt{letregion}-bound region variable.

An example should clarify this. Suppose the region profile shows that
\texttt{r5} grows very big. Further, suppose an object profile of
\texttt{r5} shows that program point \texttt{pp345} is responsible.
Searching for \texttt{pp345} in the region-annotated program, you may find
that the allocation at \texttt{pp345} is into some other region variable,
\texttt{r34}, say. Here \texttt{r34} will be a formal region parameter of a
region-polymorphic function which at runtime has been instantiated to
\texttt{r5} by one or more calls of region-polymorphic functions.

You can now use the region flow graph to find the ``cascade'' of region
polymorphic applications that ends up instantiating \texttt{r34} to
\texttt{r5}.

Profiling is sketched in Figure~\ref{profStrategy.fig}.

\newcommand{\picbox}[1]{\framebox(5,3){\scriptsize{\parbox{22mm}{\begin{center}
        #1 \end{center}}}}}
\newcommand{\vectorr}[1]{\vector(1,0){1}
  \makebox(-1,1)[t]{\scriptsize{#1}}}

\setlength{\unitlength}{0.5cm}
\begin{figure}[ht]
\hrule
\begin{center}
\begin{picture}(29,8)
\put(0,4){\picbox{Choose \\ Compile-Time \\ Profiling \\ Strategy}}
\put(6,4){\picbox{Compile ML Source Program with Kit compiler}}
\put(12,4){\picbox{Choose Target \\ Profiling Strategy}}
\put(18,4){\picbox{Execute Target Program \\ (\texttt{run} $\ldots$)}}
\put(24,4){\picbox{Generate \\ Profiles \\ with the graph \\ generator \texttt{rp2ps}}}
%\put(5,5.5){\vectorr{}}
%\put(11,5.5){\vectorr{}}
%\put(17,5.5){\vectorr{}}
%\put(23,5.5){\vectorr{}}
\put(8,4){\vector(-1,-1){2}}
\put(2.5,0){\dashbox{0.3}(6.0,2){\scriptsize{\parbox{40mm}{\begin{center}Region-
        Annotated \\ Lambda Program\end{center}}}}}
\put(9,4){\vector(1,-1){2}}
\put(9,0){\dashbox{0.3}(4,2){\scriptsize{\parbox{22mm}{\begin{center}Region
      \\ Flow \\ Graph\end{center}}}}}
\put(20.5,4){\vector(0,-1){2}}
\put(18.5,0){\dashbox{0.3}(4,2){\scriptsize{\parbox{22mm}{\begin{center}Profile
      \\ Datafile\end{center}}}}}
\put(26.5,4){\vector(0,-1){2}}
\put(22,2){\vector(1,1){2}}
\put(24.5,0){\dashbox{0.3}(4,2){\scriptsize{\parbox{22mm}{\begin{center}Profile
      \\ Graphs\end{center}}}}}
\put(1,1.5){\scriptsize \texttt{.log}\index{log@\texttt{.log}}}
\put(13,1.5){\scriptsize \texttt{.log}\index{log@\texttt{.log}}}
\put(13,1){\scriptsize \texttt{.vcg}\index{vcg@\texttt{.vcg}}}
\put(17.3,1.5){\scriptsize \texttt{.rp}\index{rp@\texttt{.rp}}}
\put(23.3,1.5){\scriptsize \texttt{.ps}\index{ps@\texttt{.ps}}}
\end{picture}
\caption{Overview of the ML Kit profiler. Dotted boxes
        represent output from the profiler. The file containing the output
        is also shown, e.g. a profile goes into a \texttt{.ps} file.}
\label{profStrategy.fig}
\end{center}
\hrule
\end{figure}

We will now show an example on how to profile a concrete program
containing a space leak and then show how the profiler can be used to
fix it. After that, we explain in more detail how to specify the profiling
strategies and how the profiles are generated.

%-------------------------------------------------
\section{Profiling project \texttt{scan\_rev1}}
%-------------------------------------------------

In this section, we concentrate on the general principles of profiling. We
use the revised scan project (project \texttt{/kitdemo/scan\_rev1.pm}) as
an example. Instead of asking for an input file to scan (as project
\texttt{scan.pm} does) the program scans the same file
(\texttt{../../kitdemo/life.sml}) 11 times.

The first thing to do is to get an overview of the memory usage of the
program. The region profile gives you that\index{scan_rev1@\texttt{scan\_rev1}}. See Figure
\ref{scan_rev1_1.fig}.

\begin{figure}[htb]
\begin{center}
  \scalebox{1.3}{\includegraphics*[0,0][198,132]{scan_rev1_1.eps}}
  \caption{It is obvious that memory is accumulated in the two top
    bands. The global region \texttt{r1} and region \texttt{r2797}
    hold the largets amount of memory. The graph has been generated
    by executing \texttt{run -microsec 10000} on the HPUX (with the C
    backend) and then typing \texttt{rp2ps -sampleMax 1200
      -region}.}\label{scan_rev1_1.fig}
\end{center}
\end{figure}
%\noindent
The graph shows that region \texttt{r1} holds the largest amount of memory,
but it does not get bigger over time. Region \texttt{r2797}, however,
accumulates more memory for each time it scans the life
program.
%\footnote{It may not be possible for you to get the exact
%  same region variable names if you try the example.
%  Changes in the ML Kit setup may influence which region variables
%  are generated. }

To see what happens in region \texttt{r2797}, we make an object profile of
that region, see Figure \ref{scan_rev1_2.fig}.

\begin{figure}[htb]
\begin{center}
  \scalebox{1.3}{\includegraphics*[0,0][198,132]{scan_rev1_2.eps}}
  \caption{There seems to be a space leak at program point
    \texttt{pp33}. The graph has been generated by typing \texttt{rp2ps
      -sampleMax 1200 -object 2797}.}\label{scan_rev1_2.fig}
\end{center}
\end{figure}
%\noindent
The object profile shows that program point \texttt{pp33} produces a lot
of allocations which are first freed again when the program stops. We now
search for \texttt{pp33} in file \texttt{prelude.log} and find:

%\begin{footnotesize}
\begin{verbatim}
fun implode attop r1 pp32 [r110:inf] (strs)= 
    ccall(implodeStringProfiling,  attop r110 pp33, strs); 
\end{verbatim}
%\end{footnotesize}                                
\noindent
Formal region variable \texttt{r110} is instantiated with {\tt letregion}-bound
region variable \texttt{r2797} in a call to function \texttt{implode}. We
now search after \texttt{r2797} in file \texttt{scan\_rev1.log} and find the
following fragment of the region flow graph.
\begin{eqnarray}
\texttt{toString}&&\texttt{[r1545:inf]} \nonumber\\
& &\texttt{--r1545 attop-->  LETREGION[r2395:inf];} \nonumber \\
& &\texttt{ --r1545 attop-->   driver[r2468:inf]} \nonumber \\
& &\texttt{--r2468 attop--> LETREGION[r2797:inf];} \label{path01.ref}
\end{eqnarray}
\noindent
This is read as follows: the formal region variable \texttt{r2468} is
instantiated to {\tt letregion}-bound region variable \texttt{r2797} when
function \texttt{driver} is called. Formal region variable \texttt{r1545}
is then instantiated to region variable \texttt{r2468} when calling
function \texttt{toString}.\footnote{Region flow graphs are local to each
  program in a project. Calling a non local region polymorphic function
  will then introduce an edge in the region flow graph, but we do not know
  in which module the called function is located. It may be necessary to
  look in several log files to find the path from a formal region variable
  to an actual.}
Searching after \texttt{r1545} in file \texttt{lib.log} shows that
\texttt{toString} calls function \texttt{implode} which is found in file
\texttt{prelude.log}.\footnote{We use \texttt{...} to indicate that we have
  deleted text.}

%\begin{footnotesize}
\begin{verbatim}
fun toString attop r1 pp200 [r1545:inf] (n)= 
    letregion r1542:inf, r1543:inf, r1544:inf, r1547:1 
    in implode[sat r1545 pp208] atbot r1547 pp207 
...
\end{verbatim}
%\end{footnotesize}
\noindent
We see that region \texttt{r2797} is passed with storage mode attop
(\ref{path01.ref}, above) to formal region variable \texttt{r2468} when
function \texttt{driver} is called for the first time. Region \texttt{r2797}
contains the result string which is printed after scanning the file. This
can be seen from the lambda program in file \texttt{scan\_rev1.log}.
Searching after allocation points allocating into region \texttt{r2468}
gives among others the following fragments: \texttt{": size = "attop r2468}
and \texttt{" comments: "attop r2468}.

The result string is not needed after a file has been scanned and the
result string printed, so the memory holding the result string can be
de-allocated. The {\attop} storage mode explains why the region holding the
result string is not deallocated between scans. So, why is the storage mode
attop? To answer this we have to see where \texttt{driver} is called the
first time, which is in function \texttt{do\_it}:

%\begin{footnotesize}
\begin{verbatim}
fun main(is: instream):unit =
let 
  fun driver(None,n,inside) = 
        report_totals(n, inside)
    | driver(Some filename,n:int,inside:int) =
        case scan_file filename of
          Some(n,inside) => report_totals(n,inside)
        | None => ()

  val filename = "../../kitdemo/life.sml"
  fun do_it 0 = driver(Some filename, 0, 0)
    | do_it n = (driver(Some filename, 0, 0); do_it (n-1))
in
  do_it 10;
  ()
end
\end{verbatim}
%\end{footnotesize}
\noindent
The following fragment of the corresponding lambda program (file
\texttt{scan\_rev1.log}) shows that the file name \texttt{"life.sml"} is
also put into region \texttt{r2797} which, of course, has to stay allocated
between the scans:

%\begin{footnotesize}
\begin{verbatim}
...
letregion r2797:inf 
in let val filename = "../../kitdemo/life.sml"attop r2797 pp501
   in  letregion r2798:3 
     in let fun do_it atbot r2798 pp502 [] (var70)= 
...
\end{verbatim}                                
%\end{footnotesize}
\noindent
The reason that the file name and the other strings mentioned above must
stay in the same region is that they are all made part of the same list of
strings, namely the argument to \texttt{implode} in \texttt{report\_totals}.

The region \texttt{r2797} contains both local and non-local data to the
driver function which is why the region cannot be reset in the driver
function.  A general solution to this problem is to delay the creation of
the file name, so that the file name is created at each call to
\texttt{driver}. The newly created file name will then be put into a region local
to the application point to \texttt{driver}. The revision is found in
project \texttt{kitdemo/scan\_rev2.pm}:\index{scan_rev2@\texttt{scan\_rev2.pm}}

%\begin{footnotesize}
\begin{verbatim}
fun filename() = "../../kitdemo/life.sml"
fun do_it 0 = driver(Some (filename()), 0, 0)
  | do_it n = (driver(Some (filename()), 0, 0); do_it (n-1))
\end{verbatim}
%\end{footnotesize}
\noindent
Figure \ref{scan_rev2_1.fig} shows a region profile of the
\texttt{scan\_rev2} project.

\begin{figure}[htb]
\hrule
\medskip

\begin{center}
  \scalebox{1.3}{\includegraphics*[0,0][198,132]{scan_rev2_1.eps}}
\end{center}
  \caption{There is no space leak: no matter how many times we scan the
    file, the project will use the same number of words. The graph has been
    generated by executing \texttt{run -microsec 10000} and \texttt{rp2ps
      -sampleMax 1200 -region}.}\label{scan_rev2_1.fig}
\medskip

\hrule
\end{figure}
%\noindent
To see the effect of the modifications above consider the following lambda
fragment (found in file \texttt{scan\_rev2.log}):

%\begin{footnotesize}
\begin{verbatim}
fun do_it atbot r2797 pp501 [] (var142)= 
  (case var142 
     of 0 => 
        letregion r2799:inf, r2800:2, r2801:3, r2803:1 
        in driver[atbot r2799 pp506] atbot r2803 pp505 
           (Some atbot r2800 pp503 "../../kitdemo/life.sml"
                                        attop r2799 pp502, 
            0, 
            0
           ) atbot r2801 pp504 
        end (*r2799:inf, r2800:2, r2801:3, r2803:1*)
\end{verbatim}                                
%\end{footnotesize}
\noindent
The copy of the file name is put into region \texttt{r2799} which is
deallocated after the call to \texttt{driver}.

%----------------------------------------
\section{Compile-Time Profiling Strategy}
%----------------------------------------

We will now show some examples on how the profiling tools can be used. As
shown in Figure \ref{profStrategy.fig} we have to choose a \emph{Compile-Time
  Profiling Strategy}\index{profile strategy!compile-time@compile-time}. The Compile-Time
Profiling Strategy directs how the region-annotated lambda code with
program points and the region flow graph are generated.

The Compile-Time Profiling Strategy is set up in the Profiling
sub-menu\index{Profiling sub-menu} in the
ML Kit menu.\footnote{The \texttt{Instruction Count
    Profiling}\index{Instruction Count Profiling@\texttt{Instruction Count
      Profiling}} option is only available in the HP-UX backend and has
  nothing to do with region profiling. It simply counts the number of
  executed instructions in the target program excluding runtime calls and
  the link file. It should only be used when region profiling is not
  enabled. If the number of instructions executed gets too large, the
  Overflow exception is raised.}

%\begin{quote}
%\begin{footnotesize}
\begin{verbatim}
Profiling

0       region profiling............................ off >>>
1       generate lambda program with program points. off
2       generate region flow graph (.vcg file)...... off
3       paths between two nodes in region flow graph [] >>>
4       Instruction Count Profiling................. off
\end{verbatim}
%\end{footnotesize}
%\end{quote}
\noindent
Region profiling is enabled by choosing the first item:
\mbox{\texttt{region profiling}}\index{region profiling@\texttt{region
    profiling}}.

If you want the region-annotated lambda code with program points, toggle
the second menu item: \texttt{generate lambda program with program
  points}\index{generate lambda program with program points@\texttt{generate lambda program with pro\-gram points}}.  The lambda program is written on the log.

To generate a region flow graph, choose \texttt{generate region flow graph
  (.vcg file)}\index{generate region flow graph (.vcg
  file)@\texttt{generate region flow graph (.vcg file)}}. The region flow
graph will be written on the log in text layout which may be hard to read.
A more readable graph is exported to the working directory in file
\emph{f}\texttt{.vcg} where \emph{f}\texttt{.sml} is the source program.
The file \emph{f}\texttt{.vcg} contains the region flow graph in a format
that can be read by the VCG tool\index{VCG tool} (Visualization of Compiler
Graphs\footnote{The VCG tool can be obtained from
  \[\texttt{http://www.cs.uni-sb.de/RW/users/sander/html/gsvcg1.html}.\]
  We use version 1.30 found in file \texttt{vcg.1.30.r3.17.tar}.}).

As a running example we use the project \texttt{life.pm} in the \texttt{kitdemo}
directory. The project contains one file: \texttt{life.sml}. We toggle the
first three options on (above, 0-2) and compile the project from inside
the \texttt{Project} sub-menu. 

The ML Kit now generates several files of which we have \texttt{life.log}
(containing, among other things, the lambda program with program points and the
region flow graph in text layout), \texttt{life.vcg} (the region flow graph
ready to use with the VCG tool) and the executable \texttt{run}.

%-------------------------------------------------
\subsubsection{Lambda program with program points}
%-------------------------------------------------
In the log file (\texttt{life.log}) you find the lambda program by searching for
\texttt{LAMBDA CODE WITH PROGRAM POINTS}:
%\begin{footnotesize}
\begin{verbatim}
Report: LAMBDA CODE WITH PROGRAM POINTS:: 
   let exception Div : (exn,r1) 
                  (* exn value or name attop r1 pp2 *);
...
\end{verbatim}
%\end{footnotesize}
\noindent
In the first line we have an allocation with storage mode
\texttt{attop} into region \texttt{r1}. The allocation point has
program point 2 (\texttt{pp2}).

%----------------------------------------------------------
\subsubsection{Region flow graphs \label{regFlowGraph.sec}}
%----------------------------------------------------------
The region flow graph is found by searching after \texttt{REGION FLOW GRAPH
  FOR PROFILING}:\label{reg_flow_graph.ex}
%\begin{footnotesize}
\begin{verbatim}
Report: REGION FLOW GRAPH FOR PROFILING:: 
   Begin layout of region flow graph and SCC-graph.
...
       cp_list[r314:inf]
          --r314 sat-->   [*r314*] ;
          --r314 atbot-->   LETREGION[r1539:inf];
          --r314 sat-->   nthgen'[r944:inf]   
                         --r944 sat-->   [*r944*] ;
                         --r944 atbot-->   LETREGION[r1588:inf];
...
\end{verbatim}
%\end{footnotesize}
\noindent
The region flow graph is almost equivalent to the graph used by the
storage mode analysis (p.~\pageref{region flow graph}) where region
variables are nodes and an edge between two nodes $\rho$ and $\rho'$
is inserted if $\rho$ is a formal region parameter of a function $f$
which is applied to actual region parameter $\rho'$. This implies that
\texttt{letregion}-bound region variables are always leaf nodes.

Nodes in the graph are written in square brackets, where for example
\texttt{cp\_list[r314:inf]} means that \texttt{r314} is a formal region
parameter in function \texttt{cp\_list}. An asterisk inside a square
bracket means that the node has been written earlier. Only the node
identifier (i.e. the region variable) will then be printed. The size of the
region is printed after the region variable: we use \texttt{inf} for an
infinite region and \texttt{:}\emph{size} for a finite region where
\emph{size} is the region size in words.

Edges are written with the \emph{from node} identifier inside the
edge. The edge points to the \emph{to node}. The text
\texttt{cp\_list[r314:inf]  --r314 sat-->   [*r314*] ;} is read: there
is an edge from node \texttt{r314} to node \texttt{r314}, and node
\texttt{r314} has been written earlier. We have a cycle, so
\texttt{cp\_list} must call itself recursively; if you look in file
\texttt{life.sml} you will find something like:

%\begin{footnotesize}
\begin{verbatim}
fun cp_list[] = []
  | cp_list((x,y)::rest) = 
        let val l = cp_list rest
        in (x,y):: l
        end.
\end{verbatim}
%\end{footnotesize}
\noindent
It is important to look inside the edge for the from node. Consider for
example:
%\begin{footnotesize}
\begin{verbatim}
...
 LETREGION[r3621:2];   --r3480 atbot-->   LETREGION[r3627:2];
...
\end{verbatim}
%\end{footnotesize}  
\noindent
We do not have an edge from the \texttt{letregion}-bound region variable
(\texttt{r3621}) to the other \texttt{letregion}-bound variable (\texttt{r3627}).

%-----------------------------------------------------
\subsubsection{The strongly connected components graph}
%-----------------------------------------------------
The region flow graph can get very complicated to read because we may have
mutually recursive functions giving a bunch of edges and cycles.  If the
graphs get too complicated you may find help in the \emph{strongly
  connected component}\index{strongly connected component} (scc) version of the graph.

The scc graph is found by searching for \texttt{[sccNo} in the log
file. Each scc is identified by a unique \emph{scc number}. The region
variables contained in each scc is written as info on the scc-node.

Consider for example:
%\begin{footnotesize}
\begin{verbatim}
[sccNo 206: r1181,]   --sccNo 206-->   [sccNo 205: r1486,];
\end{verbatim}
%\end{footnotesize}
\noindent
We have a scc node (id 206) containing region variable \texttt{r1181} and
an edge to scc node (id 205) containing region variable
\texttt{r1486}.

%--------------------------------------------------------
\subsubsection{Region flow paths\label{regFlowPath.sec}}
%--------------------------------------------------------
If you are interested in the possible paths\index{region flow path} from
one region variable to another, the ML Kit can find them for you.

This often happens when you have an object profile (for example of
region $\rho_1$) showing that a certain allocation point is
responsible for the allocations of interest but the region they are
allocated in is not the same as the one written at the allocation
point, say $\rho_2$, in the region-annotated lambda program.

The region written at the allocation point ($\rho_2$) must then be a formal
region variable and it is now interesting to find out how $\rho_2$ has been
instantiated to $\rho_1$.

You can specify the from and to nodes that you want the paths for in the
fourth menu item (\texttt{paths between two nodes in region flow
  graph}\index{paths between two nodes in region flow
    graph@\texttt{paths between two nodes in region flow graph}}) in the
Profiling sub-menu:

\begin{footnotesize}
\begin{verbatim}
Profiling

0       region profiling............................ off >>>
1       generate lambda program with program points. off
2       generate region flow graph (.vcg file)...... off
3       paths between two nodes in region flow graph [] >>>
4       Instruction Count Profiling................. off

Toggle line (t <number>), Activate line (a <number>), Up (u), or Quit(q): 

>3
<type an int pair list of region variables,
e.g. [(formal reg. var. at pp.,\texttt{letregion}-bound reg. var.)]> or up (u): >
[(314,1588)]
\end{verbatim}
\end{footnotesize}
\noindent
You may type in a list of integer pairs, i.e. you can specify several
pairs of nodes that you want the paths for.

Compiling the source program again gives a new log file where you can
search for \texttt{[Starting layout of paths...}:\footnote{Because region
  variables may change when re-compiling a source program in a project it
  may be necessary to start all over by starting the Kit again and compile
  the whole project again to make sure that the regions you have specified
  will match the regions in a region flow graph of a previous compilation.}

%\begin{footnotesize}
\begin{verbatim}
[Starting layout of paths...
    [Start path: [sccNo 59: r314,]--->
                 [sccNo 58: r944,]--->[sccNo 57: r1588,]]
...Finishing layout of paths]
\end{verbatim}
%\end{footnotesize}
\noindent
If you look at the region flow graph on
page~\pageref{reg_flow_graph.ex} you see that the only path from
region \texttt{r314} to region \texttt{r1588} goes through function
\texttt{nthgen'}, i.e. \texttt{nthgen'} calls \texttt{cp\_list}. If
you look in the file \texttt{life.sml} you may notice that
\texttt{nthgen'} actually calls a function \texttt{copy} and not
\texttt{cp\_list}. The function \texttt{copy} is declared as

%\begin{footnotesize}
\begin{verbatim}
copy (GEN l) = GEN(cp_list l)
\end{verbatim}
%\end{footnotesize}
\noindent
If you see in the lambda program (file \texttt{life.log}) you may notice
that \texttt{cp\_list} has been inlined instead of \texttt{copy} by the
optimizer.

%---------------------------------
\subsubsection{Using the VCG tool}
%---------------------------------

The VCG tool\index{VCG tool} can be used to visualize the exported graphs
(file \emph{source}\texttt{.vcg}). We assume that you have installed the
tool and it is started by typing \texttt{xvcg} at the command prompt.  We
use file \texttt{life.vcg} as the running example. Typing
\mbox{\texttt{xvcg life.vcg}} at the command prompt gives the window shown
in Figure \ref{vcg1.fig}.

\begin{figure}[htb]
\begin{center}
  \scalebox{0.5}{\includegraphics*[0,0][293,327]{vcg1.eps}}
  \caption{The VCG graph contains two nodes. The
    node ``Region flow graph'' represents the folded region flow graph and
    the node ``SCC graph'' represents the folded strongly connected
    componemt graph.}\label{vcg1.fig}
\end{center}
\end{figure}

The two graphs are exported \emph{folded}. To unfold a graph choose
\textbf{Unfold Subgraph} from the pull-down menu inside the
\texttt{xvcg} window. The pull-down menu is activated by pressing one
of the mouse buttons. After activating \textbf{Unfold Subgraph} you
have to pick the node representing the graph to unfold. This is done
by clicking on the node with the left mouse button. Pressing the right
mouse button will then unfold the chosen graph. Figure \ref{vcg2.fig}
shows a small fraction of the unfolded region flow graph.

\begin{figure}[htb]
\begin{center}
  \scalebox{0.8}{\includegraphics*[0,0][459,164]{vcg2.eps}}
  \caption{The figure shows a small fragment of
          the region flow graph.}\label{vcg2.fig}
\end{center}
\end{figure}
%\noindent
The graph is read in the same way as the text-based version in the log
file. It can be printed out, scaled etc. from the pull-down
menu. The graph is folded again by choosing \textbf{Fold Subgraph} and clicking
on one of the nodes. All nodes in the graph then turn black, and clicking
on the right mouse button folds the graph.

Region flow paths are also exported together with the region flow
graph. Each path is numbered, and can be viewed by the \textbf{Expose/Hide
  edges} facility in the VCG pull-down menu, see Figure \ref{vcg3.fig}.
\begin{figure}[htb]
\begin{center}
  \scalebox{0.5}{\includegraphics*[0,0][556,117]{vcg3.eps}}
  \caption{After choosing the
    \textbf{Expose/Hide edges} facility you get this window. The window
    shows that there are two \emph{edge classes} in the graph; one for the
    region flow graph and one for the path from node \texttt{r474} to node
    \texttt{r1748}. If you have generated the path from section
    \ref{regFlowPath.sec} you have the option
    \texttt{Path2(r314,r1588)}.}\label{vcg3.fig}
\end{center}
\end{figure}
%\noindent
Each path is numbered because there can be several paths between the same
two nodes. Clicking on the edge class ``Graph'' will hide the edges in the
region flow graph so that edges in the generated path are the only edges
shown, see Figure \ref{vcg4.fig}.
\begin{figure}[htb]
\begin{center}
  \scalebox{0.8}{\includegraphics*[0,0][460,186]{vcg4.eps}}
  \caption{The Figure shows the path between
          node \texttt{r474} and \texttt{r1748}. If you look on page
          \pageref{reg_flow_graph.ex} you may notice that it is the same
          path as in the log file; the numbers have changed however,
          because they where generated in two different
          compilations.}\label{vcg4.fig}
\end{center}
\end{figure}

%----------------------------------
\section{Target Profiling Strategy}
%----------------------------------
When the source program has been compiled and linked you have an
executable, \texttt{run}. Typing \texttt{run} at the command prompt will
execute the program with a predefined Target Profiling
Strategy\index{profile strategy!target@target}.  The profiling strategy is
printed on the first four lines of output:

%\begin{footnotesize}
\begin{verbatim}
Profiling is turned on with options:
     profile timer (unix virtual timer) is turned on.
     a profile tick occurs every 1th second.
     profiling data is written on file profile.rp.
\end{verbatim}
%\end{footnotesize}
\noindent
You can change the profiling strategy by passing command line arguments
directly to the executable\index{profile strategy!option@options}.  The
second line says that a virtual timer is used. There are three possible
timers, but in general it may be system dependent. On the HP-UX operating
system you have the following timers:\footnote{A complete description can
  be found in the manual page for \texttt{getitimer}.}
\begin{description}
\item[REAL\index{timer!real}] which is real time.
\item[VIRTUAL\index{timer!virtual}] which is the process virtual time. It runs only when the
  process is executing.
\item[PROF\index{timer!prof}] which is the process virtual time together with the time used
  in the operating system on behalf of the process.
\end{description}
\noindent
You specify the timer to use by passing
\texttt{-realtime}\index{realtime@\texttt{-realtime} option},
\texttt{-virtualtime}\index{virtualtime@\texttt{-virtualtime} option} or 
\texttt{-profiletime}\index{profiletime@\texttt{-profiletime} option} to the executable.

The third line says that a \emph{profile tick}\index{profile tick} occurs every 1 second.
A profile tick is when the program stops normal execution, and memory
is traversed to collect profile data. The more often a profile tick
occurs the more detailed you profile. The \emph{time slot}\index{time slot} (the time
between to succeeding profile ticks) to use is specified by the
\texttt{-sec n}\index{sec@\texttt{-sec} option} and 
\texttt{-microsec n}\index{microsec@\texttt{-microsec} option} options. A time slot of half a
second is specified by \texttt{-microsec 500000} and not
by \texttt{-sec 0.5}.\footnote{The lowest possible time slot to use is
  system dependent. It is also system dependent how long time that
  passes before the time wraps. This will not in practice happen on a
  HP-UX but it will happen after about 40 minutes on SUN OS4.}

The fourth line tells you that the collected profile data is exported to
file \texttt{profile.rp}. This can be changed by the 
\texttt{-file outFileName}\index{file@\texttt{-file} option} option.

There are several other command line arguments which can be seen by the
\texttt{-h} or \texttt{-help}\index{help@\texttt{-help} option} options.

%----------------------------------
\section{Executing \texttt{run}}
%----------------------------------
After executing \texttt{run} some \emph{region statistics}\index{region statistics} are printed on
stdout. The region statistics are collected independently of the Target
Profiling Strategy above and are exact values for the program.

\begin{scriptsize}
\begin{verbatim}
*************Region statistics***************


SBRK.
  Number of calls to sbrk                     :          3
  Number of bytes allocated in each SBRK call :      24240
  Total number of bytes allocated by SBRK     :      72720 (0.1Mb)

REGIONPAGES.
  Size of one page              :        800 bytes

  Max. no. of simultaneously allocated pages :         78
  Number of allocated pages now              :          3

REGIONS.
  Size of infinite region descriptor (incl. profiling information) :         28 bytes
  Size of infinite region descriptor (excl. profiling information) :         16 bytes

  Size of finite region descriptor   :          8 bytes

  Number of calls to allocateRegionInf   :     157771
  Number of calls to deallocateRegionInf :     157768

  Number of calls to allocateRegionFin   :    3457870
  Number of calls to deallocateRegionFin :    3457870

  Number of calls to alloc                  :    1446811
  Number of calls to resetRegion            :     139776
  Number of calls to deallocateRegionsUntil :          0

  Max. no. of co-existing regions (finite plus infinite) :        242
  Number of regions now                                  :          3

  Live data in infinite regions :         84 bytes ( 0.0Mb)
  Live data in finite regions   :          0 bytes ( 0.0Mb)
  ---------------------------------------------------------
  Total live data               :         84 bytes ( 0.0Mb)

  Maximum space used for region pages                 :      62400 bytes ( 0.1Mb)
  Maximum space used on data in region pages          :      27488 bytes ( 0.0Mb)
      Space in regions at that time used on profiling :      27576 bytes ( 0.0Mb)
  -------------------------------------------------------------------------------
  Maximum allocated space in region pages             :      55064 bytes ( 0.1Mb)

  Memory utilisation for infinite regions (     55064/     62400) : 88%

  Maximum space used on the stack for infinite region descriptors   :        400 bytes ( 0.0Mb)
      Additional space used on profiling information at that time   :        300 bytes ( 0.0Mb)
  ---------------------------------------------------------------------------------------------
  Maximum space used on infinite region descriptors on the stack    :        700 bytes ( 0.0Mb)

  Maximum space used on the stack for finite regions              :       6604 bytes ( 0.0Mb)
      Additional space used on profiling information at that time :       3584 bytes ( 0.0Mb)
  -------------------------------------------------------------------------------------------
  Maximum space used on finite regions on the stack               :      10188 bytes ( 0.0Mb)

  Max. size of stack when program was executed        :      11256 bytes ( 0.0Mb)
    Space used on profiling information at that time  :       3800 bytes ( 0.0Mb)
  -------------------------------------------------------------------------------
  Max. stack use excl. profiling information          :       7456 bytes ( 0.0Mb)

  Max. size of stack in a profile tick                :       5596 bytes ( 0.0Mb)

*********End of region statistics*********
\end{verbatim}
\end{scriptsize}
\noindent
The {\tt SBRK} part above shows how memory is allocated from the operating
system.

Each region consists of several \emph{region pages}\index{region pages} whose size is found in
the {\tt REGIONPAGES} part. The value
%\begin{center}
\begin{footnotesize}
\begin{verbatim}
Max. no. of simultaneously allocated pages      :       78
\end{verbatim}
\end{footnotesize}
%\end{center}
\noindent 
multiplied by
%\begin{center}
\begin{footnotesize}
\begin{verbatim}
Size of one page          :        800 bytes
\end{verbatim}
\end{footnotesize}
%\end{center}
\noindent 
gives the maximal memory use in infinite regions (62400 bytes).

In the {\tt REGIONS} part, we see the number of calls to finite and
infinite region operations, respectively. The target program has allocated
157771 infinite regions and deallocated 157768; hence three global regions were
alive when the program finished; i.e. global regions are not
necessarily deallocated explicitly before the program terminates.

No finite regions are alive (3457870 allocations and deallocations).  We
have allocated 1446811 objects in infinite regions. It has been possible to
reset an infinite region 139776 times. The {\tt deallocateRegionsUntil}
operation is only used when raising exceptions, i.e. no exceptions have
been raised.

Because objects allocated in infinite regions are not split across
different region pages it is not always possible to fill out all
region pages. The value

\begin{center}
\begin{footnotesize}
\begin{verbatim}
Memory utilisation for infinite regions (     55064/     62400) : 88%
\end{verbatim}
\end{footnotesize}
\end{center}

\noindent
shows memory utilisation at the moment where the program had allocated the
largest amount of memory. The size of objects in finite regions allocated
on the stack is shown together with the overhead produced by the profiler.
The values

\begin{center}
\begin{footnotesize}
\begin{verbatim}
Max. size of stack when program was executed     :   11256 bytes ( 0.0Mb)
\end{verbatim}
\end{footnotesize}
\end{center}

\noindent
and

\begin{center}
\begin{footnotesize}
\begin{verbatim}
Max. size of stack in a profile tick             :    5596 bytes ( 0.0Mb)
\end{verbatim}
\end{footnotesize}
\end{center}

\noindent
can be used to see if it is necessary to profile more detailed.  If
the difference between the two figures is large you can profile with a
smaller time slot.

After execution of the target program we have a profile data file named
{\tt profile.rp}.

%--------------------------------------------
\section{Processing the profile data file}
%--------------------------------------------
The profile datafile \texttt{profile.rp} can be processed by the graph
generator\index{graph generator@\texttt{rp2ps} options|(} \texttt{rp2ps} (read RegionProfiler2PostScript) found in the
\texttt{bin} directory for the ML Kit version you use.\footnote{The
  \texttt{rp2ps} program is based on a profiler by Colin Runciman,
  David Wakeling and Niklas R\"{o}jemo.} The graph generator is
controlled by command line options.

A region profile is produced by the
\texttt{-region}\index{region@\texttt{-region} option} switch. Typing
the UNIX command ~~\boxml{rp2ps -region}~~ produces a postscript file in
file \texttt{region.ps}. The file \texttt{profile.rp} is used as profile
data file\index{profile data file}. Figure \ref{prof_eks1.fig} shows the region profile for
the example program \texttt{life.sml}.
\begin{figure}[htb]
\begin{center}
  \scalebox{1.3}{\includegraphics*[0,0][198,133]{prof_eks1.eps}}
  \caption{The region profile shows all
          regions and the stack with the region (or stack) having the
          largest area at the top. Executing the life program with
          \texttt{run -microsec 100000} and typing \texttt{rp2ps
            -sampleMax 1200 -region} produces this graph.}\label{prof_eks1.fig}
\end{center}
\end{figure}
%\noindent
The regions are sorted by size (area) with the largest at the top and the
smallest at the bottom. If there are more regions than can be shown in
different shades, the smallest are collected in an {\em other\/}
\emph{band} at the bottom.

Each region is identified with a number that matches a {\tt
  letregion}-bound region variable in the region-annotated lambda
program. Infinite regions end with ``{\tt inf}'' and finite regions
with ``{\tt fin}''. We also have a band \texttt{rDesc} and
\texttt{stack}. The \texttt{rDesc} band shows the memory used on
infinite ``region descriptors'' on the stack. The stack band shows
stack usage excluding the region descriptors for the infinite regions.

The \emph{max.\ allocation line} ``Maximum allocated bytes in regions:
$\ldots$'' at top of Figure \ref{prof_eks1.fig} shows the maximum number of
bytes allocated in regions when the target program was executed. Because we
also show the stack use on the graph (as the {\tt rDesc} and {\tt stack} band), we
offset the max.\ allocation line upwards by the maximum stack use shown. The
space between the max. allocation line and the top band shows the
inaccuracy of the profiling strategy used. Having a large gap indicates
that a smaller time slot should be used or maybe another Compile-Time Profiling
Strategy.

An object profile is produced by the
\texttt{-object}\index{object@\texttt{-object} option} switch. If we
want to examine the largest region shown in Figure \ref{prof_eks1.fig}, we
type \texttt{rp2ps -sampleMax 1200 -object 1588} and get the object profile shown in
Figure \ref{prof_eks2.fig}.
\begin{figure}[htb]
\begin{center}
  \scalebox{1.3}{\includegraphics*[0,0][198,133]{prof_eks2.eps}}
  \caption{The object profile shows all
    allocation points allocating into this region.}\label{prof_eks2.fig}
\end{center}
\end{figure}
%\noindent
We see that allocation point \texttt{pp64} is responsible for the largest
amount of allocations in the program. The allocation point may be found by
searching after program point \texttt{pp64} in the region-annotated
lambda program.

A stack profile (Figure \ref{prof_eks3.fig}) shows memory usage in
the stack. A stack profile is generated with the \texttt{-stack}
option\index{stack@\texttt{-stack} option} to \texttt{rp2ps}.

\begin{figure}[htb]
\begin{center}
  \scalebox{1.3}{\includegraphics*[0,0][198,133]{prof_eks3.eps}}
  \caption{Memory usage on the stack.}\label{prof_eks3.fig}
\end{center}
\end{figure}
%\noindent

%-------------------------------------------------------
\section{More complicated graphs with \texttt{rp2ps}}
%-------------------------------------------------------
This section gives a fast overview of the more advanced options which can
be passed to \texttt{rp2ps}. First of all, it is possible to name the
profiles with the \texttt{-name} option\index{name@\texttt{-name} option}. Comments are inserted in the
x-axis with the \texttt{-comment}\index{comment@\texttt{-comment} option} option.

The profile data file may contain an large number of \emph{samples}
(the data collected by a profile tick is called a sample). By default,
\texttt{rp2ps} only uses 64 samples. This may be changed with the
\texttt{-sampleMax}\index{sampleMax@\texttt{-sampleMax} option} option. The following two algorithms are used to sort
out samples:
\begin{quote}
\begin{description}
\item[{\tt -sortBySize}\index{sortBySize@\texttt{-sortBySize} option}] where the $n$ (specified by \texttt{-sampleMax})
  largest samples are kept.
\item[{\tt -sortByTime}\index{sortByTime@\texttt{-sortByTime} option}] is used by default and makes a binary deletion of
  samples by time such that the $n$ samples shown will be equally
  distributed on the $x$-axis.
\end{description}
\end{quote}
\noindent
The \texttt{-sortBySize} option is handy if you get some profiles
with a large gap between the top band and the \emph{max. allocation line}.
If there is a large gap when using option \texttt{-sortBySize}, then you
have to profile with smaller time slots. You can use the 
\texttt{-stat}\index{stat@\texttt{-stat} option}
option to get the number of samples in the profile data file. It is printed
as \texttt{Number of ticks:}.

Figure \ref{prof_eks4.fig} shows the profile for the following
command line:
%\begin{footnotesize}
\begin{verbatim}
rp2ps -region -sampleMax 50 -name life.sml 
      -comment 9 "A comment at time 9" -sortByTime
\end{verbatim}
%\end{footnotesize}
\noindent

\begin{figure}[htb]
\begin{center}
  \scalebox{1.3}{\includegraphics*[0,0][198,133]{prof_eks4.eps}}
  \caption{It is possible to insert comments in the profiles.}\label{prof_eks4.fig}
\end{center}
\end{figure}
%\noindent
The graph generator recognize several options not shown above. They are
printed on stdout when typing \texttt{rp2ps -h}.
\index{graph generator@\texttt{rp2ps} options|)}
%
\chapter{Interacting with the Kit}
%
\label{controlkit.sec}
\label{startup.sec}
Starting the Kit was described in Section~\ref{tryit.sec}.  To
\index{leaving the Kit}\index{exit from the Kit}\index{quitting from
  the Kit}leave the Kit, type \index{q@{\tt q}}\boxml{q} followed by a
return character.  In the following, we give an overview of several
sub-menus.  Section~\ref{scriptmodify.sec} explains how to set up a
personal script file. The {\tt Project} menu is described in Section
\ref{projects.sec}.

%
\section{Printing of Intermediate Forms}
%
The menu \texttt{Printing of intermediate
  forms}\index{Printing of intermediate forms@{\tt Printing of 
intermediate forms}} controls which
intermediate forms are output on the \index{log file}log file.  A summary of the
major phases that produce printable intermediate forms  is
shown in Figure~\ref{phases.fig}. The phases are listed in the
order they take place in the Kit.
\begin{figure}
\begin{center}
Menu: Printing of Intermediate Forms
\medskip

\begin{tabular}{|l|c|l|}
\hline
 {\bf Phase} & {\bf Type of Result} & {\bf Flag(s) which Print Result} \\
\hline
 Elaboration            & $\Lam$    & \hfill \boxml{$(\ast)$}\\
 Elim. of Poly. Eq.     & $\Lam$    & \hfill \boxml{$(\ast)$}\\
 Lambda Optimiser       & $\Lam$    & \hfill \boxml{$(\ast)$}\\
                        & report    & \boxml{statistics after}\\&&~~\boxml{optimisation}\\
 Spreading              & $\RegExp$ & \hfill \boxml{$(\ast)$}\\
 Region Inference       & $\RegExp$ & \hfill \boxml{$(\ast)$}\\
 Multiplicity Inference & $\MulExp$ & \hfill \boxml{$(\ast)$}\\
 K-normalisation        & $\MulExp$  & \\
 Storage Mode Analysis  & $\MulExp$ & \boxml{print atbot expression} \hfill $(\ast)$\\
 Dropping of Regions    & $\MulExp$ &   \boxml{print drop regions}\\&&~~\boxml{expression} \hfill $(\ast)$\\
 Physical Size Inference& $\MulExp$ & \boxml{print physical size}\\&&~~\boxml{inference expression} \hfill $(\ast)$\\
 Call Conversion        & $\MulExp$ & \boxml{print call-explicit}\\&&~~\boxml{expression} \hfill $(\ast)$\\
 Code Generation        & KAM-code  & \boxml{print KAM code before}\\&&~~\boxml{register allocation} \hfill $(\ast)$\\
 Register Allocation    & KAM-code  & \boxml{print KAM code after}\\&&~~\boxml{register allocation} \hfill $(\ast)$\\
\hline
\end{tabular}
\end{center}
\caption{The table shows how the menu items in the {\tt Printing of Intermediate
Forms} menu correspond to the phases in the Kit. \index{intermediate forms}
Enabling \boxml{debug compiler} from the 
\boxml{Debug Kit} menu causes all intermediate forms marked $(\ast)$ 
to be printed.
Thus one can select phases individually or ask to have all printed.
The phases that follow K-normalisation all work on K-normal forms, 
but, for readablity, terms are printed as though they had not been normalised
(unless \boxml{Print in K-normal Form} from the {\tt Layout} menu
is enabled).}
\label{phases.fig}
\end{figure}
The optimiser, which rewrites a \emph{Lambda}\index{Lambda@$\Lam$}
program, collects statistics about the optimisation and this
statistics can be printed by turning on the flag \texttt{statistics
  after optimisation}\index{statistics after optimisation@{\tt
    statistics after optimisation}}.  Storage mode analysis (see
Chapter \ref{storagemodes.sec}) results in a
\emph{MulExp}\index{MulExp@$\MulExp$} expression, which can be printed
by turning on the flag \texttt{print atbot expression}\index{print
  atbot expression@{\tt print atbot expression}}.  After that, regions
with only \textbf{get} effects are removed from the \emph{MulExp}
expression (see Page~\pageref{bother-to-distinguish-get-n-put}).  To
see the resulting expression, turn on \texttt{print drop regions
  expression}\index{print drop regions expression@{\tt print drop
    regions expression}}. Physical size inference\index{physical size
inference}\index{region size} then determines the size in words of
finite region variables.  For instance, a finite region that will
contain a pair will have physical size two words.  To see the
expression after physical size inference, turn on \texttt{print
  physical size inference expression}\index{print physical size
  inference expression@{\tt print physical size inference
    expression}}.  After that, call conversion\index{call conversion}
converts the \emph{MulExp} expression to a
\index{expression!call-explicit}call-explicit expression (see
Page~\pageref{call-explicit}).  To see the result, enable the flag
\texttt{print call-explicit expression}.  After that, KAM\index{Kit
  Abstract Machine} code is generated.  The KAM code before register
allocation can be inspected by enabling the flag \texttt{print KAM
  code before register allocation}\index{print KAM code before
  register allocation@{\tt print KAM code before register
    allocation}}. The result of register allocation can be
viewed by enabling the flag \texttt{print KAM code after register
  allocation}\index{print KAM code after register allocation@{\tt
    print KAM code after register allocation}}.\index{register}

\section{Layout of Intermediate Forms}
While the switches described in the previous section concern which
intermediate forms to print, the switches in the sub-menu
\texttt{Layout}\index{Layout@{\tt Layout}} control how these forms are
printed.

The flags \texttt{print types}, \texttt{print effects}, and
\texttt{print regions} control the printing of types and places,
effects and region allocation points (``\texttt{at}~$\rho$'').
All eight combinations of these three flags are possible, but if
{\tt print\_effect} is turned on it is best also to turn the two
others on so that one can see where the effect variables and the region variables
which appear in arrow effects are bound.\index{print effects@{\tt print\_effects}}.


Enabling \texttt{print in K-Normal Form}\index{print in K-Normal Form@{\tt print in
    K-Normal Form}}\index{K-normalisation} causes  expressions to be output
in K-Normal Form instead of the simplified form in which they are
normally presented.
%
\section{Creating your own Script File}
\label{scriptmodify.sec}
%
If you have built the Kit yourself on an HP or a SUN using
the distribution accessible from our web site, the Kit has
already produced a script file for you and you do not have
to modify it to get started. If somebody else has built
the Kit locally, they should be able to refer you to a script file which you
can take as a starting point; the only things you will
have to change in the script will be the constants
listed in Section~\ref{paths.sec}. Likewise, if
you have downloaded an executable Kit from the Kit web site,
you will have received with it a script file for the architecture
in question and you only have to modify the constants listed
in Section~\ref{paths.sec}.
If you are porting the Kit to a completely 
different platform, you need to take the script constants 
listed in Section~\ref{cflags.sec} into account too.
\subsection{Script constants concerning paths}
\label{paths.sec}
Under the header \boxml{(*  File *)} in the script file you should
find the following constants\index{paths}
\begin{description}
\item[{\tt log\_to\_file}] True if log information should be written
to a file rather than onto the screen.
\item[{\tt path\_to\_kit\_script}] The full file name of 
your script file.\index{path to kit script@{\tt path\_to\_kit\_script}}
\item[{\tt path\_to\_runtime}] The full file name of the non-profiling
runtime system of the Kit.\index{path to runtime system@{{\tt path\_to\_runtime}}}
\item[{\tt path\_to\_runtime\_prof}] The full file name of the profiling
runtime system of the Kit.\index{runtime system}\index{runtime system!path to@}
\index{path to runtime system@{{\tt path\_to\_runtime\_prof}}}
\end{description}
\subsection{Platform-dependent Settings}
\label{cflags.sec}
The string constant {\tt target\_file\_extension} is set to
\boxml{".c"} if you generate C target code and to \boxml{".s"}
if you generate HP target code.\index{target file extension@{\tt target\_file\_extension}}
\index{kit architecture@{\tt kit\_architecture}}
\index{C compiler@{\tt c\_compiler}}
\index{C!libraries}
\index{c libs@{\tt c\_libs}}

The following settings
\begin{verbatim}
val kit_architecture : string = "HPUX"
val c_compiler : string = "cc -Aa"
val c_libs : string = "-lm"
\end{verbatim}
may all have to be changed, depending on your platform and
the C-compiler you use.  See the {\tt readme} and {\tt roadmap} files 
in the distribution.

\chapter{Calling C Functions}
\label{ccall.sec}

In this chapter, we describe how the ML Kit programmer can call C
functions from within Standard ML programs.  The Kit allows ML values
to be passed to C functions, which again may return ML values. Not all
ML values are represented as if they were C values. For instance, C
strings are null-terminated arrays of characters in contrast to ML
strings in the Kit, which are represented as a linked list of bounded
sized character arrays. To allow the programmer to conveniently
convert between C values and ML values, the Kit provides a small
number of conversion functions and macros.

When a C function to be called from within an ML program has to return
a boxed values of known size, finite regions are allocated by the Kit
and pointers to them are passed to the C function as additional
parameters. Moreover, when a C function has to return values of
unbounded size, pointers to infinite regions are passed to the C
function; in this case, the C function can itself allocate space in
these non-finite regions. In both cases, the Kit uses region inference
to infer the lifetime of regions that are passed to the C function.
The region inference algorithm does not analyse C functions. Instead,
the Kit inspects the ML type provided by the programmer. The Kit
assumes that functions with monomorphic types are \index{region
exomorphism}region exomorphisms; \index{region endomorphism}region
endomorphic functions may be described using ML polymorphism.

For every C function that is called from an ML program, the order of the
region arguments (if any) is uniquely determined by the ML result type
of the function.  This type must be constructed from lists, records,
booleans, reals, strings, integers, and type variables.

%profiling 

Examples of existing libraries that can be accessed from within ML
programs include the X Window System and standard UNIX libraries
providing functions such as {\tt time}, {\tt cp}, and {\tt
fork}. There are limitations to the scheme, however. First, because C
and the Kit do not share value representations, transmitting large
data structures between C and ML will often involve significant
copying. Second, some C libraries require the user to set up
\index{call-back function}call-back functions to be executed when
specific events occur. It is not currently possible with the Kit to
have a C function call an ML function.

%========================================================
\section{Declaring Primitives and C Functions}
\label{parPassing.sec}
%========================================================
The Kit comes with a prelude defining some of the initial basis of the
1997 Definition.  The declarations in the prelude use a special
built-in identifier called \indexTwo{prim}{\texttt{prim}}, which is
declared to have type scheme $\forall \alpha \beta .  (\texttt{string}
\ast \texttt{string} \ast \alpha) \rightarrow \beta$ in the initial
environment.  A primitive function is then declared in the prelude by
passing its name to \texttt{prim}.  For example, the declaration
\begin{verbatim}
  fun op = (x : ''a, y : ''a) : bool = prim ("=", "=", (x, y))
\end{verbatim}
\noindent
declares polymorphic equality.  The argument and result types are
explicitly stated so as to give the primitive the correct type
scheme. The first string {\tt "="} denotes a primitive (in this case
polymorphic equality). Some primitives are implemented by the compiler
(as is polymorphic equality). For other primitives, the Kit generates
a call to a C function, which must then be present at link-time. The
second argument to {\tt prim} is a primitive to use when profiling is
enabled. A convenient way to declare a C function is to use the
following scheme:
$$\texttt{fun}~ \emph{vid} ~\texttt{(}x_1:\tau_1, \ldots, x_n:\tau_n\texttt{)}
    : \tau ~\texttt{=} ~\texttt{prim(}\emph{c\_func}, \emph{c\_funcProf}, \texttt{(}
  x_1, \ldots, x_n\texttt{)} \texttt{)}
$$

\noindent The result type $\tau$ must be of the form
\begin{quote}
\begin{tabbing}
$\tau$ ::\== ~\= $\alpha$ $~|~$ {\tt int} $~|~$ {\tt bool} $~|~$ $\tau_1 \ast \ldots
             \ast \tau_n$ \\ \> $|$ \> $\tau$ {\tt list} $~|~$ {\tt real}
             $~|~$ {\tt string} $~|~$ {\tt unit}
\end{tabbing}
\end{quote}
\noindent
If the result type is one of $\alpha$, {\tt int}, {\tt bool} or ${\tt unit}$ then the
result value can be returned unboxed. If the result type represents a
boxed value, the C function must be told where to store the value. For
any type which is either {\tt real} or a non-empty tuple type, and
does not occur in a list type of the result type $\tau$, the Kit
allocates space for the value and passes a pointer to the allocated
space as an additional argument to the C function. For any type
representing a boxed value that is either {\tt string} or occurs in a
list type of the result type $\tau$, the Kit cannot statically
determine the amount of space needed to store the value. Instead,
regions are passed to the C function as additional arguments and the C
function must then explicitly allocate space in these regions as
needed, using a C function provided by the runtime system. The order
in which these additional arguments are passed to the C function is determined
by a pre-order traversal of the result type $\tau$.  For a list type,
regions are given in the order:
\begin{enumerate}
    \item region for cons-cells
    \item region for auxiliary pairs
    \item regions for elements (if necessary)
\end{enumerate}

Below we give an example to show what extra arguments are passed to a
C function, given the result type. In the example, we use the following
(optional) naming convention: 
names of arguments holding addresses of 
pre-allocated space in regions 
start with {\tt vAddr}, while names of arguments
holding addresses of region descriptors (to be used for allocation in an
infinite region) start with {\tt rAddr}.
\begin{example}
  Given the result type $({\tt int} \ast {\tt string}) ~{\tt list}
  \ast {\tt real}$, the following extra ar\-gu\-ments are passed to the
  C function (in order): {\tt vAddrPair}, {\tt rAddrLCons},
  {\tt rAddrLPairs}, {\tt rAddrEPairs}, {\tt rAddrEStrings} and {\tt
    vAddrReal}, see Figure \ref{args_ex1.fig}. 
  
  Here {\tt vAddrPair} holds an address pointing to pre-allocated storage
  in which the tuple of the list and the (pointer to the) real should
  reside. The arguments {\tt rAddrLCons} and {\tt rAddrLPairs} hold region
  addresses for the spine and the auxiliary pairs of the list,
  respectively.  Similarly, {\tt rAddrEPairs} and {\tt rAddrEStrings} hold
  region addresses for element pairs and strings, respectively. The
  argument {\tt vAddrReal} holds the address for pre-allocated storage for
  the real.
\end{example}

\setlength{\unitlength}{1pt}
\begin{figure}[ht]
\hrule
\begin{center}
\begin{picture}(400,155)
\put(125,140){\framebox{$\ast$}}
\put(155,100){\framebox{\texttt{real}}}
\put(75,100){\framebox{\texttt{list}}}
\put(85,60){\framebox{$\ast$}}
\put(40,20){\framebox{\texttt{int}}}
\put(115,20){\framebox{\texttt{string}}}
\put(125,140){\line(-1,-1){29}}
\put(138,140){\line(1,-1){29}}
\put(90,97){\line(0,-1){28}}
\put(85,60){\line(-1,-1){29}}
\put(98,60){\line(1,-1){29}}

\put(115,145){\circle{10}}\put(115,145){\makebox(0,0){1}}
\put(65,105){\circle{10}}\put(65,105){\makebox(0,0){2}}
\put(75,65){\circle{10}}\put(75,65){\makebox(0,0){3}}
\put(30,25){\circle{10}}\put(30,25){\makebox(0,0){4}}
\put(105,25){\circle{10}}\put(105,25){\makebox(0,0){5}}
\put(145,105){\circle{10}}\put(145,105){\makebox(0,0){6}}

\put(200,145){\circle{10}}\put(200,145){\makebox(0,0){1}}
\put(210,142){\texttt{vAddrPair}}

\put(200,125){\circle{10}}\put(200,125){\makebox(0,0){2}}
\put(210,122){\texttt{rAddrLCons} and \texttt{rAddrLPairs}}

\put(200,105){\circle{10}}\put(200,105){\makebox(0,0){3}}
\put(210,102){\texttt{rAddrEPairs}}

\put(200,85){\circle{10}}\put(200,85){\makebox(0,0){4}}
\put(210,82){Integers are unboxed}

\put(200,65){\circle{10}}\put(200,65){\makebox(0,0){5}}
\put(210,62){\texttt{rAddrEStrings}}

\put(200,45){\circle{10}}\put(200,45){\makebox(0,0){6}}
\put(210,42){\texttt{vAddrReal}}

\end{picture}
\caption{The order of pointers to allocated space and infinite regions
  is determined from a pre-order traversal of the result type $({\tt
  int} \ast {\tt string}) ~{\tt list} \ast {\tt real}$.}
\label{args_ex1.fig}
\end{center}
\hrule
\end{figure}

Additional arguments holding pointers to pre-allocated space and
infinite regions are passed to the C function prior to the ML
arguments. Consider again the ML declaration
$$\texttt{fun}~ \emph{vid} ~\texttt{(}x_1:\tau_1, \ldots, x_n:\tau_n\texttt{)}
    : \tau ~\texttt{=} ~\texttt{prim(}\emph{c\_func}, \emph{c\_funcProf}, \texttt{(}
  x_1, \ldots, x_n\texttt{)} \texttt{)}
$$
\noindent
The C function \emph{c\_func} must then be declared as
\begin{eqnarray}
  \texttt{int} \ \emph{c\_func} \ \texttt{(}\texttt{int}\ \emph{addr}_1,
    \ldots, \texttt{int}\ \emph{addr}_m,\ \texttt{int}\ x_1, \ldots, \texttt{int}\ x_n\texttt{)} \nonumber
\end{eqnarray}
\noindent
where \emph{addr}$_1$, $\ldots$, \emph{addr}$_m$ are pointers to
pre-allocated space and infinite regions as described above.

To support profiling, the programmer must provide special profiling
versions of certain C functions. If profiling is enabled and at least
one pointer to pre-allocated space or to an infinite region is passed
to the C function then also a program point representing the call to
the C function is passed to the C function. The program point is used
by the C function when allocating into infinite regions, as explained
in Section \ref{prof.sec}. The program point is passed as the last
argument:
\begin{tabbing}
\indent\=  $\texttt{int} \ \emph{c\_funcProf} \ ($\=$\texttt{int}\ \emph{addr}_1,
    \ldots, \texttt{int}\ \emph{addr}_m,$\\
  \>\>$ \texttt{int}\ x_1, \ldots,
    \texttt{int}\ x_n, \texttt{int}\ \emph{pPoint}) $
\end{tabbing}
\noindent
C functions that do not allocate into infinite regions can be used unchanged
when profiling.\footnote{For simplicity, we have chosen to pass the program
  point even though the C function only uses pre-allocated space.  Because
  we pass the program point as the last argument to the C function we need
  not have the program point as a formal parameter in the C function. The
  program point is passed but not used.}

%========================================
\section{Conversion Macros and Functions}
%========================================
The runtime system provides a small library of conversion macros and
functions for use by C functions that need to convert between ML
values and C values. Using this library for converting between
representations protects you against any future change in the
representation of ML values.  The interface to the library is provided
through the include file\index{MlConvert.h@\texttt{MlConvert.h}}.
\begin{verbatim}
src/Runtime/Version17/MlConvert.h
\end{verbatim}

%--------------------
\subsection{Integers}
%--------------------
There are two macros for converting between the ML representation of
integers and the C representation of integers:\footnote{In this
release of the Kit, these macros are the identity maps, but that may
change.}
\begin{verbatim}
#define convertIntToC(i)
#define convertIntToML(i)
\end{verbatim}
To convert an ML integer \texttt{i\_ml} to a C integer \texttt{i\_c},
write \index{convertIntToC@\textt{convertIntToC}}
\begin{verbatim}
i_c = convertIntToC(i_ml);
\end{verbatim}
To convert a C integer \texttt{i\_c} to an ML
 integer \texttt{i\_ml}, write \index{convertIntToML@\texttt{convertIntToML}}
\begin{verbatim}
i_ml = convertIntToML(i_c);
\end{verbatim}
The macros demonstrated here are used in the examples \ref{power.ex},
\ref{power_real.ex}, and \ref{power_exn.ex} in Section \ref{Cexamples.sec}.

%-----------------
\subsection{Units}
%-----------------
The following constant in the conversion library denotes the ML
representation of {\tt ()}:
\begin{verbatim}
#define mlUNIT
\end{verbatim}

%-----------------
\subsection{Reals}
%-----------------
An ML real is represented as a pointer into a region containing the
real. To convert an ML real to a C real we dereference the pointer. To
convert a C real to an ML real, we update the memory to contain the ML
real. The following two macros are provided:
\begin{verbatim}
#define convertRealToC(mlReal)
#define convertRealToML(cReal, mlReal)
\end{verbatim}

Converting from an ML real to a C real can be done with the first macro:
\begin{quote}
\emph{C}$_{\emph{real}}$ = \indexTwo{convertRealToC}{\texttt{convertRealToC}}(\emph{ML}$_{\emph{real}}$)\texttt{;}.
\end{quote}

Converting from a C real to an ML real (being part of the result value of the
C function) can be done in one or two steps depending on whether the real is
part of a list or not. If the real is not in a list the memory containing
the real has been allocated before the C call (See Section~\ref{parPassing.sec}):
\begin{quote}
\indexTwo{convertRealToML}{\texttt{convertRealToML}}(\emph{C}$_{\emph{real}}$, \emph{ML}$_{\emph{real}}$)\texttt{;}.
\end{quote}

If the ML real is in a list element, then space must be allocated for
the real before converting it. If $\rho_{\emph{real}}$ is the region
for the real you write:
\begin{quote}
\indexTwo{allocReal}{\texttt{allocReal}}($\rho_{\emph{real}}$, \emph{ML}$_{\emph{real}}$)\texttt{;} \\
\texttt{convertRealToML}(\emph{C}$_{\emph{real}}$, \emph{ML}$_{\emph{real}}$)\texttt{;}
\end{quote}

The above macros are used in the examples \ref{power_real.ex},
\ref{power_exn.ex} and \ref{real_list.ex} in Section \ref{Cexamples.sec}.

%--------------------
\subsection{Booleans}
%--------------------
Four constants provide the values of true and false in ML and in
C. These are defined by the following macros:\footnote{Booleans in the
Kit are tagged for historical reasons.}

\begin{verbatim}
#define mlTRUE  3
#define mlFALSE 1
#define cTRUE   1
#define cFALSE  0
\end{verbatim}

Two macros are provided for converting booleans:

\begin{verbatim}
#define convertBoolToC(i)
#define convertBoolToML(i)
\end{verbatim}

\noindent Converting booleans are similar to converting integers:
\begin{quote}
\emph{C}$_{\emph{bool}}$ = \indexTwo{convertBoolToC}{\texttt{convertBoolToC}}(\emph{ML}$_{\emph{bool}}$)\texttt{;} \\
\emph{ML}$_{\emph{bool}}$=\indexTwo{convertBoolToML}{\texttt{convertBoolToML}}(\emph{C}$_{\emph{bool}}$)\texttt{;}.
\end{quote}

%-------------------
\subsection{Records}
%-------------------
Records are boxed. One macro is provided for storing and retrieving
elements:

\begin{verbatim}
#define elemRecordML(recAddr, offset)
\end{verbatim}

\noindent An element can be retrieved by writing 
\begin{quote}
\emph{ML}$_{\emph{elem}}$ = \indexTwo{elemRecordML}{\texttt{elemRecordML}}(\emph{ML}$_{\emph{rec}}$, \emph{offset})\texttt{;}
\end{quote}
\noindent
where the first element has offset 0. An element is stored by
\begin{quote}
\texttt{elemRecordML}(\emph{ML}$_{\emph{rec}}$, \emph{offset}) \texttt{=} \emph{ML}$_{\emph{elem}}$\texttt{;}
\end{quote}
\noindent
\noindent Two specialized versions of the above macros are provided for
pairs:

\index{first@\texttt{first}}
\index{second@\texttt{second}}
\begin{verbatim}
#define first(x)
#define second(x)
\end{verbatim}

If the record is in a list element then it is necessary to allocate the record
before using it. This is done with the macro

\begin{verbatim}
#define allocRecordML(rhoRec, size, recAddr)
\end{verbatim}

\noindent
where \boxml{rhoRec} is a pointer to a region descriptor, 
\boxml{size} is the size of
the record (i.e., the number of components), and \boxml{recAddr}
is a variable in which \boxml{allocRecordML} returns a pointer to
storage for the record. The record is then stored, component by component,
by repeatedly  calling \boxml{elemRecordML} with the pointer as argument.


The above macros are used in examples \ref{real_list.ex},
\ref{change_elem.ex} and \ref{dir.ex} in Section \ref{Cexamples.sec}.

%-------------------
\subsection{Strings}
%-------------------
Strings are boxed and always allocated in infinite regions. It is possible
to print an ML string by using the C function

\index{printString@\texttt{printString}}
\begin{verbatim}
void printString(StringDesc *str);
\end{verbatim}

Strings are converted from ML to C and vice versa using the two C 
functions

\begin{verbatim}
void convertStringToC(StringDesc *mlStr, char *cStr, int cStrLen);
StringDesc *convertStringToML(int rAddr, char *cStr);.
\end{verbatim}
\noindent
An ML string is converted to a C string by writing
\begin{quote}
\indexTwo{convertStringToC}{\texttt{convertStringToC}}(\emph{ML}$_{\emph{str}}$,\emph{C}$_{\emph{str}}$, \emph{cStrLen})\texttt{;}
\end{quote}
\noindent
and a C string is converted to an ML string by writing
\begin{quote}
\emph{ML}$_{\emph{str}}$ = \indexTwo{convertStringToML}{\texttt{convertStringToML}}(\emph{rhoStr}, \emph{C}$_{\emph{str}}$)\texttt{;}
\end{quote}

When using \texttt{convertStringToC}, the C string
(\emph{C}$_{\emph{str}}$) has to be allocated in advance. The length
of the pre-allocated C string is also passed to
\texttt{convertStringToC}. If the ML string is larger than the C
string an error message is written on {\tt stdout} and the program
will terminate. The following function returns the size of an ML
string:
\index{sizeString@\texttt{sizeString}}
\begin{verbatim}
int sizeString(StringDesc *str);
\end{verbatim}

The above macros are used in the examples \ref{dir.ex} and
\ref{print_string_list.ex} in Section \ref{Cexamples.sec}.

%-----------------
\subsection{Lists}
%-----------------

Lists are always allocated in infinite regions. A list uses, as a minimum,
two regions. One region for the constructors (\texttt{NIL} and
\texttt{CONS}) and one region for the auxiliary pairs (Figure \ref{list.fig}).

\setlength{\unitlength}{0.55 cm}
\begin{figure}[ht]
\hrule
\begin{center}
\begin{picture}(20,5.5)
\scriptsize
\put(3.5,0){\framebox(2,1){{\em elem}}}
\put(3,2){\framebox(3,1){}}
\put(6,2){\framebox(3,1){}}

\put(4.5,2.5){\vector(0,-1){1.5}}
\put(7.5,2.5){\vector(0,1){1.5}}

\put(10.5,0){\framebox(2.5,1){{\em elem}}}
\put(13.5,4){\framebox(2,1){\em NIL}}
\put(10,2){\framebox(3,1){}}
\put(13,2){\framebox(3,1){}}

\put(11.5,2.5){\vector(0,-1){1.5}}
\put(14.5,2.5){\vector(0,1){1.5}}

\put(0,4){\framebox(3,1){\em CONS}}
\put(3,4){\framebox(3,1){}}
\put(4.5,4.5){\vector(0,-1){1.5}}

\put(6.75,4){\framebox(3,1){\em CONS}}
\put(9.75,4){\framebox(3,1){}}
\put(11.25,4.5){\vector(0,-1){1.5}}

\multiput(0,1.5)(0.2,0){100}{\line(1,0){0.1}}
\put(17.5,0.5){\mbox{$\rho_{elem}$}}
\put(17.5,2.25){\mbox{$\rho_{pair}$}}
\multiput(0,3.5)(0.2,0){100}{\line(1,0){0.1}}
\put(17.5,4){\mbox{$\rho_{cons}$}}
\end{picture}
\end{center}
\caption{A list is constructed with constructors (\texttt{NIL} and
  \texttt{CONS}) and pairs. The constructors are allocated in region
  \mbox{$\rho_{cons}$} and the pairs in region \mbox{$\rho_{pair}$}. If the
  elements are boxed then they are allocated in one or more infinite
  regions. In this Figure we assume one infinite region for the elements.}
\label{list.fig} \vspace{0.2cm}
\hrule
\end{figure}

We will now show three examples of manipulating lists. The first example
runs through a list. Consider the following C function template:

\index{run_through_a_list@\texttt{run\_through\_a\_list}}
\begin{verbatim}
int run_through_a_list(int list) {
  int ls;
  int elemML;
  for (ls=list; isCONS(ls); ls=tl(ls)) {
    elemML = hd(ls);
    /*do something with the element*/
  }
  return;
}
\end{verbatim}

The ML list is passed to the C function in parameter \texttt{list}. The
example uses a simple loop to run through the list. The parameter
\texttt{list} points at the first constructor in the list. Each time we
have a \texttt{CONS} constructor we also have an element, see Figure
\ref{list.fig}. The element can be retrieved with the \texttt{hd} macro.
One obtains the tail of the list by using the \texttt{tl} macro.

The following four macros are provided in the conversion library.

\index{isNIL@\texttt{isNIL}}
\index{isCONS@\texttt{isCONS}}
\index{hd@\texttt{hd}}
\index{tl@\texttt{tl}}
\begin{verbatim}
#define isNIL(x)
#define isCONS(x)
#define hd(x)
#define tl(x)
\end{verbatim}
                                
The next example explains how to construct a list backwards. Consider
the following C function template.

\index{construct_list_backwards@\texttt{construct\_list\_backwards}}
\begin{verbatim}
int construct_list_backwards(int consRho, int pairRho) {
  int *resList, *pair;
  makeNIL(consRho,resList);  
  while (/*more elements*/) {
    ml_elem = ...;
    allocRecordML(pairRho, 2, pair);
    first(pair) = (int) ml_elem;
    second(pair) = (int) resList;
    makeCONS(consRho, pair, resList);
  }
  return (int) resList;
}
\end{verbatim}

\noindent First we make the \texttt{NIL} constructor which marks the
end of the list. Each time we have an element, we allocate a pair. We
store the element in the first cell of the pair. A pointer to the list
(constructed so far) is put in the second cell of the pair. We then
allocate a new \texttt{CONS} constructor, now being the first
constructor in the list. The pair is the argument given to the
\texttt{CONS} constructor. We have assumed that the elements are
unboxed, so that no regions are necessary for the elements.

The last example shows how a list can be constructed forwards. It is more
clumsy to construct the list forwards because we have to return a pointer
to the first element. Consider the following C function template.

\index{construct_list_forwards@\texttt{construct\_list\_forwards}}
\begin{verbatim}
int construct_list_forwards(int consRho, int pairRho) {
  int *pair, *cons, *temp_pair, res;

  /* The first element is special because we have to    */
  /* return a pointer to it.                            */
  ml_elem = ...
  allocRecordML(pairRho, 2, pair);
  first(pair) = (int) ml_elem;
  makeCONS(consRho, pair, cons);
  res = (int) cons;

  while (/*more elements*/) {
    ml_elem = ...
    allocRecordML(pairRho, 2, temp_pair);
    first(temp_pair) = (int) ml_elem;
    makeCONS(consRho, temp_pair, cons);
    second(pair) = (int) cons;
    pair = temp_pair;
  }
  makeNIL(consRho, cons);
  second(pair) = (int)cons;
  return res;
}
\end{verbatim}

\noindent We construct the \texttt{CONS} constructor and pair for the
first element and return a pointer to the \texttt{CONS} constructor as
the result. We then construct the rest of the list by constructing a
\texttt{CONS} constructor and a pair for each element. It is necessary
to use a temporary variable for the pair (in the example
\texttt{temp\_pair}) because we have to update the pair for the
previous element. We let the last pair point at a \texttt{NIL}
constructor to denote the end of the list.

The two macros \texttt{makeCONS} and \texttt{makeNIL} are provided in
the conversion library:

\index{makeNIL@\texttt{makeNIL}}
\index{makeCONS@\texttt{makeCONS}}
\begin{verbatim}
#define makeNIL(rAddr, ptr)
#define makeCONS(rAddr, pair, ptr)
\end{verbatim}

%------------------
\section{Exceptions}
%------------------
C functions are allowed to raise exceptions and it is possible for the
ML code to handle these exceptions. A C function cannot declare
exceptions locally. As an example, consider the following ML
declaration.

\begin{verbatim}
exception EXN
fun raiseif0 (arg : int) : unit = 
     prim(31, ("raiseif0", "raiseif0", arg, EXN))
\end{verbatim}

\noindent If we want the function \texttt{raiseif0} to raise exception
\texttt{EXN} if the argument (\texttt{arg}) is 0 then we use the
function \texttt{raise\_exn} provided by the conversion library. The C
function may be declared thus:

\begin{verbatim}
int raiseif0(int arg, int exn) {
  int c_int;
  c_int = convertIntToC(arg);
  if (c_int = 0) {
    raise_exn(exn);
    return;
  }
  return mlUnit;
}
\end{verbatim}

Exceptions are used in examples \ref{power_exn.ex} and \ref{dir.ex} in
Section \ref{Cexamples.sec}.

%----------------------------------
\section{Profiling\label{prof.sec}}
%----------------------------------
It is necessary to make special versions of those C functions that
allocate into infinite regions if the Kit profiler is used.

When profiling is enabled, an extra argument is passed to some of the C
functions. The argument is an integer identifying the allocation point
representing the C call in the lambda program (Chapter
\ref{useOfProf.sec}).

The conversion library contains special versions of various allocation
macros and functions presented earlier in this chapter:

\index{allocRealProf@\texttt{allocRealProf}}
\index{allocRecordMLProf@\texttt{allocRecordMLProf}}
\index{convertStringToMLProfiling@\texttt{convertStringToMLProfiling}}
\index{makeNILProf@\texttt{makeNILProf}}
\index{makeCONSProf@\texttt{makeCONSProf}}
\begin{verbatim}
#define allocRealProf(realRho, realPtr, pPoint)
#define allocRecordMLProf(rhoRec, ssize, recAddr, pPoint)
StringDesc *convertStringToMLProfiling(int rhoString, 
                                       char *cStr, 
                                       int pPoint);
#define makeNILProf(rAddr, ptr, pPoint)
#define makeCONSProf(rAddr, pair, ptr, pPoint)
\end{verbatim}

As an example, we show the profiling version of the C function
\texttt{construct\_\-list\_\-backwards}, presented earlier.

\begin{verbatim}
int construct_list_backwardsProf(int consRho, 
                                 int pairRho, 
                                 int pPoint) {
  int *resList, *pair;
  makeNILProf(consRho,resList, pPoint);  
  while (/*more elements*/) {
    ml_elem = ...;
    allocRecordMLProf(pairRho, 2, pair, pPoint);
    first(pair) = (int) ml_elem;
    second(pair) = (int) resList;
    makeCONSProf(consRho, pair, resList, pPoint);
  }
  return (int) resList;
}
\end{verbatim}

The above example shows that it is not difficult to make the profiling
version of a C function; use the ``\texttt{Prof}'' versions of the
macros and use the extra argument \texttt{pPoint}, appropriately. The
same program point is used for all allocations in the C function,
perceiving the C function as one entity.

%----------------------
\section{Storage Modes}
%----------------------
As described in Chapter~\ref{storagemodes.sec} (page~\pageref{atbit.lab}), 
actual region parameters contain
a storage mode at runtime, if the region is infinite. 
A C function may check the storage mode of an
infinite region to see whether it is possible to reset the region before
allocating space in it. The conversion library provides a macro,
\mbox{\indexTwo{is_inf_and_atbot}{\texttt{is\_inf\_and\_atbot(x)}}}, 
which can be used to test whether 
resetting is safe, assuming that the arguments to the
C function are dead.

The C function \texttt{resetRegion}, which is 
provided by the conversion library,
can be used to reset a region as in the C function template below.

\index{resetRegion@\texttt{resetRegion}}
\begin{verbatim}
int construct_list_backwards(int consRho, int pairRho) {
  int *resList, *pair;

  if (is_inf_and_atbot(consRho))
    resetRegion(consRho);
  if (is_inf_and_atbot(pairRho))
    resetRegion(pairRho);

  makeNIL(consRho,resList);  
  ...
\end{verbatim}

\noindent The C programmer should be careful not to reset regions that
could contain live values. In particular, the C programmer must be
conservative and take into acount possible region aliasing between
regions holding arguments and regions holding the result. 
Clearly, if a region which the C function is supposed to
return a result in contains part of the value argument(s) of the function,
then the function should not first reset the region and 
then access the argument(s).

%-----------------------------------
\section{Compiling and Linking}
%-----------------------------------
To use a set of C functions in the ML code, one must first compile the
C functions into an object file. (Remember to include the conversion
library.) 

As an example, the file {\tt kitdemo/my\_lib.c} holds a set of example
C functions. On the HPUX system this file is compiled by
typing\footnote{On the SUN OS4 system type {\tt gcc -ansi -o my\_lib.o
-c my\_lib.c}.}
\begin{verbatim}
cc -Aa -D_HPUX_SOURCE -o my_lib.o -c my_lib.c
\end{verbatim}
\noindent
in the {\tt kitdemo} directory. If the C functions are used with
profiling type\footnote{On the SUN OS4 system type {\tt gcc -ansi -o
my\_lib\_prof.o -DPROFILING -c my\_lib.c}.}
\begin{verbatim}
cc -Aa -D_HPUX_SOURCE -DPROFILING -o my_lib_prof.o -c my_lib.c
\end{verbatim}

The project {\tt ccalls} located in the {\tt kitdemo} directory
demonstrates calls to C functions. The project must be compiled and linked
with the file {\tt my\_lib.o} (or the file {\tt my\_lib\_prof.o} if
profiling is enabled.) This is done by first modifying the ~~\texttt{link
  with library}~~ string in the {\tt Control} menu so that it contains
the full name of  {\tt kitdemo/my\_lib.o}, for example
\begin{quote}
\texttt{"/home/thor1/jane/kitdemo/my\_lib.o -lm"}
\end{quote}
\noindent
and then compiling the project as usual. If
profiling is enabled, the link string must instead refer to {\tt kitdemo/my\_lib\_prof.o}, e.g., 
\begin{quote}
\texttt{"/home/thor1/jane/kitdemo/my\_lib\_prof.o -lm"}
\end{quote}
\noindent
The project is then executed as usual.

%------------------------------------------------------
\subsection{Auto Conversion} 
%------------------------------------------------------
\index{auto conversion}
For C functions that are simple, in a sense which is 
defined below, the  Kit can generate code which 
automatically converts arguments
from ML to C and results from C back to ML.

Auto conversion is enabled by prepending a {\tt @}-character to
the name of the C function, as in the following example:

\begin{verbatim}
fun power (base : int, n : int) : int = 
     prim(31, ("@power", base, n))
\end{verbatim}

\noindent
The power function may then be implemented in C as follows:

\begin{verbatim}
    int power(int base, int n) {
      int p;
      for (p = 1; n > 0; --n)
        p = p * base;
      return p;
    }
\end{verbatim}

\noindent
No explicit conversion is needed in the C code. Auto conversion is only
supported when the arguments of the ML function are of type {\tt int} or
{\tt bool} and when the result has type {\tt unit}, {\tt int} or {\tt
  bool}. It also works when profiling is enabled.

Auto conversion is used in example \ref{power_auto.ex} in Section
\ref{Cexamples.sec}.

%--------------------------------------
\section{Examples\label{Cexamples.sec}}
%--------------------------------------
\index{C calls, examples} \index{my_lib.c@\texttt{my\_lib.c}}
\index{ccalls.sml@\texttt{ccalls.sml}} Several example C functions are
located in the file \mbox{\texttt{kitdemo/my\_lib.c}} and the project
{\tt kitdemo/ccalls.pm} makes use of these functions.

The following ML declarations are located in the {\tt ccalls.sml} file
which is part of the {\tt ccalls} project, search after

\begin{verbatim}
(*----------------------------------------------*)
(* Interface functions that call prim(31, ...)  *)
(*----------------------------------------------*)
\end{verbatim}

\begin{verbatim}
fun power(base : int, n : int) : int = 
     prim(31, ("power", "power", base, n))
fun power_auto(base : int, n : int) : int = 
     prim(31, ("@power_auto", "@power_auto", base, n))
fun power_real (base : real, n : int) : real = 
     prim(31, ("power_real", "power_real", base, n))
fun print_string_list (string_list) : unit = 
     prim(31, ("print_string_list","print_string_list", 
               string_list))
exception Power of string
fun power_exn (base : real, n : int) : real = 
     prim(31, ("power_exn", "power_exn", 
               base, n, Power "This is power"))
exception DIR of string
fun dir (directory : string) : string list = 
     prim(31, ("dir", "dirProf", directory, 
               DIR "Cannot open directory"))
fun real_list () : real list = 
     prim(31, ("real_list", "real_listProf"))
fun change_elem (p : int*string) : string*int =
      prim(31, ("change_elem", "change_elem", p))
\end{verbatim}

The implementation of each of the C functions is summarized below (see
the file {\tt my\_lib.c} for detailed comments.)

\begin{example}\label{power.ex}
  The \indexTwo{power}{\texttt{power}} function shows how to convert integers. This is done
  with the macros \texttt{convertIntToC} and \texttt{convertIntToML}.
\end{example}

\begin{example}\label{power_real.ex}
  The \indexTwo{power_real}{\texttt{power\_real}} function shows how to convert reals. This is done
  with the macros \texttt{convertRealToC} and \texttt{convertRealToML}.
\end{example}

\begin{example}\label{power_auto.ex}
  The \indexTwo{power_auto}{\texttt{power\_auto}} function shows the use of auto conversion. This
  is the easiest way of declaring C functions. The same C function
  may be called from the Kit and other C programs.
\end{example}

\begin{example}\label{print_string_list.ex}
  The \indexTwo{print_string_list}{\texttt{print\_string\_list}} example shows how to run through a list
  of strings. The method can easily be extended to running through lists of
  lists of lists, etc.
\end{example}

\begin{example}\label{power_exn.ex}
  The \indexTwo{power_exn}{\texttt{power\_exn}} function shows how an exception can be raised
  from a C function. Note that it is necessary to {\tt return} from the C
  function after you have called the \texttt{raise\_exn} function.
\end{example}

\begin{example}\label{dir.ex}
  The \indexTwo{dir}{\texttt{dir}} function shows how a list can be constructed backwards.
  We use the UNIX system calls \texttt{opendir} and \texttt{readdir} to
  read the contents of the specified directory.
  
  Note also that we check the infinite regions for resetting at the start
  of the C function. The checks must be placed at the start of the
  function, orelse not inserted at all.
  
  If you compare the C functions \texttt{dir} and \texttt{dirProf} you may
  notice how the function \texttt{dir} is modified to work with
  profiling.
\end{example}

\begin{example}\label{real_list.ex}
  Function \indexTwo{real_list}{\texttt{real\_list}} constructs a list of
  reals forwards. The reals are allocated in an infinite region. It may be
  more convenient to construct the list backwards in the C function and
  then apply a list reverse function on the result list in the Kit
  program.
\end{example}

\begin{example}\label{change_elem.ex}
  Function \indexTwo{change_elem}{\texttt{change\_elem}} shows the use of
  macro \texttt{elemRecordML}. The result type is \texttt{string*int}. The
  function swaps the two elements in the pair. The Kit passes an address to
  pre-allocated space for the result pair, and an infinite region for the
  result string.
  
  At first thought it should be enough to just swap the two arguments, and
  not copy the string into the string region, i.e. one could write the
  following function:

\begin{verbatim}
int change_elem(int newPair, int stringRho, int pair) {
  int firstElem_ml, secondElem_ml;

  firstElem_ml = elemRecordML(pair, 0);
  secondElem_ml = elemRecordML(pair, 1);

  elemRecordML(newPair, 0) = secondElem_ml;
  elemRecordML(newPair, 1) = firstElem_ml;

  return newPair;
}
\end{verbatim}

This function may work sometimes but it is not always safe! Region
inference expects the result string to be allocated in
\texttt{stringRho}, and may therefore de-allocate the region containing
the argument string, \texttt{secondElem\_ml}, while the string in the
returned pair is still alive. A safe version of \texttt{change\_elem} is
found in \texttt{my\_lib.c}.
\end{example}

\chapter{Changes from Version 2}
\index{changes}
\section{More Efficient Representation of Lists}
\index{list}
Lists are now represented with just one region for the spine of the list
plus any regions for the elements of the list. Thus \boxml{::} is no
longer applied to a pair.

\index{live variable analysis|see{variable}}
\index{KAM|see{Kit Abstract Machine}}
\index{endomorphism|see{region endomorphism}}
\index{exomorphism|see{region exomorphism}}
\index{tuple|see{record}}
\index{$\mu$|see{type and place}}
\index{rDesc|see{region descriptor}}
\index{example programs|see{{\tt kitdemo} directory}}
\index{value declaration|see{declaration}}
\printindex
\begin{center}
\bf Global Regions
\end{center}
\smallskip

\hrule
\halign{\parbox[t]{15mm}{#}\hfil\ &\ \parbox[t]{13cm}{\strut#\strut}\cr
\boxml{r1}&Holds values of type {\tt top}, i.e., records, exceptions and closures;\cr
\boxml{r2}&This region does not actually exist; it is used with unboxed values,
           such as integers, booleans and the 0-tuple.\cr}
\hrule
\bigskip
\end{document}
